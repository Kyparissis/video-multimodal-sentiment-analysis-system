{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90914b2d-ca8b-4879-a786-e9c8cdb6b36b",
   "metadata": {},
   "source": [
    "# CvT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2288afbe-7145-4305-bf3c-db80e8824a1e",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "674a882b-3a5f-4be0-97f3-2f34626eec3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-21 21:33:58.553340: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1734809638.575745  118381 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1734809638.582389  118381 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-21 21:33:58.604693: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, Image, Audio, ClassLabel, Features, Value\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import warnings\n",
    "from transformers import Trainer, TrainingArguments, TrainerCallback\n",
    "# from audiomentations import Compose, AddGaussianSNR, GainTransition, Gain, ClippingDistortion, TimeStretch, PitchShift\n",
    "# from transformers import ASTConfig, ASTFeatureExtractor, ASTForAudioClassification, ASTModel\n",
    "from collections import OrderedDict\n",
    "from copy import deepcopy\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c76021-bdaf-4fda-80a4-94a8b1e8c82d",
   "metadata": {},
   "source": [
    "## Ensure GPU access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a60ba713-31e1-4ff9-acfa-0e071f175c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc20f67-c015-45da-9a81-c4ee8adefe42",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0d7f8b5-2914-4b79-8927-b533abb2fdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define class labels\n",
    "class_labels = ClassLabel(names=[\"Negative Sentiment\", \"Positive Sentiment\"])\n",
    "\n",
    "# Define features with audio and label columns\n",
    "features = Features({\n",
    "    # \"image\": Image(),        # Define the image feature\n",
    "    \"audio\": Audio(),        # Define the audio feature\n",
    "    \"labels\": class_labels,  # Assign the class labels\n",
    "})\n",
    "\n",
    "label2id = {\n",
    "    \"Negative Sentiment\": 0,\n",
    "    \"Positive Sentiment\": 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e20ad260-a417-4eb0-aa1e-f6c8a653e5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_base_path = \"/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "488995d0-6c3d-4b90-a3c9-fda6769ff01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the CSV file\n",
    "df = pd.read_csv(dataset_base_path + \"label_edited.csv\", \n",
    "                 sep='\\t', \n",
    "                 encoding='utf-8', \n",
    "                 header=0)\n",
    "\n",
    "df = df[['video_id', 'clip_id', 'annotation_label', 'mode']].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da71f3b4-9e11-400a-bcf8-4f2430fc6f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is used to return the full path of a video in the CMU-MOSI dataset format\n",
    "def get_audio_path(video_id, clip_id):\n",
    "    return dataset_base_path + f\"Splited/Raw_onlyAudio/{video_id}/{clip_id}.wav\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751ecb74-4270-435f-9c03-277afee133b4",
   "metadata": {},
   "source": [
    "#### Get audio paths and labels of the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb6d69db-29e4-453d-9d2f-9f5f8c8b42cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct audio file paths and labels\n",
    "audio_paths = df.apply(lambda row: get_audio_path(row['video_id'], row['clip_id']), axis=1).tolist()\n",
    "labels = df['annotation_label'].astype(int).tolist()  # Convert labels to integers if necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2dbf27-8c71-4508-8b0d-c5fc45a897f6",
   "metadata": {},
   "source": [
    "Assure they are loaded correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1eb30e78-d4cf-4fe7-b0c9-121e4214a0bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f4a3a8a-02a0-4a72-8083-76fab40165e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/03bSnISJMiM/11.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/03bSnISJMiM/10.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/03bSnISJMiM/13.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/03bSnISJMiM/12.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/03bSnISJMiM/1.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/03bSnISJMiM/3.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/03bSnISJMiM/2.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/03bSnISJMiM/5.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/03bSnISJMiM/4.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/03bSnISJMiM/7.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/03bSnISJMiM/6.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/03bSnISJMiM/9.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/03bSnISJMiM/8.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/0h-zjBukYpk/24.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/0h-zjBukYpk/25.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/0h-zjBukYpk/20.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/0h-zjBukYpk/21.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/0h-zjBukYpk/22.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/0h-zjBukYpk/23.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/0h-zjBukYpk/1.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/0h-zjBukYpk/3.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/0h-zjBukYpk/2.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/0h-zjBukYpk/5.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/0h-zjBukYpk/4.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/0h-zjBukYpk/7.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/0h-zjBukYpk/6.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/0h-zjBukYpk/9.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/0h-zjBukYpk/8.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/0h-zjBukYpk/11.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/0h-zjBukYpk/10.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/0h-zjBukYpk/13.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/0h-zjBukYpk/12.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/0h-zjBukYpk/15.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/0h-zjBukYpk/14.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/0h-zjBukYpk/17.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/0h-zjBukYpk/16.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/0h-zjBukYpk/19.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/0h-zjBukYpk/18.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/1DmNV9C1hbY/11.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/1DmNV9C1hbY/10.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/1DmNV9C1hbY/13.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/1DmNV9C1hbY/12.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/1DmNV9C1hbY/14.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/1DmNV9C1hbY/1.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/1DmNV9C1hbY/3.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/1DmNV9C1hbY/2.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/1DmNV9C1hbY/5.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/1DmNV9C1hbY/4.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/1DmNV9C1hbY/7.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/1DmNV9C1hbY/6.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/1DmNV9C1hbY/9.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/1DmNV9C1hbY/8.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/1iG0909rllw/24.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/1iG0909rllw/25.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/1iG0909rllw/26.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/1iG0909rllw/27.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/1iG0909rllw/20.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/1iG0909rllw/21.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/1iG0909rllw/22.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/1iG0909rllw/23.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/1iG0909rllw/28.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/1iG0909rllw/29.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/1iG0909rllw/1.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/1iG0909rllw/3.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/1iG0909rllw/2.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/1iG0909rllw/5.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/1iG0909rllw/4.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/1iG0909rllw/7.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/1iG0909rllw/6.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/1iG0909rllw/9.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/1iG0909rllw/8.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/1iG0909rllw/11.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/1iG0909rllw/10.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/1iG0909rllw/13.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/1iG0909rllw/12.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/1iG0909rllw/15.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/1iG0909rllw/14.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/1iG0909rllw/17.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/1iG0909rllw/16.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/1iG0909rllw/19.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/1iG0909rllw/18.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/1iG0909rllw/30.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2WGyTLYerpo/56.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2WGyTLYerpo/54.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2WGyTLYerpo/42.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2WGyTLYerpo/48.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2WGyTLYerpo/43.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2WGyTLYerpo/60.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2WGyTLYerpo/61.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2WGyTLYerpo/62.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2WGyTLYerpo/63.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2WGyTLYerpo/49.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2WGyTLYerpo/52.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2WGyTLYerpo/53.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2WGyTLYerpo/24.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2WGyTLYerpo/25.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2WGyTLYerpo/26.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2WGyTLYerpo/27.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2WGyTLYerpo/20.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2WGyTLYerpo/21.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2WGyTLYerpo/22.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2WGyTLYerpo/23.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2WGyTLYerpo/46.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2WGyTLYerpo/47.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2WGyTLYerpo/44.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2WGyTLYerpo/45.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2WGyTLYerpo/28.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2WGyTLYerpo/29.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2WGyTLYerpo/40.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2WGyTLYerpo/41.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2WGyTLYerpo/1.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2WGyTLYerpo/3.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2WGyTLYerpo/2.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2WGyTLYerpo/5.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2WGyTLYerpo/4.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2WGyTLYerpo/7.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2WGyTLYerpo/6.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2WGyTLYerpo/9.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2WGyTLYerpo/8.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2WGyTLYerpo/51.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2WGyTLYerpo/39.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2WGyTLYerpo/38.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2WGyTLYerpo/59.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2WGyTLYerpo/58.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2WGyTLYerpo/11.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2WGyTLYerpo/10.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2WGyTLYerpo/13.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2WGyTLYerpo/12.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2WGyTLYerpo/15.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2WGyTLYerpo/14.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2WGyTLYerpo/17.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2WGyTLYerpo/16.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2WGyTLYerpo/19.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2WGyTLYerpo/18.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2WGyTLYerpo/31.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2WGyTLYerpo/30.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2WGyTLYerpo/37.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2WGyTLYerpo/36.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2WGyTLYerpo/35.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2WGyTLYerpo/34.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2WGyTLYerpo/33.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2WGyTLYerpo/55.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2WGyTLYerpo/32.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2WGyTLYerpo/57.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2WGyTLYerpo/50.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2iD-tVS8NPw/24.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2iD-tVS8NPw/25.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2iD-tVS8NPw/26.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2iD-tVS8NPw/27.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2iD-tVS8NPw/20.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2iD-tVS8NPw/21.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2iD-tVS8NPw/22.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2iD-tVS8NPw/23.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2iD-tVS8NPw/28.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2iD-tVS8NPw/29.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2iD-tVS8NPw/1.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2iD-tVS8NPw/3.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2iD-tVS8NPw/2.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2iD-tVS8NPw/5.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2iD-tVS8NPw/4.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2iD-tVS8NPw/7.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2iD-tVS8NPw/6.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2iD-tVS8NPw/9.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2iD-tVS8NPw/8.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2iD-tVS8NPw/11.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2iD-tVS8NPw/10.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2iD-tVS8NPw/13.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2iD-tVS8NPw/12.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2iD-tVS8NPw/15.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2iD-tVS8NPw/14.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2iD-tVS8NPw/17.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2iD-tVS8NPw/16.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2iD-tVS8NPw/19.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2iD-tVS8NPw/18.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/2iD-tVS8NPw/30.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/5W7Z1C_fDaE/24.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/5W7Z1C_fDaE/20.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/5W7Z1C_fDaE/21.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/5W7Z1C_fDaE/22.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/5W7Z1C_fDaE/23.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/5W7Z1C_fDaE/1.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/5W7Z1C_fDaE/3.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/5W7Z1C_fDaE/2.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/5W7Z1C_fDaE/5.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/5W7Z1C_fDaE/4.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/5W7Z1C_fDaE/7.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/5W7Z1C_fDaE/6.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/5W7Z1C_fDaE/9.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/5W7Z1C_fDaE/8.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/5W7Z1C_fDaE/11.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/5W7Z1C_fDaE/10.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/5W7Z1C_fDaE/13.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/5W7Z1C_fDaE/12.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/5W7Z1C_fDaE/15.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/5W7Z1C_fDaE/14.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/5W7Z1C_fDaE/17.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/5W7Z1C_fDaE/16.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/5W7Z1C_fDaE/19.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/5W7Z1C_fDaE/18.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/6Egk_28TtTM/11.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/6Egk_28TtTM/10.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/6Egk_28TtTM/12.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/6Egk_28TtTM/1.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/6Egk_28TtTM/3.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/6Egk_28TtTM/2.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/6Egk_28TtTM/5.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/6Egk_28TtTM/4.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/6Egk_28TtTM/7.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/6Egk_28TtTM/6.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/6Egk_28TtTM/9.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/6Egk_28TtTM/8.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/6_0THN4chvY/11.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/6_0THN4chvY/10.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/6_0THN4chvY/13.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/6_0THN4chvY/12.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/6_0THN4chvY/14.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/6_0THN4chvY/1.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/6_0THN4chvY/3.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/6_0THN4chvY/2.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/6_0THN4chvY/5.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/6_0THN4chvY/4.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/6_0THN4chvY/7.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/6_0THN4chvY/6.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/6_0THN4chvY/9.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/6_0THN4chvY/8.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/73jzhE8R1TQ/11.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/73jzhE8R1TQ/10.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/73jzhE8R1TQ/13.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/73jzhE8R1TQ/12.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/73jzhE8R1TQ/15.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/73jzhE8R1TQ/14.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/73jzhE8R1TQ/17.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/73jzhE8R1TQ/16.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/73jzhE8R1TQ/19.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/73jzhE8R1TQ/18.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/73jzhE8R1TQ/1.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/73jzhE8R1TQ/3.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/73jzhE8R1TQ/2.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/73jzhE8R1TQ/5.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/73jzhE8R1TQ/4.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/73jzhE8R1TQ/7.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/73jzhE8R1TQ/6.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/73jzhE8R1TQ/9.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/73jzhE8R1TQ/8.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/7JsX8y1ysxY/24.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/7JsX8y1ysxY/25.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/7JsX8y1ysxY/26.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/7JsX8y1ysxY/27.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/7JsX8y1ysxY/20.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/7JsX8y1ysxY/21.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/7JsX8y1ysxY/22.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/7JsX8y1ysxY/23.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/7JsX8y1ysxY/28.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/7JsX8y1ysxY/29.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/7JsX8y1ysxY/1.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/7JsX8y1ysxY/3.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/7JsX8y1ysxY/2.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/7JsX8y1ysxY/5.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/7JsX8y1ysxY/4.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/7JsX8y1ysxY/7.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/7JsX8y1ysxY/6.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/7JsX8y1ysxY/9.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/7JsX8y1ysxY/8.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/7JsX8y1ysxY/39.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/7JsX8y1ysxY/38.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/7JsX8y1ysxY/11.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/7JsX8y1ysxY/10.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/7JsX8y1ysxY/13.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/7JsX8y1ysxY/12.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/7JsX8y1ysxY/15.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/7JsX8y1ysxY/14.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/7JsX8y1ysxY/17.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/7JsX8y1ysxY/16.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/7JsX8y1ysxY/19.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/7JsX8y1ysxY/18.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/7JsX8y1ysxY/31.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/7JsX8y1ysxY/30.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/7JsX8y1ysxY/37.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/7JsX8y1ysxY/36.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/7JsX8y1ysxY/35.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/7JsX8y1ysxY/34.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/7JsX8y1ysxY/33.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/7JsX8y1ysxY/32.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8OtFthrtaJM/20.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8OtFthrtaJM/21.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8OtFthrtaJM/22.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8OtFthrtaJM/23.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8OtFthrtaJM/1.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8OtFthrtaJM/3.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8OtFthrtaJM/2.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8OtFthrtaJM/5.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8OtFthrtaJM/4.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8OtFthrtaJM/7.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8OtFthrtaJM/6.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8OtFthrtaJM/9.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8OtFthrtaJM/8.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8OtFthrtaJM/11.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8OtFthrtaJM/10.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8OtFthrtaJM/13.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8OtFthrtaJM/12.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8OtFthrtaJM/15.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8OtFthrtaJM/14.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8OtFthrtaJM/17.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8OtFthrtaJM/16.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8OtFthrtaJM/19.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8OtFthrtaJM/18.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8d-gEyoeBzc/24.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8d-gEyoeBzc/25.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8d-gEyoeBzc/26.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8d-gEyoeBzc/27.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8d-gEyoeBzc/20.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8d-gEyoeBzc/21.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8d-gEyoeBzc/22.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8d-gEyoeBzc/23.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8d-gEyoeBzc/28.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8d-gEyoeBzc/29.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8d-gEyoeBzc/1.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8d-gEyoeBzc/3.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8d-gEyoeBzc/2.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8d-gEyoeBzc/5.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8d-gEyoeBzc/4.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8d-gEyoeBzc/7.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8d-gEyoeBzc/6.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8d-gEyoeBzc/9.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8d-gEyoeBzc/8.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8d-gEyoeBzc/11.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8d-gEyoeBzc/10.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8d-gEyoeBzc/13.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8d-gEyoeBzc/12.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8d-gEyoeBzc/15.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8d-gEyoeBzc/14.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8d-gEyoeBzc/17.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8d-gEyoeBzc/16.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8d-gEyoeBzc/19.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8d-gEyoeBzc/18.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8d-gEyoeBzc/30.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8qrpnFRGt2A/24.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8qrpnFRGt2A/25.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8qrpnFRGt2A/26.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8qrpnFRGt2A/20.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8qrpnFRGt2A/21.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8qrpnFRGt2A/22.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8qrpnFRGt2A/23.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8qrpnFRGt2A/1.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8qrpnFRGt2A/3.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8qrpnFRGt2A/2.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8qrpnFRGt2A/5.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8qrpnFRGt2A/4.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8qrpnFRGt2A/7.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8qrpnFRGt2A/6.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8qrpnFRGt2A/9.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8qrpnFRGt2A/8.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8qrpnFRGt2A/11.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8qrpnFRGt2A/10.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8qrpnFRGt2A/13.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8qrpnFRGt2A/12.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8qrpnFRGt2A/15.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8qrpnFRGt2A/14.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8qrpnFRGt2A/17.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8qrpnFRGt2A/16.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8qrpnFRGt2A/19.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/8qrpnFRGt2A/18.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9J25DZhivz8/24.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9J25DZhivz8/25.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9J25DZhivz8/20.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9J25DZhivz8/21.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9J25DZhivz8/22.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9J25DZhivz8/23.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9J25DZhivz8/1.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9J25DZhivz8/3.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9J25DZhivz8/2.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9J25DZhivz8/5.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9J25DZhivz8/4.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9J25DZhivz8/7.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9J25DZhivz8/6.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9J25DZhivz8/9.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9J25DZhivz8/8.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9J25DZhivz8/11.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9J25DZhivz8/10.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9J25DZhivz8/13.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9J25DZhivz8/12.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9J25DZhivz8/15.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9J25DZhivz8/14.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9J25DZhivz8/17.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9J25DZhivz8/16.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9J25DZhivz8/19.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9J25DZhivz8/18.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9T9Hf74oK10/24.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9T9Hf74oK10/25.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9T9Hf74oK10/20.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9T9Hf74oK10/21.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9T9Hf74oK10/22.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9T9Hf74oK10/23.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9T9Hf74oK10/1.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9T9Hf74oK10/3.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9T9Hf74oK10/2.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9T9Hf74oK10/5.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9T9Hf74oK10/4.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9T9Hf74oK10/7.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9T9Hf74oK10/6.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9T9Hf74oK10/9.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9T9Hf74oK10/8.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9T9Hf74oK10/11.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9T9Hf74oK10/10.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9T9Hf74oK10/13.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9T9Hf74oK10/12.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9T9Hf74oK10/15.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9T9Hf74oK10/14.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9T9Hf74oK10/17.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9T9Hf74oK10/16.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9T9Hf74oK10/19.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9T9Hf74oK10/18.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9c67fiY0wGQ/11.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9c67fiY0wGQ/10.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9c67fiY0wGQ/12.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9c67fiY0wGQ/1.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9c67fiY0wGQ/3.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9c67fiY0wGQ/2.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9c67fiY0wGQ/5.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9c67fiY0wGQ/4.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9c67fiY0wGQ/7.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9c67fiY0wGQ/6.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9c67fiY0wGQ/9.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9c67fiY0wGQ/8.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9qR7uwkblbs/24.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9qR7uwkblbs/25.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9qR7uwkblbs/26.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9qR7uwkblbs/27.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9qR7uwkblbs/20.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9qR7uwkblbs/21.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9qR7uwkblbs/22.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9qR7uwkblbs/23.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9qR7uwkblbs/28.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9qR7uwkblbs/29.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9qR7uwkblbs/1.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9qR7uwkblbs/3.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9qR7uwkblbs/2.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9qR7uwkblbs/5.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9qR7uwkblbs/4.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9qR7uwkblbs/7.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9qR7uwkblbs/6.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9qR7uwkblbs/9.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9qR7uwkblbs/8.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9qR7uwkblbs/11.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9qR7uwkblbs/10.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9qR7uwkblbs/13.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9qR7uwkblbs/12.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9qR7uwkblbs/15.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9qR7uwkblbs/14.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9qR7uwkblbs/17.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9qR7uwkblbs/16.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9qR7uwkblbs/19.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9qR7uwkblbs/18.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9qR7uwkblbs/31.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9qR7uwkblbs/30.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9qR7uwkblbs/33.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/9qR7uwkblbs/32.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Af8D0E4ZXaw/24.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Af8D0E4ZXaw/25.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Af8D0E4ZXaw/26.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Af8D0E4ZXaw/27.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Af8D0E4ZXaw/20.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Af8D0E4ZXaw/21.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Af8D0E4ZXaw/22.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Af8D0E4ZXaw/23.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Af8D0E4ZXaw/28.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Af8D0E4ZXaw/29.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Af8D0E4ZXaw/1.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Af8D0E4ZXaw/3.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Af8D0E4ZXaw/2.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Af8D0E4ZXaw/5.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Af8D0E4ZXaw/4.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Af8D0E4ZXaw/7.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Af8D0E4ZXaw/6.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Af8D0E4ZXaw/9.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Af8D0E4ZXaw/8.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Af8D0E4ZXaw/11.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Af8D0E4ZXaw/10.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Af8D0E4ZXaw/13.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Af8D0E4ZXaw/12.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Af8D0E4ZXaw/15.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Af8D0E4ZXaw/14.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Af8D0E4ZXaw/17.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Af8D0E4ZXaw/16.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Af8D0E4ZXaw/19.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Af8D0E4ZXaw/18.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Af8D0E4ZXaw/31.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Af8D0E4ZXaw/30.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BI97DNYfe5I/24.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BI97DNYfe5I/25.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BI97DNYfe5I/26.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BI97DNYfe5I/27.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BI97DNYfe5I/20.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BI97DNYfe5I/21.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BI97DNYfe5I/22.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BI97DNYfe5I/23.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BI97DNYfe5I/28.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BI97DNYfe5I/29.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BI97DNYfe5I/1.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BI97DNYfe5I/3.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BI97DNYfe5I/2.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BI97DNYfe5I/5.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BI97DNYfe5I/4.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BI97DNYfe5I/7.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BI97DNYfe5I/6.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BI97DNYfe5I/9.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BI97DNYfe5I/8.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BI97DNYfe5I/11.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BI97DNYfe5I/10.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BI97DNYfe5I/13.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BI97DNYfe5I/12.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BI97DNYfe5I/15.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BI97DNYfe5I/14.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BI97DNYfe5I/17.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BI97DNYfe5I/16.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BI97DNYfe5I/19.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BI97DNYfe5I/18.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BI97DNYfe5I/31.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BI97DNYfe5I/30.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BXuRRbG0Ugk/24.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BXuRRbG0Ugk/25.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BXuRRbG0Ugk/26.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BXuRRbG0Ugk/27.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BXuRRbG0Ugk/20.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BXuRRbG0Ugk/21.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BXuRRbG0Ugk/22.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BXuRRbG0Ugk/23.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BXuRRbG0Ugk/28.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BXuRRbG0Ugk/29.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BXuRRbG0Ugk/1.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BXuRRbG0Ugk/3.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BXuRRbG0Ugk/2.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BXuRRbG0Ugk/5.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BXuRRbG0Ugk/4.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BXuRRbG0Ugk/7.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BXuRRbG0Ugk/6.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BXuRRbG0Ugk/9.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BXuRRbG0Ugk/8.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BXuRRbG0Ugk/11.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BXuRRbG0Ugk/10.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BXuRRbG0Ugk/13.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BXuRRbG0Ugk/12.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BXuRRbG0Ugk/15.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BXuRRbG0Ugk/14.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BXuRRbG0Ugk/17.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BXuRRbG0Ugk/16.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BXuRRbG0Ugk/19.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BXuRRbG0Ugk/18.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BXuRRbG0Ugk/31.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BXuRRbG0Ugk/30.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Bfr499ggo-0/20.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Bfr499ggo-0/21.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Bfr499ggo-0/22.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Bfr499ggo-0/1.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Bfr499ggo-0/3.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Bfr499ggo-0/2.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Bfr499ggo-0/5.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Bfr499ggo-0/4.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Bfr499ggo-0/7.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Bfr499ggo-0/6.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Bfr499ggo-0/9.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Bfr499ggo-0/8.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Bfr499ggo-0/11.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Bfr499ggo-0/10.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Bfr499ggo-0/13.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Bfr499ggo-0/12.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Bfr499ggo-0/15.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Bfr499ggo-0/14.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Bfr499ggo-0/17.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Bfr499ggo-0/16.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Bfr499ggo-0/19.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Bfr499ggo-0/18.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BioHAh1qJAQ/24.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BioHAh1qJAQ/25.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BioHAh1qJAQ/26.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BioHAh1qJAQ/27.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BioHAh1qJAQ/20.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BioHAh1qJAQ/21.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BioHAh1qJAQ/22.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BioHAh1qJAQ/23.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BioHAh1qJAQ/28.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BioHAh1qJAQ/29.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BioHAh1qJAQ/1.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BioHAh1qJAQ/3.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BioHAh1qJAQ/2.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BioHAh1qJAQ/5.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BioHAh1qJAQ/4.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BioHAh1qJAQ/7.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BioHAh1qJAQ/6.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BioHAh1qJAQ/9.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BioHAh1qJAQ/8.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BioHAh1qJAQ/11.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BioHAh1qJAQ/10.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BioHAh1qJAQ/13.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BioHAh1qJAQ/12.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BioHAh1qJAQ/15.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BioHAh1qJAQ/14.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BioHAh1qJAQ/17.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BioHAh1qJAQ/16.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BioHAh1qJAQ/19.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BioHAh1qJAQ/18.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BioHAh1qJAQ/30.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BvYR0L6f2Ig/24.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BvYR0L6f2Ig/25.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BvYR0L6f2Ig/26.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BvYR0L6f2Ig/20.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BvYR0L6f2Ig/21.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BvYR0L6f2Ig/22.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BvYR0L6f2Ig/23.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BvYR0L6f2Ig/1.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BvYR0L6f2Ig/3.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BvYR0L6f2Ig/2.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BvYR0L6f2Ig/5.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BvYR0L6f2Ig/4.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BvYR0L6f2Ig/7.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BvYR0L6f2Ig/6.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BvYR0L6f2Ig/9.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BvYR0L6f2Ig/8.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BvYR0L6f2Ig/11.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BvYR0L6f2Ig/10.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BvYR0L6f2Ig/13.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BvYR0L6f2Ig/12.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BvYR0L6f2Ig/15.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BvYR0L6f2Ig/14.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BvYR0L6f2Ig/17.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BvYR0L6f2Ig/16.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BvYR0L6f2Ig/19.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/BvYR0L6f2Ig/18.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Ci-AH39fi3Y/42.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Ci-AH39fi3Y/43.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Ci-AH39fi3Y/24.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Ci-AH39fi3Y/25.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Ci-AH39fi3Y/26.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Ci-AH39fi3Y/27.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Ci-AH39fi3Y/20.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Ci-AH39fi3Y/21.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Ci-AH39fi3Y/22.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Ci-AH39fi3Y/23.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Ci-AH39fi3Y/44.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Ci-AH39fi3Y/28.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Ci-AH39fi3Y/29.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Ci-AH39fi3Y/40.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Ci-AH39fi3Y/41.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Ci-AH39fi3Y/1.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Ci-AH39fi3Y/3.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Ci-AH39fi3Y/2.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Ci-AH39fi3Y/5.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Ci-AH39fi3Y/4.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Ci-AH39fi3Y/7.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Ci-AH39fi3Y/6.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Ci-AH39fi3Y/9.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Ci-AH39fi3Y/8.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Ci-AH39fi3Y/39.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Ci-AH39fi3Y/38.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Ci-AH39fi3Y/11.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Ci-AH39fi3Y/10.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Ci-AH39fi3Y/13.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Ci-AH39fi3Y/12.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Ci-AH39fi3Y/15.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Ci-AH39fi3Y/14.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Ci-AH39fi3Y/17.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Ci-AH39fi3Y/16.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Ci-AH39fi3Y/19.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Ci-AH39fi3Y/18.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Ci-AH39fi3Y/31.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Ci-AH39fi3Y/30.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Ci-AH39fi3Y/37.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Ci-AH39fi3Y/36.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Ci-AH39fi3Y/35.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Ci-AH39fi3Y/34.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Ci-AH39fi3Y/33.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Ci-AH39fi3Y/32.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Clx4VXItLTE/24.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Clx4VXItLTE/25.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Clx4VXItLTE/26.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Clx4VXItLTE/27.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Clx4VXItLTE/20.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Clx4VXItLTE/21.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Clx4VXItLTE/22.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Clx4VXItLTE/23.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Clx4VXItLTE/28.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Clx4VXItLTE/29.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Clx4VXItLTE/1.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Clx4VXItLTE/3.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Clx4VXItLTE/2.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Clx4VXItLTE/5.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Clx4VXItLTE/4.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Clx4VXItLTE/7.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Clx4VXItLTE/6.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Clx4VXItLTE/9.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Clx4VXItLTE/8.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Clx4VXItLTE/11.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Clx4VXItLTE/10.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Clx4VXItLTE/13.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Clx4VXItLTE/12.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Clx4VXItLTE/15.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Clx4VXItLTE/14.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Clx4VXItLTE/17.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Clx4VXItLTE/16.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Clx4VXItLTE/19.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Clx4VXItLTE/18.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Clx4VXItLTE/31.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Clx4VXItLTE/30.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Dg_0XKD0Mf4/11.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Dg_0XKD0Mf4/10.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Dg_0XKD0Mf4/13.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Dg_0XKD0Mf4/12.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Dg_0XKD0Mf4/15.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Dg_0XKD0Mf4/14.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Dg_0XKD0Mf4/17.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Dg_0XKD0Mf4/16.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Dg_0XKD0Mf4/18.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Dg_0XKD0Mf4/1.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Dg_0XKD0Mf4/3.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Dg_0XKD0Mf4/2.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Dg_0XKD0Mf4/5.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Dg_0XKD0Mf4/4.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Dg_0XKD0Mf4/7.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Dg_0XKD0Mf4/6.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Dg_0XKD0Mf4/9.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Dg_0XKD0Mf4/8.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/G-xst2euQUc/11.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/G-xst2euQUc/10.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/G-xst2euQUc/13.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/G-xst2euQUc/12.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/G-xst2euQUc/15.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/G-xst2euQUc/14.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/G-xst2euQUc/17.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/G-xst2euQUc/16.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/G-xst2euQUc/19.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/G-xst2euQUc/18.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/G-xst2euQUc/20.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/G-xst2euQUc/1.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/G-xst2euQUc/3.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/G-xst2euQUc/2.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/G-xst2euQUc/5.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/G-xst2euQUc/4.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/G-xst2euQUc/7.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/G-xst2euQUc/6.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/G-xst2euQUc/9.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/G-xst2euQUc/8.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/G-xst2euQUc/21.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/G6GlGvlkxAQ/24.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/G6GlGvlkxAQ/25.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/G6GlGvlkxAQ/26.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/G6GlGvlkxAQ/27.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/G6GlGvlkxAQ/20.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/G6GlGvlkxAQ/21.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/G6GlGvlkxAQ/22.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/G6GlGvlkxAQ/23.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/G6GlGvlkxAQ/28.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/G6GlGvlkxAQ/29.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/G6GlGvlkxAQ/1.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/G6GlGvlkxAQ/3.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/G6GlGvlkxAQ/2.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/G6GlGvlkxAQ/5.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/G6GlGvlkxAQ/4.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/G6GlGvlkxAQ/7.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/G6GlGvlkxAQ/6.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/G6GlGvlkxAQ/9.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/G6GlGvlkxAQ/8.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/G6GlGvlkxAQ/11.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/G6GlGvlkxAQ/10.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/G6GlGvlkxAQ/13.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/G6GlGvlkxAQ/12.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/G6GlGvlkxAQ/15.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/G6GlGvlkxAQ/14.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/G6GlGvlkxAQ/17.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/G6GlGvlkxAQ/16.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/G6GlGvlkxAQ/19.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/G6GlGvlkxAQ/18.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/GWuJjcEuzt8/11.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/GWuJjcEuzt8/10.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/GWuJjcEuzt8/13.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/GWuJjcEuzt8/12.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/GWuJjcEuzt8/15.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/GWuJjcEuzt8/14.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/GWuJjcEuzt8/17.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/GWuJjcEuzt8/16.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/GWuJjcEuzt8/18.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/GWuJjcEuzt8/1.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/GWuJjcEuzt8/3.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/GWuJjcEuzt8/2.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/GWuJjcEuzt8/5.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/GWuJjcEuzt8/4.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/GWuJjcEuzt8/7.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/GWuJjcEuzt8/6.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/GWuJjcEuzt8/9.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/GWuJjcEuzt8/8.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/HEsqda8_d0Q/24.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/HEsqda8_d0Q/25.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/HEsqda8_d0Q/26.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/HEsqda8_d0Q/27.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/HEsqda8_d0Q/20.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/HEsqda8_d0Q/21.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/HEsqda8_d0Q/22.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/HEsqda8_d0Q/23.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/HEsqda8_d0Q/28.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/HEsqda8_d0Q/29.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/HEsqda8_d0Q/1.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/HEsqda8_d0Q/3.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/HEsqda8_d0Q/2.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/HEsqda8_d0Q/5.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/HEsqda8_d0Q/4.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/HEsqda8_d0Q/7.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/HEsqda8_d0Q/6.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/HEsqda8_d0Q/9.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/HEsqda8_d0Q/8.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/HEsqda8_d0Q/11.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/HEsqda8_d0Q/10.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/HEsqda8_d0Q/13.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/HEsqda8_d0Q/12.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/HEsqda8_d0Q/15.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/HEsqda8_d0Q/14.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/HEsqda8_d0Q/17.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/HEsqda8_d0Q/16.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/HEsqda8_d0Q/19.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/HEsqda8_d0Q/18.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/HEsqda8_d0Q/31.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/HEsqda8_d0Q/30.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/HEsqda8_d0Q/34.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/HEsqda8_d0Q/33.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/HEsqda8_d0Q/32.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/I5y0__X72p0/24.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/I5y0__X72p0/25.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/I5y0__X72p0/26.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/I5y0__X72p0/27.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/I5y0__X72p0/20.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/I5y0__X72p0/21.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/I5y0__X72p0/22.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/I5y0__X72p0/23.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/I5y0__X72p0/28.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/I5y0__X72p0/29.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/I5y0__X72p0/1.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/I5y0__X72p0/3.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/I5y0__X72p0/2.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/I5y0__X72p0/5.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/I5y0__X72p0/4.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/I5y0__X72p0/7.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/I5y0__X72p0/6.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/I5y0__X72p0/9.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/I5y0__X72p0/8.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/I5y0__X72p0/39.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/I5y0__X72p0/38.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/I5y0__X72p0/11.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/I5y0__X72p0/10.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/I5y0__X72p0/13.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/I5y0__X72p0/12.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/I5y0__X72p0/15.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/I5y0__X72p0/14.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/I5y0__X72p0/17.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/I5y0__X72p0/16.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/I5y0__X72p0/19.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/I5y0__X72p0/18.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/I5y0__X72p0/31.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/I5y0__X72p0/30.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/I5y0__X72p0/37.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/I5y0__X72p0/36.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/I5y0__X72p0/35.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/I5y0__X72p0/34.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/I5y0__X72p0/33.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/I5y0__X72p0/32.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Iu2PFX3z_1s/11.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Iu2PFX3z_1s/10.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Iu2PFX3z_1s/13.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Iu2PFX3z_1s/12.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Iu2PFX3z_1s/15.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Iu2PFX3z_1s/14.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Iu2PFX3z_1s/16.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Iu2PFX3z_1s/1.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Iu2PFX3z_1s/3.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Iu2PFX3z_1s/2.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Iu2PFX3z_1s/5.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Iu2PFX3z_1s/4.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Iu2PFX3z_1s/7.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Iu2PFX3z_1s/6.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Iu2PFX3z_1s/9.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Iu2PFX3z_1s/8.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/IumbAb8q2dM/20.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/IumbAb8q2dM/21.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/IumbAb8q2dM/22.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/IumbAb8q2dM/1.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/IumbAb8q2dM/3.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/IumbAb8q2dM/2.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/IumbAb8q2dM/5.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/IumbAb8q2dM/4.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/IumbAb8q2dM/7.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/IumbAb8q2dM/6.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/IumbAb8q2dM/9.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/IumbAb8q2dM/8.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/IumbAb8q2dM/11.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/IumbAb8q2dM/10.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/IumbAb8q2dM/13.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/IumbAb8q2dM/12.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/IumbAb8q2dM/15.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/IumbAb8q2dM/14.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/IumbAb8q2dM/17.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/IumbAb8q2dM/16.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/IumbAb8q2dM/19.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/IumbAb8q2dM/18.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Jkswaaud0hk/11.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Jkswaaud0hk/10.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Jkswaaud0hk/13.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Jkswaaud0hk/12.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Jkswaaud0hk/15.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Jkswaaud0hk/14.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Jkswaaud0hk/17.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Jkswaaud0hk/16.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Jkswaaud0hk/19.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Jkswaaud0hk/18.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Jkswaaud0hk/20.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Jkswaaud0hk/1.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Jkswaaud0hk/3.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Jkswaaud0hk/2.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Jkswaaud0hk/5.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Jkswaaud0hk/4.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Jkswaaud0hk/7.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Jkswaaud0hk/6.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Jkswaaud0hk/9.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Jkswaaud0hk/8.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/LSi-o-IrDMs/24.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/LSi-o-IrDMs/25.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/LSi-o-IrDMs/26.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/LSi-o-IrDMs/27.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/LSi-o-IrDMs/20.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/LSi-o-IrDMs/21.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/LSi-o-IrDMs/22.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/LSi-o-IrDMs/23.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/LSi-o-IrDMs/28.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/LSi-o-IrDMs/29.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/LSi-o-IrDMs/1.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/LSi-o-IrDMs/3.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/LSi-o-IrDMs/2.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/LSi-o-IrDMs/5.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/LSi-o-IrDMs/4.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/LSi-o-IrDMs/7.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/LSi-o-IrDMs/6.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/LSi-o-IrDMs/9.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/LSi-o-IrDMs/8.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/LSi-o-IrDMs/11.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/LSi-o-IrDMs/10.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/LSi-o-IrDMs/13.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/LSi-o-IrDMs/12.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/LSi-o-IrDMs/15.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/LSi-o-IrDMs/14.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/LSi-o-IrDMs/17.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/LSi-o-IrDMs/16.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/LSi-o-IrDMs/19.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/LSi-o-IrDMs/18.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/MLal-t_vJPM/11.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/MLal-t_vJPM/10.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/MLal-t_vJPM/13.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/MLal-t_vJPM/12.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/MLal-t_vJPM/15.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/MLal-t_vJPM/14.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/MLal-t_vJPM/17.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/MLal-t_vJPM/16.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/MLal-t_vJPM/18.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/MLal-t_vJPM/1.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/MLal-t_vJPM/3.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/MLal-t_vJPM/2.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/MLal-t_vJPM/5.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/MLal-t_vJPM/4.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/MLal-t_vJPM/7.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/MLal-t_vJPM/6.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/MLal-t_vJPM/9.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/MLal-t_vJPM/8.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Njd1F0vZSm4/11.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Njd1F0vZSm4/10.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Njd1F0vZSm4/13.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Njd1F0vZSm4/12.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Njd1F0vZSm4/1.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Njd1F0vZSm4/3.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Njd1F0vZSm4/2.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Njd1F0vZSm4/5.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Njd1F0vZSm4/4.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Njd1F0vZSm4/7.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Njd1F0vZSm4/6.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Njd1F0vZSm4/9.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Njd1F0vZSm4/8.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Nzq88NnDkEk/24.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Nzq88NnDkEk/25.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Nzq88NnDkEk/26.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Nzq88NnDkEk/27.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Nzq88NnDkEk/20.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Nzq88NnDkEk/21.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Nzq88NnDkEk/22.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Nzq88NnDkEk/23.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Nzq88NnDkEk/28.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Nzq88NnDkEk/29.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Nzq88NnDkEk/1.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Nzq88NnDkEk/3.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Nzq88NnDkEk/2.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Nzq88NnDkEk/5.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Nzq88NnDkEk/4.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Nzq88NnDkEk/7.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Nzq88NnDkEk/6.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Nzq88NnDkEk/9.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Nzq88NnDkEk/8.wav',\n",
       " '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/Nzq88NnDkEk/11.wav',\n",
       " ...]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "882faa30-b324-4309-aef7-184e94e75ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = Dataset.from_dict({\n",
    "#     \"audio\": audio_paths,\n",
    "#     \"labels\": labels,\n",
    "# }, features=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90cd1385-b0aa-4e1e-b4ce-4e2f304f68ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3196a98b-3586-4994-be63-89ace1e0a0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Verify the dataset structure\n",
    "# print(dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa96401-69f8-4223-a949-4d006fb03fa2",
   "metadata": {},
   "source": [
    "## Load feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "267b5ea3-89f5-47b1-93c9-180a63317f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we define which pretrained model we want to use and instantiate a feature extractor\n",
    "from transformers import AutoImageProcessor\n",
    "\n",
    "pretrained_model = \"microsoft/cvt-13\"\n",
    "image_processor = AutoImageProcessor.from_pretrained(pretrained_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933320e4-98f4-487f-b01d-1df5a408a2ad",
   "metadata": {},
   "source": [
    "### View extractor's inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c257c9a-d475-4490-84a3-71f87e0d1abe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pixel_values']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_processor.model_input_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24e984f9-0c3e-4bbf-b2d8-4555ca152311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we save model input name and sampling rate for later use\n",
    "model_input_name = 'pixel_values'  # key -> 'input_values'\n",
    "\n",
    "SAMPLING_RATE = 16000  # Hz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e0e5d0-dd02-405f-bad1-d232c1dc79d0",
   "metadata": {},
   "source": [
    "### Set maximum audio length to be processed\n",
    "\n",
    "- Below this value, the audio will be padded.\n",
    "- After this value, the audio will be truncated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0aa88cdb-5e02-4f76-ba71-9b26eac8edf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_AUDIO_SECONDS = 10  # Maximum audio duration in seconds\n",
    "MAX_AUDIO_LENGTH = SAMPLING_RATE * MAX_AUDIO_SECONDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c790423e-ad3b-4daf-93ad-b1a7c00a5ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160000 max samples length\n"
     ]
    }
   ],
   "source": [
    "print(MAX_AUDIO_LENGTH, \"max samples length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4568e51-1af1-4727-b154-7da1e64668b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "224"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_processor.size['shortest_edge']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54ccfcaf-9c35-4cf3-b3fd-77a96e0cd020",
   "metadata": {},
   "outputs": [],
   "source": [
    "imageSizeHeight = image_processor.size['shortest_edge']\n",
    "imageSizeWidth = image_processor.size['shortest_edge']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05dda1c0-1c87-4cd6-a1cd-d16f369fd34b",
   "metadata": {},
   "source": [
    "## Dataset Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77c0146d-1f33-434e-af4b-70ec67479092",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import torchvision.transforms as T\n",
    "\n",
    "def get_spectrograms(wavs):\n",
    "    # Step 2: Generate log Mel spectrograms\n",
    "    spectrograms = []\n",
    "    for wav in wavs:\n",
    "        # Calculate the window length (25ms) and hop length (10ms) in samples\n",
    "        # WE USE THE SAME PARAMETERS FOR SPECTROGRAM GENERATION AS THE AST MODEL\n",
    "        # This results in a 128×100t spectrogram\n",
    "        hamming_window = 0.025 # [sec] window size\n",
    "        hop_freq = 0.010       # [sec] step size\n",
    "        win_length = int(hamming_window * SAMPLING_RATE)  # 25ms window\n",
    "        hop_length = int(hop_freq * SAMPLING_RATE)        # 10ms step\n",
    "\n",
    "        mel_spec = librosa.feature.melspectrogram(\n",
    "            y=wav,\n",
    "            sr=SAMPLING_RATE,\n",
    "            n_fft=2048,  # Number of FFT components\n",
    "            hop_length=hop_length,\n",
    "            win_length=win_length,\n",
    "            window='hamming',  # Use Hamming window\n",
    "            n_mels=128  # 128 Mel filterbank features (used by AST) (number of Mel filterbanks)\n",
    "                        # whisper uses 80\n",
    "        )\n",
    "        log_mel_spec = librosa.power_to_db(mel_spec, ref=np.max)  # Convert to log scale\n",
    "        spectrograms.append(log_mel_spec)\n",
    "\n",
    "    # Step 3: Resize each spectrogram to 224x224\n",
    "    resized_spectrograms = []\n",
    "    for spec in spectrograms:\n",
    "        # Normalize the spectrogram to [0, 1]\n",
    "        spec_min = np.min(spec)\n",
    "        spec_max = np.max(spec)\n",
    "        normalized_spec = (spec - spec_min) / (spec_max - spec_min)  # Normalize to [0, 1]\n",
    "        \n",
    "        # Ensure the spectrogram is 2D (height x width)\n",
    "        # spec_resized = librosa.util.fix_length(spec, size=MAX_AUDIO_LENGTH)  # Ensure fixed length\n",
    "        # Resize to 224x224 (use interpolation)\n",
    "        # By default, it uses the bilinear interpolation filter for resizing\n",
    "        resized_spec = T.Resize((imageSizeHeight, imageSizeWidth))(torch.tensor(normalized_spec).unsqueeze(0).unsqueeze(0).float())\n",
    "        resized_spectrograms.append(resized_spec.squeeze(0).squeeze(0).numpy())  # Remove extra dimensions\n",
    "    \n",
    "    # Step 3: Convert to 3-channel image format (if needed by the model)\n",
    "    # Most ResNet-like models expect 3-channel input, so we stack the spectrogram\n",
    "    processed_spectrograms = [np.stack([spec, spec, spec], axis=0) for spec in resized_spectrograms]\n",
    "\n",
    "    return processed_spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "61455d31-6044-4a96-b42b-4e1409ff7d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad or truncate the audio (before making it a spectrogram)\n",
    "def pad_audio(audio, max_length, return_tensor=False):   \n",
    "    # Convert audio to torch.Tensor if it's a numpy.ndarray\n",
    "    if isinstance(audio, np.ndarray):\n",
    "        audio = torch.tensor(audio)\n",
    "    \n",
    "    audio_length = len(audio)\n",
    "    if audio_length < max_length:\n",
    "        # Pad with zeros (as a tensor) to the right\n",
    "        padding = torch.zeros(max_length - audio_length)\n",
    "        padded_audio = torch.cat([audio, padding])  # Concatenate the padding\n",
    "    else:\n",
    "        padded_audio = audio[:max_length]  # Slice the tensor if it's too long\n",
    "    \n",
    "    # Convert to ndarray if required\n",
    "    if not return_tensor:\n",
    "        padded_audio = padded_audio.numpy()  # Convert back to numpy array if requested\n",
    "    \n",
    "    return padded_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ad986fa-1353-49c1-aa8c-fba6930d6eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_audio(batch):\n",
    "    # Step 1: Load the audio signals\n",
    "    wavs = [pad_audio(audio[\"array\"], MAX_AUDIO_LENGTH) for audio in batch[\"input_values\"]]\n",
    "    # wavs = [audio[\"array\"] for audio in batch[\"input_values\"]]\n",
    "\n",
    "    processed_spectrograms = get_spectrograms(wavs)\n",
    "    \n",
    "    inputs = image_processor(processed_spectrograms,\n",
    "                             do_normalize=False,\n",
    "                             do_rescale=False,\n",
    "                             # image_mean=,\n",
    "                             # image_std=,\n",
    "                             return_tensors=\"pt\")\n",
    "\n",
    "    output_batch = {\n",
    "        model_input_name: inputs[\"pixel_values\"],  # Correct key for processed image tensors\n",
    "        \"labels\": list(batch[\"labels\"])          # Pass the labels unchanged\n",
    "    }\n",
    "\n",
    "    # print(output_batch)\n",
    "\n",
    "    return output_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fec7e12-fa0f-4b8f-9c04-b16e9ae2fa69",
   "metadata": {},
   "source": [
    "### Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "30e7b50f-fd2c-4f30-b9d4-753fe6f36dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio_augmentations = Compose([\n",
    "##     Adds Gaussian noise to the audio while maintaining a specified signal-to-noise ratio (SNR)\n",
    "#     AddGaussianSNR(min_snr_db=10,    # min_snr_db: Minimum SNR in decibels (dB). A lower value means more noise.\n",
    "#                    max_snr_db=20),   # max_snr_db: Maximum SNR in dB. A higher value means less noise.\n",
    "##     Adjusts the audio volume by applying a uniform gain\n",
    "#     Gain(min_gain_db=-6,      # min_gain_db: Minimum gain in dB. A negative value decreases volume.\n",
    "#          max_gain_db=6),      # max_gain_db: Maximum gain in dB. A positive value increases volume.\n",
    "##     Gradually applies gain changes over a specified duration to create a smooth volume transition.\n",
    "#     GainTransition(min_gain_db=-6,                     # min_gain_db: Minimum gain change in dB. Negative for fading out, positive for fading in.\n",
    "#                    max_gain_db=6,                      # max_gain_db: Maximum gain change in dB.\n",
    "#                    min_duration=0.01,                  # min_duration: Minimum duration of the gain transition (in seconds or as a fraction of total duration, depending on duration_unit\n",
    "#                    max_duration=0.3,                   # max_duration: Maximum duration of the gain transition.\n",
    "#                    duration_unit=\"fraction\"),          # \"fraction\": Durations are a fraction of the total audio length.\n",
    "#                                                        # \"seconds\": Durations are in absolute time.\n",
    "##     Simulates distortion by artificially clipping the waveform\n",
    "#     ClippingDistortion(min_percentile_threshold=0,     # min_percentile_threshold: Minimum amplitude threshold percentile for clipping.\n",
    "#                        max_percentile_threshold=30,    # max_percentile_threshold: Maximum amplitude threshold percentile for clipping. A higher value clips more of the waveform.\n",
    "#                        p=0.5),                         p: Probability of applying this augmentation.\n",
    "##     Alters the playback speed of the audio without changing its pitch\n",
    "#     TimeStretch(min_rate=0.8,       # min_rate: Minimum playback speed (as a fraction of the original). Values <1 slow down the audio.\n",
    "#                 max_rate=1.2),      # max_rate: Maximum playback speed. Values >1 speed up the audio.\n",
    "##     Changes the pitch of the audio without altering its speed\n",
    "#     PitchShift(min_semitones=-4,    # min_semitones: Minimum pitch shift in semitones (negative values lower the pitch).\n",
    "#                max_semitones=4),    # max_semitones: Maximum pitch shift in semitones (positive values raise the pitch).\n",
    "# ], p=0.8, shuffle=True)  # p: Overall probability of applying the composed augmentations\n",
    "#                          # shuffle: Randomly shuffles the order of augmentations during each application.\n",
    "\n",
    "# def preprocess_audio_with_transforms(batch):\n",
    "#     # we apply augmentations on each waveform\n",
    "#     wavs = [audio_augmentations(audio[\"array\"], sample_rate=SAMPLING_RATE) for audio in batch[\"input_values\"]]\n",
    "#     inputs = feature_extractor(wavs, sampling_rate=SAMPLING_RATE, return_tensors=\"pt\")\n",
    "\n",
    "#     output_batch = {model_input_name: inputs.get(model_input_name), \"labels\": list(batch[\"labels\"])}\n",
    "\n",
    "#     return output_batch\n",
    "\n",
    "# # Cast the audio column to the appropriate feature type and rename it\n",
    "# dataset = dataset.cast_column(\"audio\", Audio(sampling_rate=feature_extractor.sampling_rate))\n",
    "# dataset = dataset.rename_column(\"audio\", \"input_values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d26891e-89d7-4740-8fa8-e5863c7b77ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Apply the transformation to the whole dataset (Train, Validation, Test)\n",
    "# dataset = dataset.rename_column(\"audio\", \"input_values\")  # rename audio column\n",
    "# dataset.set_transform(preprocess_audio, output_all_columns=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b677338-79b6-47cc-a8dd-1338513ee0c0",
   "metadata": {},
   "source": [
    "### Dataset's split\n",
    "\n",
    "Here we use the dataset's preset split, in order to compare we other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2f05856a-ed2e-417f-a4e4-63d33f022add",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[df['mode'] == 'train']\n",
    "valid_df = df[df['mode'] == 'valid']\n",
    "test_df = df[df['mode'] == 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2cb54ca5-79aa-4d49-8ca2-4b35828dd788",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_from_df(df):\n",
    "    audio_paths = df.apply(lambda row: get_audio_path(row['video_id'], row['clip_id']), axis=1).tolist()\n",
    "    labels = df['annotation_label'].astype(int).tolist()\n",
    "    \n",
    "    return Dataset.from_dict({\n",
    "        \"audio\": audio_paths,\n",
    "        \"labels\": labels,\n",
    "    }, features=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e2c6c740-01ea-41b3-90bd-95e20e61a3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = create_dataset_from_df(train_df).rename_column(\"audio\", \"input_values\")  # rename audio column\n",
    "\n",
    "valid_dataset = create_dataset_from_df(valid_df).rename_column(\"audio\", \"input_values\") \n",
    "\n",
    "test_dataset = create_dataset_from_df(test_df).rename_column(\"audio\", \"input_values\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c3460d20-c9ce-4acf-a068-434ad2f459fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_size = len(train_dataset)\n",
    "validation_dataset_size = len(valid_dataset) \n",
    "test_dataset_size = len(test_dataset) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7faada69-484c-42c6-b241-5c05feb55027",
   "metadata": {},
   "source": [
    "Assure how the dataset is saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "94a2b75a-78a0-4180-8b3e-c47bd51ff6be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_values', 'labels'],\n",
       "    num_rows: 1284\n",
       "})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c592ef23-13d3-4308-99c0-df29246ed409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_values': {'path': '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/03bSnISJMiM/11.wav',\n",
       "  'array': array([9.15527344e-05, 1.22070312e-04, 1.22070312e-04, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00]),\n",
       "  'sampling_rate': 44100},\n",
       " 'labels': 0}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0b6999-a276-470d-ba23-2c5a01bc9c34",
   "metadata": {},
   "source": [
    "Create a unified dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ebe70cae-0b51-4159-a197-aae4c51b9a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to access datasets by their split names\n",
    "dataset = {\n",
    "    'train': train_dataset,\n",
    "    'validation': valid_dataset,\n",
    "    'test': test_dataset\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110e36e4-9da9-4323-a03c-1a9da4928862",
   "metadata": {},
   "source": [
    "Assurances again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5460db24-aba6-4ae8-814c-055ba9c1e38e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': Dataset({\n",
       "     features: ['input_values', 'labels'],\n",
       "     num_rows: 1284\n",
       " }),\n",
       " 'validation': Dataset({\n",
       "     features: ['input_values', 'labels'],\n",
       "     num_rows: 229\n",
       " }),\n",
       " 'test': Dataset({\n",
       "     features: ['input_values', 'labels'],\n",
       "     num_rows: 686\n",
       " })}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe7218f-df12-4f18-8413-71d1c62288cc",
   "metadata": {},
   "source": [
    "#### Dataset Normalization\n",
    "\n",
    "Firstly, we set normalization to `False` in order to calculate the mean and std of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "238e28de-36ae-48e6-be40-d9e79b2d8a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_extractor.do_normalize = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f77dc3b3-7368-4162-bf0b-fb1658bb58a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean = []\n",
    "# std = []\n",
    "\n",
    "# train_dataset_copy = deepcopy(train_dataset)\n",
    "# # we use the transformation w/o augmentation on the training dataset to calculate the mean + std\n",
    "# train_dataset_copy.set_transform(preprocess_audio, \n",
    "#                                  output_all_columns=False)\n",
    "# for i, (audio_input, labels) in enumerate(train_dataset_copy):\n",
    "#     if i%100 == 0:\n",
    "#         print(i)\n",
    "#     cur_mean = torch.mean(train_dataset_copy[i][audio_input])\n",
    "#     cur_std = torch.std(train_dataset_copy[i][audio_input])\n",
    "#     mean.append(cur_mean)\n",
    "#     std.append(cur_std)\n",
    "\n",
    "# del train_dataset_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c250edea-65cb-49a6-850f-28c135edb141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_extractor.mean = np.mean(mean)\n",
    "# feature_extractor.std = np.mean(std)\n",
    "\n",
    "# feature_extractor.mean = -7.9245896\n",
    "# feature_extractor.std = 5.2356324"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "11c7347a-3ac1-4fef-a8ef-b8ba7fbdf8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Mean Value: \", feature_extractor.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3900b3dd-5208-4a21-903f-45a4defbbb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"STD Value: \", feature_extractor.std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844aa383-a337-43d7-843c-954382d058d9",
   "metadata": {},
   "source": [
    "Set the normalization to `True` back again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "60930069-ee74-499b-b7ba-43ecbcc067df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_extractor.do_normalize = True # we set normalization to true back again"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9633810-aa0c-4e16-9540-6dd318a4e208",
   "metadata": {},
   "source": [
    "More assurances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "03fa2adf-8b96-4350-b58e-40156d2b6428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_values', 'labels'],\n",
       "    num_rows: 1284\n",
       "})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2b1d1bf6-eda8-465d-a64b-1fd9d2394826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_values': {'path': '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/03bSnISJMiM/11.wav',\n",
       "  'array': array([9.15527344e-05, 1.22070312e-04, 1.22070312e-04, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00]),\n",
       "  'sampling_rate': 44100},\n",
       " 'labels': 0}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1df3e2b0-809d-44bd-86c2-a47ca7bd7853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast the audio column to the appropriate feature type and rename it\n",
    "dataset[\"train\"] = dataset[\"train\"].cast_column(\"input_values\", Audio(sampling_rate=SAMPLING_RATE))\n",
    "dataset[\"validation\"] = dataset[\"validation\"].cast_column(\"input_values\", Audio(sampling_rate=SAMPLING_RATE))\n",
    "dataset[\"test\"] = dataset[\"test\"].cast_column(\"input_values\", Audio(sampling_rate=SAMPLING_RATE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5fa16e4f-0af0-42dc-bf80-2b01323a5c8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_values': {'path': '/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/dataset/CMU-MOSI/Splited/Raw_onlyAudio/03bSnISJMiM/11.wav',\n",
       "  'array': array([ 7.19678137e-05,  1.10071793e-04,  7.78241883e-06, ...,\n",
       "         -8.24081496e-08,  7.22105469e-08,  0.00000000e+00]),\n",
       "  'sampling_rate': 16000},\n",
       " 'labels': 0}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a5c71a-a2e2-48e3-a027-96dd212a8634",
   "metadata": {},
   "source": [
    "## Preprocess Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2ce3b7-4e7d-46a3-a351-3375911bb362",
   "metadata": {},
   "source": [
    "### Transform Train set (w/ Augmentation ability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "24d9194a-bd20-4dd8-af34-92b92e30a313",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"train\"].set_transform(preprocess_audio, \n",
    "                               output_all_columns=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c978c7b-a3ba-4bb3-8c0a-5f1d53ad669c",
   "metadata": {},
   "source": [
    "### Transform Validation & Test set (No Augmentations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bb5f7196-47ad-458f-a09f-b21fd0ce32aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# w/o augmentations on the validation & test set\n",
    "dataset[\"validation\"].set_transform(preprocess_audio, \n",
    "                                    output_all_columns=False)\n",
    "dataset[\"test\"].set_transform(preprocess_audio, \n",
    "                              output_all_columns=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5b02e2-b009-4fea-8c2d-5a31ed9cc6e6",
   "metadata": {},
   "source": [
    "##### Check dataset's labels and their names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "70fd75ac-898e-45d8-bdd1-5ffac58a7ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the actual labels corresponding to each label ID\n",
    "labels = dataset[\"train\"].features[\"labels\"].names\n",
    "label2id, id2label = dict(), dict()\n",
    "\n",
    "for i, label in enumerate(labels):\n",
    "    label2id[label] = str(i)\n",
    "    id2label[str(i)] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "124c501f-cb3c-4527-a99b-9805a28719d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 'Negative Sentiment', '1': 'Positive Sentiment'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a89710-ca64-426c-b654-b8b4fdaee241",
   "metadata": {},
   "source": [
    "### Compute class weights in train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8e21256e-e8df-496b-a5bd-cfd1e74fa2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.asarray(train_df['annotation_label'].astype(int).tolist())\n",
    "\n",
    "class_wts = compute_class_weight(class_weight='balanced',\n",
    "                                 classes=np.unique(train_labels),\n",
    "                                 y=train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2bfbd40a-5241-4587-b800-87e23abe3fab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.16304348, 0.87704918])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_wts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423be58f-9f28-4eba-8a6b-497f30829981",
   "metadata": {},
   "source": [
    "### Initialize base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6ae5d1bf-d9c2-4c2e-96a5-34e3681c8396",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of CvtForImageClassification were not initialized from the model checkpoint at microsoft/cvt-13 and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([1000, 384]) in the checkpoint and torch.Size([2, 384]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import CvtConfig, CvtForImageClassification\n",
    "# Load configuration from the pretrained model\n",
    "config = CvtConfig.from_pretrained(pretrained_model)\n",
    "# Update configuration with the number of labels in our dataset\n",
    "config.num_labels = 2\n",
    "config.label2id = label2id\n",
    "config.id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "# Initialize the model with the updated configuration\n",
    "model = CvtForImageClassification.from_pretrained(pretrained_model, \n",
    "                                                      config=config, \n",
    "                                                      ignore_mismatched_sizes=True\n",
    "                                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "54f5459f-952c-48a4-ae44-abd85d2349a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.init_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf1a6c2-9ac5-458b-a7f3-9e3af2c7d1ca",
   "metadata": {},
   "source": [
    "#### Check model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1bb447b3-c145-46f7-a1b8-01c33dd7e9f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CvtForImageClassification(\n",
       "  (cvt): CvtModel(\n",
       "    (encoder): CvtEncoder(\n",
       "      (stages): ModuleList(\n",
       "        (0): CvtStage(\n",
       "          (embedding): CvtEmbeddings(\n",
       "            (convolution_embeddings): CvtConvEmbeddings(\n",
       "              (projection): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(2, 2))\n",
       "              (normalization): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layers): Sequential(\n",
       "            (0): CvtLayer(\n",
       "              (attention): CvtAttention(\n",
       "                (attention): CvtSelfAttention(\n",
       "                  (convolution_projection_query): CvtSelfAttentionProjection(\n",
       "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                      (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "                      (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                  )\n",
       "                  (convolution_projection_key): CvtSelfAttentionProjection(\n",
       "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                      (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
       "                      (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                  )\n",
       "                  (convolution_projection_value): CvtSelfAttentionProjection(\n",
       "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                      (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
       "                      (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                  )\n",
       "                  (projection_query): Linear(in_features=64, out_features=64, bias=True)\n",
       "                  (projection_key): Linear(in_features=64, out_features=64, bias=True)\n",
       "                  (projection_value): Linear(in_features=64, out_features=64, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): CvtSelfOutput(\n",
       "                  (dense): Linear(in_features=64, out_features=64, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): CvtIntermediate(\n",
       "                (dense): Linear(in_features=64, out_features=256, bias=True)\n",
       "                (activation): GELU(approximate='none')\n",
       "              )\n",
       "              (output): CvtOutput(\n",
       "                (dense): Linear(in_features=256, out_features=64, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path): Identity()\n",
       "              (layernorm_before): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "              (layernorm_after): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): CvtStage(\n",
       "          (embedding): CvtEmbeddings(\n",
       "            (convolution_embeddings): CvtConvEmbeddings(\n",
       "              (projection): Conv2d(64, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "              (normalization): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layers): Sequential(\n",
       "            (0): CvtLayer(\n",
       "              (attention): CvtAttention(\n",
       "                (attention): CvtSelfAttention(\n",
       "                  (convolution_projection_query): CvtSelfAttentionProjection(\n",
       "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                      (convolution): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "                      (normalization): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                  )\n",
       "                  (convolution_projection_key): CvtSelfAttentionProjection(\n",
       "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                      (convolution): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "                      (normalization): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                  )\n",
       "                  (convolution_projection_value): CvtSelfAttentionProjection(\n",
       "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                      (convolution): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "                      (normalization): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                  )\n",
       "                  (projection_query): Linear(in_features=192, out_features=192, bias=True)\n",
       "                  (projection_key): Linear(in_features=192, out_features=192, bias=True)\n",
       "                  (projection_value): Linear(in_features=192, out_features=192, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): CvtSelfOutput(\n",
       "                  (dense): Linear(in_features=192, out_features=192, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): CvtIntermediate(\n",
       "                (dense): Linear(in_features=192, out_features=768, bias=True)\n",
       "                (activation): GELU(approximate='none')\n",
       "              )\n",
       "              (output): CvtOutput(\n",
       "                (dense): Linear(in_features=768, out_features=192, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path): Identity()\n",
       "              (layernorm_before): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "              (layernorm_after): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (1): CvtLayer(\n",
       "              (attention): CvtAttention(\n",
       "                (attention): CvtSelfAttention(\n",
       "                  (convolution_projection_query): CvtSelfAttentionProjection(\n",
       "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                      (convolution): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "                      (normalization): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                  )\n",
       "                  (convolution_projection_key): CvtSelfAttentionProjection(\n",
       "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                      (convolution): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "                      (normalization): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                  )\n",
       "                  (convolution_projection_value): CvtSelfAttentionProjection(\n",
       "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                      (convolution): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "                      (normalization): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                  )\n",
       "                  (projection_query): Linear(in_features=192, out_features=192, bias=True)\n",
       "                  (projection_key): Linear(in_features=192, out_features=192, bias=True)\n",
       "                  (projection_value): Linear(in_features=192, out_features=192, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): CvtSelfOutput(\n",
       "                  (dense): Linear(in_features=192, out_features=192, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): CvtIntermediate(\n",
       "                (dense): Linear(in_features=192, out_features=768, bias=True)\n",
       "                (activation): GELU(approximate='none')\n",
       "              )\n",
       "              (output): CvtOutput(\n",
       "                (dense): Linear(in_features=768, out_features=192, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path): Identity()\n",
       "              (layernorm_before): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "              (layernorm_after): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): CvtStage(\n",
       "          (embedding): CvtEmbeddings(\n",
       "            (convolution_embeddings): CvtConvEmbeddings(\n",
       "              (projection): Conv2d(192, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "              (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layers): Sequential(\n",
       "            (0): CvtLayer(\n",
       "              (attention): CvtAttention(\n",
       "                (attention): CvtSelfAttention(\n",
       "                  (convolution_projection_query): CvtSelfAttentionProjection(\n",
       "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                  )\n",
       "                  (convolution_projection_key): CvtSelfAttentionProjection(\n",
       "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                  )\n",
       "                  (convolution_projection_value): CvtSelfAttentionProjection(\n",
       "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                  )\n",
       "                  (projection_query): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (projection_key): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (projection_value): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): CvtSelfOutput(\n",
       "                  (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): CvtIntermediate(\n",
       "                (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "                (activation): GELU(approximate='none')\n",
       "              )\n",
       "              (output): CvtOutput(\n",
       "                (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path): CvtDropPath(p=0.02222222276031971)\n",
       "              (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "              (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (1): CvtLayer(\n",
       "              (attention): CvtAttention(\n",
       "                (attention): CvtSelfAttention(\n",
       "                  (convolution_projection_query): CvtSelfAttentionProjection(\n",
       "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                  )\n",
       "                  (convolution_projection_key): CvtSelfAttentionProjection(\n",
       "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                  )\n",
       "                  (convolution_projection_value): CvtSelfAttentionProjection(\n",
       "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                  )\n",
       "                  (projection_query): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (projection_key): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (projection_value): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): CvtSelfOutput(\n",
       "                  (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): CvtIntermediate(\n",
       "                (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "                (activation): GELU(approximate='none')\n",
       "              )\n",
       "              (output): CvtOutput(\n",
       "                (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path): CvtDropPath(p=0.02222222276031971)\n",
       "              (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "              (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (2): CvtLayer(\n",
       "              (attention): CvtAttention(\n",
       "                (attention): CvtSelfAttention(\n",
       "                  (convolution_projection_query): CvtSelfAttentionProjection(\n",
       "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                  )\n",
       "                  (convolution_projection_key): CvtSelfAttentionProjection(\n",
       "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                  )\n",
       "                  (convolution_projection_value): CvtSelfAttentionProjection(\n",
       "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                  )\n",
       "                  (projection_query): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (projection_key): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (projection_value): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): CvtSelfOutput(\n",
       "                  (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): CvtIntermediate(\n",
       "                (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "                (activation): GELU(approximate='none')\n",
       "              )\n",
       "              (output): CvtOutput(\n",
       "                (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path): CvtDropPath(p=0.02222222276031971)\n",
       "              (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "              (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (3): CvtLayer(\n",
       "              (attention): CvtAttention(\n",
       "                (attention): CvtSelfAttention(\n",
       "                  (convolution_projection_query): CvtSelfAttentionProjection(\n",
       "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                  )\n",
       "                  (convolution_projection_key): CvtSelfAttentionProjection(\n",
       "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                  )\n",
       "                  (convolution_projection_value): CvtSelfAttentionProjection(\n",
       "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                  )\n",
       "                  (projection_query): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (projection_key): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (projection_value): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): CvtSelfOutput(\n",
       "                  (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): CvtIntermediate(\n",
       "                (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "                (activation): GELU(approximate='none')\n",
       "              )\n",
       "              (output): CvtOutput(\n",
       "                (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path): CvtDropPath(p=0.02222222276031971)\n",
       "              (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "              (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (4): CvtLayer(\n",
       "              (attention): CvtAttention(\n",
       "                (attention): CvtSelfAttention(\n",
       "                  (convolution_projection_query): CvtSelfAttentionProjection(\n",
       "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                  )\n",
       "                  (convolution_projection_key): CvtSelfAttentionProjection(\n",
       "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                  )\n",
       "                  (convolution_projection_value): CvtSelfAttentionProjection(\n",
       "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                  )\n",
       "                  (projection_query): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (projection_key): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (projection_value): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): CvtSelfOutput(\n",
       "                  (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): CvtIntermediate(\n",
       "                (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "                (activation): GELU(approximate='none')\n",
       "              )\n",
       "              (output): CvtOutput(\n",
       "                (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path): CvtDropPath(p=0.02222222276031971)\n",
       "              (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "              (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (5): CvtLayer(\n",
       "              (attention): CvtAttention(\n",
       "                (attention): CvtSelfAttention(\n",
       "                  (convolution_projection_query): CvtSelfAttentionProjection(\n",
       "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                  )\n",
       "                  (convolution_projection_key): CvtSelfAttentionProjection(\n",
       "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                  )\n",
       "                  (convolution_projection_value): CvtSelfAttentionProjection(\n",
       "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                  )\n",
       "                  (projection_query): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (projection_key): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (projection_value): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): CvtSelfOutput(\n",
       "                  (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): CvtIntermediate(\n",
       "                (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "                (activation): GELU(approximate='none')\n",
       "              )\n",
       "              (output): CvtOutput(\n",
       "                (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path): CvtDropPath(p=0.02222222276031971)\n",
       "              (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "              (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (6): CvtLayer(\n",
       "              (attention): CvtAttention(\n",
       "                (attention): CvtSelfAttention(\n",
       "                  (convolution_projection_query): CvtSelfAttentionProjection(\n",
       "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                  )\n",
       "                  (convolution_projection_key): CvtSelfAttentionProjection(\n",
       "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                  )\n",
       "                  (convolution_projection_value): CvtSelfAttentionProjection(\n",
       "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                  )\n",
       "                  (projection_query): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (projection_key): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (projection_value): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): CvtSelfOutput(\n",
       "                  (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): CvtIntermediate(\n",
       "                (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "                (activation): GELU(approximate='none')\n",
       "              )\n",
       "              (output): CvtOutput(\n",
       "                (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path): CvtDropPath(p=0.02222222276031971)\n",
       "              (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "              (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (7): CvtLayer(\n",
       "              (attention): CvtAttention(\n",
       "                (attention): CvtSelfAttention(\n",
       "                  (convolution_projection_query): CvtSelfAttentionProjection(\n",
       "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                  )\n",
       "                  (convolution_projection_key): CvtSelfAttentionProjection(\n",
       "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                  )\n",
       "                  (convolution_projection_value): CvtSelfAttentionProjection(\n",
       "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                  )\n",
       "                  (projection_query): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (projection_key): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (projection_value): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): CvtSelfOutput(\n",
       "                  (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): CvtIntermediate(\n",
       "                (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "                (activation): GELU(approximate='none')\n",
       "              )\n",
       "              (output): CvtOutput(\n",
       "                (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path): CvtDropPath(p=0.02222222276031971)\n",
       "              (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "              (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (8): CvtLayer(\n",
       "              (attention): CvtAttention(\n",
       "                (attention): CvtSelfAttention(\n",
       "                  (convolution_projection_query): CvtSelfAttentionProjection(\n",
       "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                  )\n",
       "                  (convolution_projection_key): CvtSelfAttentionProjection(\n",
       "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                  )\n",
       "                  (convolution_projection_value): CvtSelfAttentionProjection(\n",
       "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                  )\n",
       "                  (projection_query): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (projection_key): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (projection_value): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): CvtSelfOutput(\n",
       "                  (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): CvtIntermediate(\n",
       "                (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "                (activation): GELU(approximate='none')\n",
       "              )\n",
       "              (output): CvtOutput(\n",
       "                (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path): CvtDropPath(p=0.02222222276031971)\n",
       "              (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "              (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (9): CvtLayer(\n",
       "              (attention): CvtAttention(\n",
       "                (attention): CvtSelfAttention(\n",
       "                  (convolution_projection_query): CvtSelfAttentionProjection(\n",
       "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                  )\n",
       "                  (convolution_projection_key): CvtSelfAttentionProjection(\n",
       "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                  )\n",
       "                  (convolution_projection_value): CvtSelfAttentionProjection(\n",
       "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                  )\n",
       "                  (projection_query): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (projection_key): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (projection_value): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): CvtSelfOutput(\n",
       "                  (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): CvtIntermediate(\n",
       "                (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "                (activation): GELU(approximate='none')\n",
       "              )\n",
       "              (output): CvtOutput(\n",
       "                (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path): CvtDropPath(p=0.02222222276031971)\n",
       "              (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "              (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layernorm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "  (classifier): Linear(in_features=384, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e45b78d9-ac65-46ec-bd89-e791b5cb6b5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model.resnet.encoder.stages[0].layers[0].shortcut.convolution.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4294cb65-74ec-4bc1-bde5-63cb88f786b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for param in model.parameters():\n",
    "#     param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b69fa6e6-f911-4adf-8e4f-9ddecb54f3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, param in model.named_parameters():\n",
    "#     if 'ASTModel' or 'classifier' or 'pre_classifier' in name:\n",
    "#         print(f'{name}: {param.requires_grad}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b717c776-b5f8-49e8-81e7-fe77ddf68b8e",
   "metadata": {},
   "source": [
    "### Modify model's classifier head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225a856b-0072-47e8-846c-0f2758d449dc",
   "metadata": {},
   "source": [
    "##### Optimal parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5222ae46-9e8b-4c1e-befc-abeadededbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 32        # [128, 64, 32]\n",
    "dropout_p = 0.1          # [0.1, 0.3]\n",
    "act_func = 'tanh'        # [ReLU, TanH, Identity]\n",
    "\n",
    "batch_size = 4           # GPU can only handle MAX batch_size=4 -> [2, 4]\n",
    "grad_accum_steps = 8     # to simulate larger batch size -> [8, 4]\n",
    "\n",
    "weight_decay = 1e-4      # [1e-4, 1e-5]\n",
    "learning_rate = 5e-5     # Need smaller lrs -> [5e-5, 1e-5, 5e-6, 1e-6]\n",
    "\n",
    "lr_scheduler_type = \"constant\"\n",
    "\n",
    "max_epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6cdc2f13-1a43-48e9-9067-2fde6d1e1d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "if act_func == 'relu':\n",
    "    activation_function = nn.ReLU()\n",
    "elif act_func == 'tanh':\n",
    "    activation_function = nn.Tanh()\n",
    "elif act_func == 'No':\n",
    "    activation_function = nn.Identity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ea5a4514-fc59-43d3-a142-2318a6967dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.classifier = nn.Sequential(\n",
    "    OrderedDict([\n",
    "        # ('flatten', nn.Flatten(start_dim=1, end_dim=-1)),\n",
    "        ('dense', nn.Linear(384, hidden_size)),\n",
    "        ('act_func', activation_function),\n",
    "        ('dropout', nn.Dropout(dropout_p)),\n",
    "        ('dense_outp', nn.Linear(hidden_size, model.config.num_labels)),\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d170a6e-7b4e-405e-bd58-74e048d12846",
   "metadata": {},
   "source": [
    "#### Check new model (w/ classifier head) architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "03fe5a21-2af4-4841-bd02-5a803988d988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CvtForImageClassification(\n",
       "  (cvt): CvtModel(\n",
       "    (encoder): CvtEncoder(\n",
       "      (stages): ModuleList(\n",
       "        (0): CvtStage(\n",
       "          (embedding): CvtEmbeddings(\n",
       "            (convolution_embeddings): CvtConvEmbeddings(\n",
       "              (projection): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(2, 2))\n",
       "              (normalization): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layers): Sequential(\n",
       "            (0): CvtLayer(\n",
       "              (attention): CvtAttention(\n",
       "                (attention): CvtSelfAttention(\n",
       "                  (convolution_projection_query): CvtSelfAttentionProjection(\n",
       "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                      (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "                      (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                  )\n",
       "                  (convolution_projection_key): CvtSelfAttentionProjection(\n",
       "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                      (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
       "                      (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                  )\n",
       "                  (convolution_projection_value): CvtSelfAttentionProjection(\n",
       "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                      (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
       "                      (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                  )\n",
       "                  (projection_query): Linear(in_features=64, out_features=64, bias=True)\n",
       "                  (projection_key): Linear(in_features=64, out_features=64, bias=True)\n",
       "                  (projection_value): Linear(in_features=64, out_features=64, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): CvtSelfOutput(\n",
       "                  (dense): Linear(in_features=64, out_features=64, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): CvtIntermediate(\n",
       "                (dense): Linear(in_features=64, out_features=256, bias=True)\n",
       "                (activation): GELU(approximate='none')\n",
       "              )\n",
       "              (output): CvtOutput(\n",
       "                (dense): Linear(in_features=256, out_features=64, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path): Identity()\n",
       "              (layernorm_before): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "              (layernorm_after): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): CvtStage(\n",
       "          (embedding): CvtEmbeddings(\n",
       "            (convolution_embeddings): CvtConvEmbeddings(\n",
       "              (projection): Conv2d(64, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "              (normalization): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layers): Sequential(\n",
       "            (0): CvtLayer(\n",
       "              (attention): CvtAttention(\n",
       "                (attention): CvtSelfAttention(\n",
       "                  (convolution_projection_query): CvtSelfAttentionProjection(\n",
       "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                      (convolution): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "                      (normalization): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                  )\n",
       "                  (convolution_projection_key): CvtSelfAttentionProjection(\n",
       "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                      (convolution): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "                      (normalization): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                  )\n",
       "                  (convolution_projection_value): CvtSelfAttentionProjection(\n",
       "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                      (convolution): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "                      (normalization): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                  )\n",
       "                  (projection_query): Linear(in_features=192, out_features=192, bias=True)\n",
       "                  (projection_key): Linear(in_features=192, out_features=192, bias=True)\n",
       "                  (projection_value): Linear(in_features=192, out_features=192, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): CvtSelfOutput(\n",
       "                  (dense): Linear(in_features=192, out_features=192, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): CvtIntermediate(\n",
       "                (dense): Linear(in_features=192, out_features=768, bias=True)\n",
       "                (activation): GELU(approximate='none')\n",
       "              )\n",
       "              (output): CvtOutput(\n",
       "                (dense): Linear(in_features=768, out_features=192, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path): Identity()\n",
       "              (layernorm_before): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "              (layernorm_after): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (1): CvtLayer(\n",
       "              (attention): CvtAttention(\n",
       "                (attention): CvtSelfAttention(\n",
       "                  (convolution_projection_query): CvtSelfAttentionProjection(\n",
       "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                      (convolution): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "                      (normalization): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                  )\n",
       "                  (convolution_projection_key): CvtSelfAttentionProjection(\n",
       "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                      (convolution): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "                      (normalization): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                  )\n",
       "                  (convolution_projection_value): CvtSelfAttentionProjection(\n",
       "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                      (convolution): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "                      (normalization): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                  )\n",
       "                  (projection_query): Linear(in_features=192, out_features=192, bias=True)\n",
       "                  (projection_key): Linear(in_features=192, out_features=192, bias=True)\n",
       "                  (projection_value): Linear(in_features=192, out_features=192, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): CvtSelfOutput(\n",
       "                  (dense): Linear(in_features=192, out_features=192, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): CvtIntermediate(\n",
       "                (dense): Linear(in_features=192, out_features=768, bias=True)\n",
       "                (activation): GELU(approximate='none')\n",
       "              )\n",
       "              (output): CvtOutput(\n",
       "                (dense): Linear(in_features=768, out_features=192, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path): Identity()\n",
       "              (layernorm_before): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "              (layernorm_after): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): CvtStage(\n",
       "          (embedding): CvtEmbeddings(\n",
       "            (convolution_embeddings): CvtConvEmbeddings(\n",
       "              (projection): Conv2d(192, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "              (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layers): Sequential(\n",
       "            (0): CvtLayer(\n",
       "              (attention): CvtAttention(\n",
       "                (attention): CvtSelfAttention(\n",
       "                  (convolution_projection_query): CvtSelfAttentionProjection(\n",
       "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                  )\n",
       "                  (convolution_projection_key): CvtSelfAttentionProjection(\n",
       "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                  )\n",
       "                  (convolution_projection_value): CvtSelfAttentionProjection(\n",
       "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                  )\n",
       "                  (projection_query): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (projection_key): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (projection_value): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): CvtSelfOutput(\n",
       "                  (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): CvtIntermediate(\n",
       "                (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "                (activation): GELU(approximate='none')\n",
       "              )\n",
       "              (output): CvtOutput(\n",
       "                (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path): CvtDropPath(p=0.02222222276031971)\n",
       "              (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "              (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (1): CvtLayer(\n",
       "              (attention): CvtAttention(\n",
       "                (attention): CvtSelfAttention(\n",
       "                  (convolution_projection_query): CvtSelfAttentionProjection(\n",
       "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                  )\n",
       "                  (convolution_projection_key): CvtSelfAttentionProjection(\n",
       "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                  )\n",
       "                  (convolution_projection_value): CvtSelfAttentionProjection(\n",
       "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                  )\n",
       "                  (projection_query): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (projection_key): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (projection_value): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): CvtSelfOutput(\n",
       "                  (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): CvtIntermediate(\n",
       "                (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "                (activation): GELU(approximate='none')\n",
       "              )\n",
       "              (output): CvtOutput(\n",
       "                (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path): CvtDropPath(p=0.02222222276031971)\n",
       "              (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "              (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (2): CvtLayer(\n",
       "              (attention): CvtAttention(\n",
       "                (attention): CvtSelfAttention(\n",
       "                  (convolution_projection_query): CvtSelfAttentionProjection(\n",
       "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                  )\n",
       "                  (convolution_projection_key): CvtSelfAttentionProjection(\n",
       "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                  )\n",
       "                  (convolution_projection_value): CvtSelfAttentionProjection(\n",
       "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                  )\n",
       "                  (projection_query): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (projection_key): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (projection_value): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): CvtSelfOutput(\n",
       "                  (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): CvtIntermediate(\n",
       "                (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "                (activation): GELU(approximate='none')\n",
       "              )\n",
       "              (output): CvtOutput(\n",
       "                (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path): CvtDropPath(p=0.02222222276031971)\n",
       "              (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "              (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (3): CvtLayer(\n",
       "              (attention): CvtAttention(\n",
       "                (attention): CvtSelfAttention(\n",
       "                  (convolution_projection_query): CvtSelfAttentionProjection(\n",
       "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                  )\n",
       "                  (convolution_projection_key): CvtSelfAttentionProjection(\n",
       "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                  )\n",
       "                  (convolution_projection_value): CvtSelfAttentionProjection(\n",
       "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                  )\n",
       "                  (projection_query): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (projection_key): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (projection_value): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): CvtSelfOutput(\n",
       "                  (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): CvtIntermediate(\n",
       "                (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "                (activation): GELU(approximate='none')\n",
       "              )\n",
       "              (output): CvtOutput(\n",
       "                (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path): CvtDropPath(p=0.02222222276031971)\n",
       "              (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "              (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (4): CvtLayer(\n",
       "              (attention): CvtAttention(\n",
       "                (attention): CvtSelfAttention(\n",
       "                  (convolution_projection_query): CvtSelfAttentionProjection(\n",
       "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                  )\n",
       "                  (convolution_projection_key): CvtSelfAttentionProjection(\n",
       "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                  )\n",
       "                  (convolution_projection_value): CvtSelfAttentionProjection(\n",
       "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                  )\n",
       "                  (projection_query): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (projection_key): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (projection_value): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): CvtSelfOutput(\n",
       "                  (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): CvtIntermediate(\n",
       "                (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "                (activation): GELU(approximate='none')\n",
       "              )\n",
       "              (output): CvtOutput(\n",
       "                (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path): CvtDropPath(p=0.02222222276031971)\n",
       "              (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "              (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (5): CvtLayer(\n",
       "              (attention): CvtAttention(\n",
       "                (attention): CvtSelfAttention(\n",
       "                  (convolution_projection_query): CvtSelfAttentionProjection(\n",
       "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                  )\n",
       "                  (convolution_projection_key): CvtSelfAttentionProjection(\n",
       "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                  )\n",
       "                  (convolution_projection_value): CvtSelfAttentionProjection(\n",
       "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                  )\n",
       "                  (projection_query): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (projection_key): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (projection_value): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): CvtSelfOutput(\n",
       "                  (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): CvtIntermediate(\n",
       "                (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "                (activation): GELU(approximate='none')\n",
       "              )\n",
       "              (output): CvtOutput(\n",
       "                (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path): CvtDropPath(p=0.02222222276031971)\n",
       "              (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "              (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (6): CvtLayer(\n",
       "              (attention): CvtAttention(\n",
       "                (attention): CvtSelfAttention(\n",
       "                  (convolution_projection_query): CvtSelfAttentionProjection(\n",
       "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                  )\n",
       "                  (convolution_projection_key): CvtSelfAttentionProjection(\n",
       "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                  )\n",
       "                  (convolution_projection_value): CvtSelfAttentionProjection(\n",
       "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                  )\n",
       "                  (projection_query): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (projection_key): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (projection_value): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): CvtSelfOutput(\n",
       "                  (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): CvtIntermediate(\n",
       "                (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "                (activation): GELU(approximate='none')\n",
       "              )\n",
       "              (output): CvtOutput(\n",
       "                (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path): CvtDropPath(p=0.02222222276031971)\n",
       "              (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "              (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (7): CvtLayer(\n",
       "              (attention): CvtAttention(\n",
       "                (attention): CvtSelfAttention(\n",
       "                  (convolution_projection_query): CvtSelfAttentionProjection(\n",
       "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                  )\n",
       "                  (convolution_projection_key): CvtSelfAttentionProjection(\n",
       "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                  )\n",
       "                  (convolution_projection_value): CvtSelfAttentionProjection(\n",
       "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                  )\n",
       "                  (projection_query): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (projection_key): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (projection_value): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): CvtSelfOutput(\n",
       "                  (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): CvtIntermediate(\n",
       "                (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "                (activation): GELU(approximate='none')\n",
       "              )\n",
       "              (output): CvtOutput(\n",
       "                (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path): CvtDropPath(p=0.02222222276031971)\n",
       "              (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "              (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (8): CvtLayer(\n",
       "              (attention): CvtAttention(\n",
       "                (attention): CvtSelfAttention(\n",
       "                  (convolution_projection_query): CvtSelfAttentionProjection(\n",
       "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                  )\n",
       "                  (convolution_projection_key): CvtSelfAttentionProjection(\n",
       "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                  )\n",
       "                  (convolution_projection_value): CvtSelfAttentionProjection(\n",
       "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                  )\n",
       "                  (projection_query): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (projection_key): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (projection_value): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): CvtSelfOutput(\n",
       "                  (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): CvtIntermediate(\n",
       "                (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "                (activation): GELU(approximate='none')\n",
       "              )\n",
       "              (output): CvtOutput(\n",
       "                (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path): CvtDropPath(p=0.02222222276031971)\n",
       "              (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "              (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (9): CvtLayer(\n",
       "              (attention): CvtAttention(\n",
       "                (attention): CvtSelfAttention(\n",
       "                  (convolution_projection_query): CvtSelfAttentionProjection(\n",
       "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                  )\n",
       "                  (convolution_projection_key): CvtSelfAttentionProjection(\n",
       "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                  )\n",
       "                  (convolution_projection_value): CvtSelfAttentionProjection(\n",
       "                    (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                      (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                      (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                    )\n",
       "                    (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "                  )\n",
       "                  (projection_query): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (projection_key): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (projection_value): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "                (output): CvtSelfOutput(\n",
       "                  (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): CvtIntermediate(\n",
       "                (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "                (activation): GELU(approximate='none')\n",
       "              )\n",
       "              (output): CvtOutput(\n",
       "                (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (drop_path): CvtDropPath(p=0.02222222276031971)\n",
       "              (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "              (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layernorm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "  (classifier): Sequential(\n",
       "    (dense): Linear(in_features=384, out_features=32, bias=True)\n",
       "    (act_func): Tanh()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (dense_outp): Linear(in_features=32, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f2e60540-e2fa-4332-85e9-8107cd6bcd79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0684, -0.0914, -0.0908,  ..., -0.1138,  0.1391,  0.1046],\n",
       "        [-0.0100, -0.0810, -0.0298,  ...,  0.2016,  0.0576,  0.0898],\n",
       "        [ 0.0567,  0.0696, -0.1893,  ..., -0.0498, -0.0143, -0.0584],\n",
       "        ...,\n",
       "        [ 0.0583, -0.0704,  0.0410,  ..., -0.0731,  0.2418,  0.0843],\n",
       "        [ 0.0881,  0.2585, -0.1582,  ..., -0.1391, -0.1213, -0.1624],\n",
       "        [ 0.0010, -0.1312, -0.1042,  ...,  0.4575,  0.0508, -0.0023]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cvt.encoder.stages[0].layers[0].attention.attention.projection_query.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7c96e8ad-bdd1-4547-b9ad-b1e8656fe945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0436,  0.0350,  0.0077,  ..., -0.0379,  0.0050,  0.0013],\n",
       "        [ 0.0311,  0.0427, -0.0118,  ..., -0.0328, -0.0313,  0.0502],\n",
       "        [-0.0464, -0.0101,  0.0014,  ..., -0.0505, -0.0313, -0.0330],\n",
       "        ...,\n",
       "        [ 0.0122, -0.0474, -0.0102,  ...,  0.0502, -0.0338,  0.0395],\n",
       "        [-0.0175,  0.0196,  0.0040,  ...,  0.0205, -0.0204,  0.0134],\n",
       "        [ 0.0139, -0.0141,  0.0153,  ..., -0.0500, -0.0088,  0.0326]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classifier.dense.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74b1483-994f-4ad9-bcdd-c851fb5036d0",
   "metadata": {},
   "source": [
    "##### Check if new model is trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dcfc88e3-831e-4266-8ba6-19c085436f65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cvt.encoder.stages.0.embedding.convolution_embeddings.projection.weight: True\n",
      "cvt.encoder.stages.0.embedding.convolution_embeddings.projection.bias: True\n",
      "cvt.encoder.stages.0.embedding.convolution_embeddings.normalization.weight: True\n",
      "cvt.encoder.stages.0.embedding.convolution_embeddings.normalization.bias: True\n",
      "cvt.encoder.stages.0.layers.0.attention.attention.convolution_projection_query.convolution_projection.convolution.weight: True\n",
      "cvt.encoder.stages.0.layers.0.attention.attention.convolution_projection_query.convolution_projection.normalization.weight: True\n",
      "cvt.encoder.stages.0.layers.0.attention.attention.convolution_projection_query.convolution_projection.normalization.bias: True\n",
      "cvt.encoder.stages.0.layers.0.attention.attention.convolution_projection_key.convolution_projection.convolution.weight: True\n",
      "cvt.encoder.stages.0.layers.0.attention.attention.convolution_projection_key.convolution_projection.normalization.weight: True\n",
      "cvt.encoder.stages.0.layers.0.attention.attention.convolution_projection_key.convolution_projection.normalization.bias: True\n",
      "cvt.encoder.stages.0.layers.0.attention.attention.convolution_projection_value.convolution_projection.convolution.weight: True\n",
      "cvt.encoder.stages.0.layers.0.attention.attention.convolution_projection_value.convolution_projection.normalization.weight: True\n",
      "cvt.encoder.stages.0.layers.0.attention.attention.convolution_projection_value.convolution_projection.normalization.bias: True\n",
      "cvt.encoder.stages.0.layers.0.attention.attention.projection_query.weight: True\n",
      "cvt.encoder.stages.0.layers.0.attention.attention.projection_query.bias: True\n",
      "cvt.encoder.stages.0.layers.0.attention.attention.projection_key.weight: True\n",
      "cvt.encoder.stages.0.layers.0.attention.attention.projection_key.bias: True\n",
      "cvt.encoder.stages.0.layers.0.attention.attention.projection_value.weight: True\n",
      "cvt.encoder.stages.0.layers.0.attention.attention.projection_value.bias: True\n",
      "cvt.encoder.stages.0.layers.0.attention.output.dense.weight: True\n",
      "cvt.encoder.stages.0.layers.0.attention.output.dense.bias: True\n",
      "cvt.encoder.stages.0.layers.0.intermediate.dense.weight: True\n",
      "cvt.encoder.stages.0.layers.0.intermediate.dense.bias: True\n",
      "cvt.encoder.stages.0.layers.0.output.dense.weight: True\n",
      "cvt.encoder.stages.0.layers.0.output.dense.bias: True\n",
      "cvt.encoder.stages.0.layers.0.layernorm_before.weight: True\n",
      "cvt.encoder.stages.0.layers.0.layernorm_before.bias: True\n",
      "cvt.encoder.stages.0.layers.0.layernorm_after.weight: True\n",
      "cvt.encoder.stages.0.layers.0.layernorm_after.bias: True\n",
      "cvt.encoder.stages.1.embedding.convolution_embeddings.projection.weight: True\n",
      "cvt.encoder.stages.1.embedding.convolution_embeddings.projection.bias: True\n",
      "cvt.encoder.stages.1.embedding.convolution_embeddings.normalization.weight: True\n",
      "cvt.encoder.stages.1.embedding.convolution_embeddings.normalization.bias: True\n",
      "cvt.encoder.stages.1.layers.0.attention.attention.convolution_projection_query.convolution_projection.convolution.weight: True\n",
      "cvt.encoder.stages.1.layers.0.attention.attention.convolution_projection_query.convolution_projection.normalization.weight: True\n",
      "cvt.encoder.stages.1.layers.0.attention.attention.convolution_projection_query.convolution_projection.normalization.bias: True\n",
      "cvt.encoder.stages.1.layers.0.attention.attention.convolution_projection_key.convolution_projection.convolution.weight: True\n",
      "cvt.encoder.stages.1.layers.0.attention.attention.convolution_projection_key.convolution_projection.normalization.weight: True\n",
      "cvt.encoder.stages.1.layers.0.attention.attention.convolution_projection_key.convolution_projection.normalization.bias: True\n",
      "cvt.encoder.stages.1.layers.0.attention.attention.convolution_projection_value.convolution_projection.convolution.weight: True\n",
      "cvt.encoder.stages.1.layers.0.attention.attention.convolution_projection_value.convolution_projection.normalization.weight: True\n",
      "cvt.encoder.stages.1.layers.0.attention.attention.convolution_projection_value.convolution_projection.normalization.bias: True\n",
      "cvt.encoder.stages.1.layers.0.attention.attention.projection_query.weight: True\n",
      "cvt.encoder.stages.1.layers.0.attention.attention.projection_query.bias: True\n",
      "cvt.encoder.stages.1.layers.0.attention.attention.projection_key.weight: True\n",
      "cvt.encoder.stages.1.layers.0.attention.attention.projection_key.bias: True\n",
      "cvt.encoder.stages.1.layers.0.attention.attention.projection_value.weight: True\n",
      "cvt.encoder.stages.1.layers.0.attention.attention.projection_value.bias: True\n",
      "cvt.encoder.stages.1.layers.0.attention.output.dense.weight: True\n",
      "cvt.encoder.stages.1.layers.0.attention.output.dense.bias: True\n",
      "cvt.encoder.stages.1.layers.0.intermediate.dense.weight: True\n",
      "cvt.encoder.stages.1.layers.0.intermediate.dense.bias: True\n",
      "cvt.encoder.stages.1.layers.0.output.dense.weight: True\n",
      "cvt.encoder.stages.1.layers.0.output.dense.bias: True\n",
      "cvt.encoder.stages.1.layers.0.layernorm_before.weight: True\n",
      "cvt.encoder.stages.1.layers.0.layernorm_before.bias: True\n",
      "cvt.encoder.stages.1.layers.0.layernorm_after.weight: True\n",
      "cvt.encoder.stages.1.layers.0.layernorm_after.bias: True\n",
      "cvt.encoder.stages.1.layers.1.attention.attention.convolution_projection_query.convolution_projection.convolution.weight: True\n",
      "cvt.encoder.stages.1.layers.1.attention.attention.convolution_projection_query.convolution_projection.normalization.weight: True\n",
      "cvt.encoder.stages.1.layers.1.attention.attention.convolution_projection_query.convolution_projection.normalization.bias: True\n",
      "cvt.encoder.stages.1.layers.1.attention.attention.convolution_projection_key.convolution_projection.convolution.weight: True\n",
      "cvt.encoder.stages.1.layers.1.attention.attention.convolution_projection_key.convolution_projection.normalization.weight: True\n",
      "cvt.encoder.stages.1.layers.1.attention.attention.convolution_projection_key.convolution_projection.normalization.bias: True\n",
      "cvt.encoder.stages.1.layers.1.attention.attention.convolution_projection_value.convolution_projection.convolution.weight: True\n",
      "cvt.encoder.stages.1.layers.1.attention.attention.convolution_projection_value.convolution_projection.normalization.weight: True\n",
      "cvt.encoder.stages.1.layers.1.attention.attention.convolution_projection_value.convolution_projection.normalization.bias: True\n",
      "cvt.encoder.stages.1.layers.1.attention.attention.projection_query.weight: True\n",
      "cvt.encoder.stages.1.layers.1.attention.attention.projection_query.bias: True\n",
      "cvt.encoder.stages.1.layers.1.attention.attention.projection_key.weight: True\n",
      "cvt.encoder.stages.1.layers.1.attention.attention.projection_key.bias: True\n",
      "cvt.encoder.stages.1.layers.1.attention.attention.projection_value.weight: True\n",
      "cvt.encoder.stages.1.layers.1.attention.attention.projection_value.bias: True\n",
      "cvt.encoder.stages.1.layers.1.attention.output.dense.weight: True\n",
      "cvt.encoder.stages.1.layers.1.attention.output.dense.bias: True\n",
      "cvt.encoder.stages.1.layers.1.intermediate.dense.weight: True\n",
      "cvt.encoder.stages.1.layers.1.intermediate.dense.bias: True\n",
      "cvt.encoder.stages.1.layers.1.output.dense.weight: True\n",
      "cvt.encoder.stages.1.layers.1.output.dense.bias: True\n",
      "cvt.encoder.stages.1.layers.1.layernorm_before.weight: True\n",
      "cvt.encoder.stages.1.layers.1.layernorm_before.bias: True\n",
      "cvt.encoder.stages.1.layers.1.layernorm_after.weight: True\n",
      "cvt.encoder.stages.1.layers.1.layernorm_after.bias: True\n",
      "cvt.encoder.stages.2.cls_token: True\n",
      "cvt.encoder.stages.2.embedding.convolution_embeddings.projection.weight: True\n",
      "cvt.encoder.stages.2.embedding.convolution_embeddings.projection.bias: True\n",
      "cvt.encoder.stages.2.embedding.convolution_embeddings.normalization.weight: True\n",
      "cvt.encoder.stages.2.embedding.convolution_embeddings.normalization.bias: True\n",
      "cvt.encoder.stages.2.layers.0.attention.attention.convolution_projection_query.convolution_projection.convolution.weight: True\n",
      "cvt.encoder.stages.2.layers.0.attention.attention.convolution_projection_query.convolution_projection.normalization.weight: True\n",
      "cvt.encoder.stages.2.layers.0.attention.attention.convolution_projection_query.convolution_projection.normalization.bias: True\n",
      "cvt.encoder.stages.2.layers.0.attention.attention.convolution_projection_key.convolution_projection.convolution.weight: True\n",
      "cvt.encoder.stages.2.layers.0.attention.attention.convolution_projection_key.convolution_projection.normalization.weight: True\n",
      "cvt.encoder.stages.2.layers.0.attention.attention.convolution_projection_key.convolution_projection.normalization.bias: True\n",
      "cvt.encoder.stages.2.layers.0.attention.attention.convolution_projection_value.convolution_projection.convolution.weight: True\n",
      "cvt.encoder.stages.2.layers.0.attention.attention.convolution_projection_value.convolution_projection.normalization.weight: True\n",
      "cvt.encoder.stages.2.layers.0.attention.attention.convolution_projection_value.convolution_projection.normalization.bias: True\n",
      "cvt.encoder.stages.2.layers.0.attention.attention.projection_query.weight: True\n",
      "cvt.encoder.stages.2.layers.0.attention.attention.projection_query.bias: True\n",
      "cvt.encoder.stages.2.layers.0.attention.attention.projection_key.weight: True\n",
      "cvt.encoder.stages.2.layers.0.attention.attention.projection_key.bias: True\n",
      "cvt.encoder.stages.2.layers.0.attention.attention.projection_value.weight: True\n",
      "cvt.encoder.stages.2.layers.0.attention.attention.projection_value.bias: True\n",
      "cvt.encoder.stages.2.layers.0.attention.output.dense.weight: True\n",
      "cvt.encoder.stages.2.layers.0.attention.output.dense.bias: True\n",
      "cvt.encoder.stages.2.layers.0.intermediate.dense.weight: True\n",
      "cvt.encoder.stages.2.layers.0.intermediate.dense.bias: True\n",
      "cvt.encoder.stages.2.layers.0.output.dense.weight: True\n",
      "cvt.encoder.stages.2.layers.0.output.dense.bias: True\n",
      "cvt.encoder.stages.2.layers.0.layernorm_before.weight: True\n",
      "cvt.encoder.stages.2.layers.0.layernorm_before.bias: True\n",
      "cvt.encoder.stages.2.layers.0.layernorm_after.weight: True\n",
      "cvt.encoder.stages.2.layers.0.layernorm_after.bias: True\n",
      "cvt.encoder.stages.2.layers.1.attention.attention.convolution_projection_query.convolution_projection.convolution.weight: True\n",
      "cvt.encoder.stages.2.layers.1.attention.attention.convolution_projection_query.convolution_projection.normalization.weight: True\n",
      "cvt.encoder.stages.2.layers.1.attention.attention.convolution_projection_query.convolution_projection.normalization.bias: True\n",
      "cvt.encoder.stages.2.layers.1.attention.attention.convolution_projection_key.convolution_projection.convolution.weight: True\n",
      "cvt.encoder.stages.2.layers.1.attention.attention.convolution_projection_key.convolution_projection.normalization.weight: True\n",
      "cvt.encoder.stages.2.layers.1.attention.attention.convolution_projection_key.convolution_projection.normalization.bias: True\n",
      "cvt.encoder.stages.2.layers.1.attention.attention.convolution_projection_value.convolution_projection.convolution.weight: True\n",
      "cvt.encoder.stages.2.layers.1.attention.attention.convolution_projection_value.convolution_projection.normalization.weight: True\n",
      "cvt.encoder.stages.2.layers.1.attention.attention.convolution_projection_value.convolution_projection.normalization.bias: True\n",
      "cvt.encoder.stages.2.layers.1.attention.attention.projection_query.weight: True\n",
      "cvt.encoder.stages.2.layers.1.attention.attention.projection_query.bias: True\n",
      "cvt.encoder.stages.2.layers.1.attention.attention.projection_key.weight: True\n",
      "cvt.encoder.stages.2.layers.1.attention.attention.projection_key.bias: True\n",
      "cvt.encoder.stages.2.layers.1.attention.attention.projection_value.weight: True\n",
      "cvt.encoder.stages.2.layers.1.attention.attention.projection_value.bias: True\n",
      "cvt.encoder.stages.2.layers.1.attention.output.dense.weight: True\n",
      "cvt.encoder.stages.2.layers.1.attention.output.dense.bias: True\n",
      "cvt.encoder.stages.2.layers.1.intermediate.dense.weight: True\n",
      "cvt.encoder.stages.2.layers.1.intermediate.dense.bias: True\n",
      "cvt.encoder.stages.2.layers.1.output.dense.weight: True\n",
      "cvt.encoder.stages.2.layers.1.output.dense.bias: True\n",
      "cvt.encoder.stages.2.layers.1.layernorm_before.weight: True\n",
      "cvt.encoder.stages.2.layers.1.layernorm_before.bias: True\n",
      "cvt.encoder.stages.2.layers.1.layernorm_after.weight: True\n",
      "cvt.encoder.stages.2.layers.1.layernorm_after.bias: True\n",
      "cvt.encoder.stages.2.layers.2.attention.attention.convolution_projection_query.convolution_projection.convolution.weight: True\n",
      "cvt.encoder.stages.2.layers.2.attention.attention.convolution_projection_query.convolution_projection.normalization.weight: True\n",
      "cvt.encoder.stages.2.layers.2.attention.attention.convolution_projection_query.convolution_projection.normalization.bias: True\n",
      "cvt.encoder.stages.2.layers.2.attention.attention.convolution_projection_key.convolution_projection.convolution.weight: True\n",
      "cvt.encoder.stages.2.layers.2.attention.attention.convolution_projection_key.convolution_projection.normalization.weight: True\n",
      "cvt.encoder.stages.2.layers.2.attention.attention.convolution_projection_key.convolution_projection.normalization.bias: True\n",
      "cvt.encoder.stages.2.layers.2.attention.attention.convolution_projection_value.convolution_projection.convolution.weight: True\n",
      "cvt.encoder.stages.2.layers.2.attention.attention.convolution_projection_value.convolution_projection.normalization.weight: True\n",
      "cvt.encoder.stages.2.layers.2.attention.attention.convolution_projection_value.convolution_projection.normalization.bias: True\n",
      "cvt.encoder.stages.2.layers.2.attention.attention.projection_query.weight: True\n",
      "cvt.encoder.stages.2.layers.2.attention.attention.projection_query.bias: True\n",
      "cvt.encoder.stages.2.layers.2.attention.attention.projection_key.weight: True\n",
      "cvt.encoder.stages.2.layers.2.attention.attention.projection_key.bias: True\n",
      "cvt.encoder.stages.2.layers.2.attention.attention.projection_value.weight: True\n",
      "cvt.encoder.stages.2.layers.2.attention.attention.projection_value.bias: True\n",
      "cvt.encoder.stages.2.layers.2.attention.output.dense.weight: True\n",
      "cvt.encoder.stages.2.layers.2.attention.output.dense.bias: True\n",
      "cvt.encoder.stages.2.layers.2.intermediate.dense.weight: True\n",
      "cvt.encoder.stages.2.layers.2.intermediate.dense.bias: True\n",
      "cvt.encoder.stages.2.layers.2.output.dense.weight: True\n",
      "cvt.encoder.stages.2.layers.2.output.dense.bias: True\n",
      "cvt.encoder.stages.2.layers.2.layernorm_before.weight: True\n",
      "cvt.encoder.stages.2.layers.2.layernorm_before.bias: True\n",
      "cvt.encoder.stages.2.layers.2.layernorm_after.weight: True\n",
      "cvt.encoder.stages.2.layers.2.layernorm_after.bias: True\n",
      "cvt.encoder.stages.2.layers.3.attention.attention.convolution_projection_query.convolution_projection.convolution.weight: True\n",
      "cvt.encoder.stages.2.layers.3.attention.attention.convolution_projection_query.convolution_projection.normalization.weight: True\n",
      "cvt.encoder.stages.2.layers.3.attention.attention.convolution_projection_query.convolution_projection.normalization.bias: True\n",
      "cvt.encoder.stages.2.layers.3.attention.attention.convolution_projection_key.convolution_projection.convolution.weight: True\n",
      "cvt.encoder.stages.2.layers.3.attention.attention.convolution_projection_key.convolution_projection.normalization.weight: True\n",
      "cvt.encoder.stages.2.layers.3.attention.attention.convolution_projection_key.convolution_projection.normalization.bias: True\n",
      "cvt.encoder.stages.2.layers.3.attention.attention.convolution_projection_value.convolution_projection.convolution.weight: True\n",
      "cvt.encoder.stages.2.layers.3.attention.attention.convolution_projection_value.convolution_projection.normalization.weight: True\n",
      "cvt.encoder.stages.2.layers.3.attention.attention.convolution_projection_value.convolution_projection.normalization.bias: True\n",
      "cvt.encoder.stages.2.layers.3.attention.attention.projection_query.weight: True\n",
      "cvt.encoder.stages.2.layers.3.attention.attention.projection_query.bias: True\n",
      "cvt.encoder.stages.2.layers.3.attention.attention.projection_key.weight: True\n",
      "cvt.encoder.stages.2.layers.3.attention.attention.projection_key.bias: True\n",
      "cvt.encoder.stages.2.layers.3.attention.attention.projection_value.weight: True\n",
      "cvt.encoder.stages.2.layers.3.attention.attention.projection_value.bias: True\n",
      "cvt.encoder.stages.2.layers.3.attention.output.dense.weight: True\n",
      "cvt.encoder.stages.2.layers.3.attention.output.dense.bias: True\n",
      "cvt.encoder.stages.2.layers.3.intermediate.dense.weight: True\n",
      "cvt.encoder.stages.2.layers.3.intermediate.dense.bias: True\n",
      "cvt.encoder.stages.2.layers.3.output.dense.weight: True\n",
      "cvt.encoder.stages.2.layers.3.output.dense.bias: True\n",
      "cvt.encoder.stages.2.layers.3.layernorm_before.weight: True\n",
      "cvt.encoder.stages.2.layers.3.layernorm_before.bias: True\n",
      "cvt.encoder.stages.2.layers.3.layernorm_after.weight: True\n",
      "cvt.encoder.stages.2.layers.3.layernorm_after.bias: True\n",
      "cvt.encoder.stages.2.layers.4.attention.attention.convolution_projection_query.convolution_projection.convolution.weight: True\n",
      "cvt.encoder.stages.2.layers.4.attention.attention.convolution_projection_query.convolution_projection.normalization.weight: True\n",
      "cvt.encoder.stages.2.layers.4.attention.attention.convolution_projection_query.convolution_projection.normalization.bias: True\n",
      "cvt.encoder.stages.2.layers.4.attention.attention.convolution_projection_key.convolution_projection.convolution.weight: True\n",
      "cvt.encoder.stages.2.layers.4.attention.attention.convolution_projection_key.convolution_projection.normalization.weight: True\n",
      "cvt.encoder.stages.2.layers.4.attention.attention.convolution_projection_key.convolution_projection.normalization.bias: True\n",
      "cvt.encoder.stages.2.layers.4.attention.attention.convolution_projection_value.convolution_projection.convolution.weight: True\n",
      "cvt.encoder.stages.2.layers.4.attention.attention.convolution_projection_value.convolution_projection.normalization.weight: True\n",
      "cvt.encoder.stages.2.layers.4.attention.attention.convolution_projection_value.convolution_projection.normalization.bias: True\n",
      "cvt.encoder.stages.2.layers.4.attention.attention.projection_query.weight: True\n",
      "cvt.encoder.stages.2.layers.4.attention.attention.projection_query.bias: True\n",
      "cvt.encoder.stages.2.layers.4.attention.attention.projection_key.weight: True\n",
      "cvt.encoder.stages.2.layers.4.attention.attention.projection_key.bias: True\n",
      "cvt.encoder.stages.2.layers.4.attention.attention.projection_value.weight: True\n",
      "cvt.encoder.stages.2.layers.4.attention.attention.projection_value.bias: True\n",
      "cvt.encoder.stages.2.layers.4.attention.output.dense.weight: True\n",
      "cvt.encoder.stages.2.layers.4.attention.output.dense.bias: True\n",
      "cvt.encoder.stages.2.layers.4.intermediate.dense.weight: True\n",
      "cvt.encoder.stages.2.layers.4.intermediate.dense.bias: True\n",
      "cvt.encoder.stages.2.layers.4.output.dense.weight: True\n",
      "cvt.encoder.stages.2.layers.4.output.dense.bias: True\n",
      "cvt.encoder.stages.2.layers.4.layernorm_before.weight: True\n",
      "cvt.encoder.stages.2.layers.4.layernorm_before.bias: True\n",
      "cvt.encoder.stages.2.layers.4.layernorm_after.weight: True\n",
      "cvt.encoder.stages.2.layers.4.layernorm_after.bias: True\n",
      "cvt.encoder.stages.2.layers.5.attention.attention.convolution_projection_query.convolution_projection.convolution.weight: True\n",
      "cvt.encoder.stages.2.layers.5.attention.attention.convolution_projection_query.convolution_projection.normalization.weight: True\n",
      "cvt.encoder.stages.2.layers.5.attention.attention.convolution_projection_query.convolution_projection.normalization.bias: True\n",
      "cvt.encoder.stages.2.layers.5.attention.attention.convolution_projection_key.convolution_projection.convolution.weight: True\n",
      "cvt.encoder.stages.2.layers.5.attention.attention.convolution_projection_key.convolution_projection.normalization.weight: True\n",
      "cvt.encoder.stages.2.layers.5.attention.attention.convolution_projection_key.convolution_projection.normalization.bias: True\n",
      "cvt.encoder.stages.2.layers.5.attention.attention.convolution_projection_value.convolution_projection.convolution.weight: True\n",
      "cvt.encoder.stages.2.layers.5.attention.attention.convolution_projection_value.convolution_projection.normalization.weight: True\n",
      "cvt.encoder.stages.2.layers.5.attention.attention.convolution_projection_value.convolution_projection.normalization.bias: True\n",
      "cvt.encoder.stages.2.layers.5.attention.attention.projection_query.weight: True\n",
      "cvt.encoder.stages.2.layers.5.attention.attention.projection_query.bias: True\n",
      "cvt.encoder.stages.2.layers.5.attention.attention.projection_key.weight: True\n",
      "cvt.encoder.stages.2.layers.5.attention.attention.projection_key.bias: True\n",
      "cvt.encoder.stages.2.layers.5.attention.attention.projection_value.weight: True\n",
      "cvt.encoder.stages.2.layers.5.attention.attention.projection_value.bias: True\n",
      "cvt.encoder.stages.2.layers.5.attention.output.dense.weight: True\n",
      "cvt.encoder.stages.2.layers.5.attention.output.dense.bias: True\n",
      "cvt.encoder.stages.2.layers.5.intermediate.dense.weight: True\n",
      "cvt.encoder.stages.2.layers.5.intermediate.dense.bias: True\n",
      "cvt.encoder.stages.2.layers.5.output.dense.weight: True\n",
      "cvt.encoder.stages.2.layers.5.output.dense.bias: True\n",
      "cvt.encoder.stages.2.layers.5.layernorm_before.weight: True\n",
      "cvt.encoder.stages.2.layers.5.layernorm_before.bias: True\n",
      "cvt.encoder.stages.2.layers.5.layernorm_after.weight: True\n",
      "cvt.encoder.stages.2.layers.5.layernorm_after.bias: True\n",
      "cvt.encoder.stages.2.layers.6.attention.attention.convolution_projection_query.convolution_projection.convolution.weight: True\n",
      "cvt.encoder.stages.2.layers.6.attention.attention.convolution_projection_query.convolution_projection.normalization.weight: True\n",
      "cvt.encoder.stages.2.layers.6.attention.attention.convolution_projection_query.convolution_projection.normalization.bias: True\n",
      "cvt.encoder.stages.2.layers.6.attention.attention.convolution_projection_key.convolution_projection.convolution.weight: True\n",
      "cvt.encoder.stages.2.layers.6.attention.attention.convolution_projection_key.convolution_projection.normalization.weight: True\n",
      "cvt.encoder.stages.2.layers.6.attention.attention.convolution_projection_key.convolution_projection.normalization.bias: True\n",
      "cvt.encoder.stages.2.layers.6.attention.attention.convolution_projection_value.convolution_projection.convolution.weight: True\n",
      "cvt.encoder.stages.2.layers.6.attention.attention.convolution_projection_value.convolution_projection.normalization.weight: True\n",
      "cvt.encoder.stages.2.layers.6.attention.attention.convolution_projection_value.convolution_projection.normalization.bias: True\n",
      "cvt.encoder.stages.2.layers.6.attention.attention.projection_query.weight: True\n",
      "cvt.encoder.stages.2.layers.6.attention.attention.projection_query.bias: True\n",
      "cvt.encoder.stages.2.layers.6.attention.attention.projection_key.weight: True\n",
      "cvt.encoder.stages.2.layers.6.attention.attention.projection_key.bias: True\n",
      "cvt.encoder.stages.2.layers.6.attention.attention.projection_value.weight: True\n",
      "cvt.encoder.stages.2.layers.6.attention.attention.projection_value.bias: True\n",
      "cvt.encoder.stages.2.layers.6.attention.output.dense.weight: True\n",
      "cvt.encoder.stages.2.layers.6.attention.output.dense.bias: True\n",
      "cvt.encoder.stages.2.layers.6.intermediate.dense.weight: True\n",
      "cvt.encoder.stages.2.layers.6.intermediate.dense.bias: True\n",
      "cvt.encoder.stages.2.layers.6.output.dense.weight: True\n",
      "cvt.encoder.stages.2.layers.6.output.dense.bias: True\n",
      "cvt.encoder.stages.2.layers.6.layernorm_before.weight: True\n",
      "cvt.encoder.stages.2.layers.6.layernorm_before.bias: True\n",
      "cvt.encoder.stages.2.layers.6.layernorm_after.weight: True\n",
      "cvt.encoder.stages.2.layers.6.layernorm_after.bias: True\n",
      "cvt.encoder.stages.2.layers.7.attention.attention.convolution_projection_query.convolution_projection.convolution.weight: True\n",
      "cvt.encoder.stages.2.layers.7.attention.attention.convolution_projection_query.convolution_projection.normalization.weight: True\n",
      "cvt.encoder.stages.2.layers.7.attention.attention.convolution_projection_query.convolution_projection.normalization.bias: True\n",
      "cvt.encoder.stages.2.layers.7.attention.attention.convolution_projection_key.convolution_projection.convolution.weight: True\n",
      "cvt.encoder.stages.2.layers.7.attention.attention.convolution_projection_key.convolution_projection.normalization.weight: True\n",
      "cvt.encoder.stages.2.layers.7.attention.attention.convolution_projection_key.convolution_projection.normalization.bias: True\n",
      "cvt.encoder.stages.2.layers.7.attention.attention.convolution_projection_value.convolution_projection.convolution.weight: True\n",
      "cvt.encoder.stages.2.layers.7.attention.attention.convolution_projection_value.convolution_projection.normalization.weight: True\n",
      "cvt.encoder.stages.2.layers.7.attention.attention.convolution_projection_value.convolution_projection.normalization.bias: True\n",
      "cvt.encoder.stages.2.layers.7.attention.attention.projection_query.weight: True\n",
      "cvt.encoder.stages.2.layers.7.attention.attention.projection_query.bias: True\n",
      "cvt.encoder.stages.2.layers.7.attention.attention.projection_key.weight: True\n",
      "cvt.encoder.stages.2.layers.7.attention.attention.projection_key.bias: True\n",
      "cvt.encoder.stages.2.layers.7.attention.attention.projection_value.weight: True\n",
      "cvt.encoder.stages.2.layers.7.attention.attention.projection_value.bias: True\n",
      "cvt.encoder.stages.2.layers.7.attention.output.dense.weight: True\n",
      "cvt.encoder.stages.2.layers.7.attention.output.dense.bias: True\n",
      "cvt.encoder.stages.2.layers.7.intermediate.dense.weight: True\n",
      "cvt.encoder.stages.2.layers.7.intermediate.dense.bias: True\n",
      "cvt.encoder.stages.2.layers.7.output.dense.weight: True\n",
      "cvt.encoder.stages.2.layers.7.output.dense.bias: True\n",
      "cvt.encoder.stages.2.layers.7.layernorm_before.weight: True\n",
      "cvt.encoder.stages.2.layers.7.layernorm_before.bias: True\n",
      "cvt.encoder.stages.2.layers.7.layernorm_after.weight: True\n",
      "cvt.encoder.stages.2.layers.7.layernorm_after.bias: True\n",
      "cvt.encoder.stages.2.layers.8.attention.attention.convolution_projection_query.convolution_projection.convolution.weight: True\n",
      "cvt.encoder.stages.2.layers.8.attention.attention.convolution_projection_query.convolution_projection.normalization.weight: True\n",
      "cvt.encoder.stages.2.layers.8.attention.attention.convolution_projection_query.convolution_projection.normalization.bias: True\n",
      "cvt.encoder.stages.2.layers.8.attention.attention.convolution_projection_key.convolution_projection.convolution.weight: True\n",
      "cvt.encoder.stages.2.layers.8.attention.attention.convolution_projection_key.convolution_projection.normalization.weight: True\n",
      "cvt.encoder.stages.2.layers.8.attention.attention.convolution_projection_key.convolution_projection.normalization.bias: True\n",
      "cvt.encoder.stages.2.layers.8.attention.attention.convolution_projection_value.convolution_projection.convolution.weight: True\n",
      "cvt.encoder.stages.2.layers.8.attention.attention.convolution_projection_value.convolution_projection.normalization.weight: True\n",
      "cvt.encoder.stages.2.layers.8.attention.attention.convolution_projection_value.convolution_projection.normalization.bias: True\n",
      "cvt.encoder.stages.2.layers.8.attention.attention.projection_query.weight: True\n",
      "cvt.encoder.stages.2.layers.8.attention.attention.projection_query.bias: True\n",
      "cvt.encoder.stages.2.layers.8.attention.attention.projection_key.weight: True\n",
      "cvt.encoder.stages.2.layers.8.attention.attention.projection_key.bias: True\n",
      "cvt.encoder.stages.2.layers.8.attention.attention.projection_value.weight: True\n",
      "cvt.encoder.stages.2.layers.8.attention.attention.projection_value.bias: True\n",
      "cvt.encoder.stages.2.layers.8.attention.output.dense.weight: True\n",
      "cvt.encoder.stages.2.layers.8.attention.output.dense.bias: True\n",
      "cvt.encoder.stages.2.layers.8.intermediate.dense.weight: True\n",
      "cvt.encoder.stages.2.layers.8.intermediate.dense.bias: True\n",
      "cvt.encoder.stages.2.layers.8.output.dense.weight: True\n",
      "cvt.encoder.stages.2.layers.8.output.dense.bias: True\n",
      "cvt.encoder.stages.2.layers.8.layernorm_before.weight: True\n",
      "cvt.encoder.stages.2.layers.8.layernorm_before.bias: True\n",
      "cvt.encoder.stages.2.layers.8.layernorm_after.weight: True\n",
      "cvt.encoder.stages.2.layers.8.layernorm_after.bias: True\n",
      "cvt.encoder.stages.2.layers.9.attention.attention.convolution_projection_query.convolution_projection.convolution.weight: True\n",
      "cvt.encoder.stages.2.layers.9.attention.attention.convolution_projection_query.convolution_projection.normalization.weight: True\n",
      "cvt.encoder.stages.2.layers.9.attention.attention.convolution_projection_query.convolution_projection.normalization.bias: True\n",
      "cvt.encoder.stages.2.layers.9.attention.attention.convolution_projection_key.convolution_projection.convolution.weight: True\n",
      "cvt.encoder.stages.2.layers.9.attention.attention.convolution_projection_key.convolution_projection.normalization.weight: True\n",
      "cvt.encoder.stages.2.layers.9.attention.attention.convolution_projection_key.convolution_projection.normalization.bias: True\n",
      "cvt.encoder.stages.2.layers.9.attention.attention.convolution_projection_value.convolution_projection.convolution.weight: True\n",
      "cvt.encoder.stages.2.layers.9.attention.attention.convolution_projection_value.convolution_projection.normalization.weight: True\n",
      "cvt.encoder.stages.2.layers.9.attention.attention.convolution_projection_value.convolution_projection.normalization.bias: True\n",
      "cvt.encoder.stages.2.layers.9.attention.attention.projection_query.weight: True\n",
      "cvt.encoder.stages.2.layers.9.attention.attention.projection_query.bias: True\n",
      "cvt.encoder.stages.2.layers.9.attention.attention.projection_key.weight: True\n",
      "cvt.encoder.stages.2.layers.9.attention.attention.projection_key.bias: True\n",
      "cvt.encoder.stages.2.layers.9.attention.attention.projection_value.weight: True\n",
      "cvt.encoder.stages.2.layers.9.attention.attention.projection_value.bias: True\n",
      "cvt.encoder.stages.2.layers.9.attention.output.dense.weight: True\n",
      "cvt.encoder.stages.2.layers.9.attention.output.dense.bias: True\n",
      "cvt.encoder.stages.2.layers.9.intermediate.dense.weight: True\n",
      "cvt.encoder.stages.2.layers.9.intermediate.dense.bias: True\n",
      "cvt.encoder.stages.2.layers.9.output.dense.weight: True\n",
      "cvt.encoder.stages.2.layers.9.output.dense.bias: True\n",
      "cvt.encoder.stages.2.layers.9.layernorm_before.weight: True\n",
      "cvt.encoder.stages.2.layers.9.layernorm_before.bias: True\n",
      "cvt.encoder.stages.2.layers.9.layernorm_after.weight: True\n",
      "cvt.encoder.stages.2.layers.9.layernorm_after.bias: True\n",
      "layernorm.weight: True\n",
      "layernorm.bias: True\n",
      "classifier.dense.weight: True\n",
      "classifier.dense.bias: True\n",
      "classifier.dense_outp.weight: True\n",
      "classifier.dense_outp.bias: True\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "        if 'cvt' or 'classifier' or 'pre_classifier' in name:\n",
    "            print(f'{name}: {param.requires_grad}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0de600-45b0-4208-9a36-3975ead8270d",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d78bc4c1-c6c6-4251-b621-cfe58486d5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_args = TrainingArguments(\n",
    "#     output_dir=\"./runs/ast_classifier\",\n",
    "#     logging_dir=\"./logs/ast_classifier\",\n",
    "#     report_to=\"tensorboard\",\n",
    "#     learning_rate=1e-2,                   \n",
    "#     push_to_hub=False,\n",
    "#     num_train_epochs=2,                   \n",
    "#     per_device_train_batch_size=batch_size, \n",
    "#     gradient_accumulation_steps=grad_accum_steps,    \n",
    "#     # per_device_eval_batch_size=1, \n",
    "#     eval_strategy=\"no\",                       \n",
    "#     save_strategy=\"no\",\n",
    "#     # eval_steps=1,\n",
    "#     # save_steps=1,\n",
    "#     # weight_decay=weight_decay,\n",
    "#     # load_best_model_at_end=True,\n",
    "#     # eval_accumulation_steps=64,\n",
    "#     # metric_for_best_model='loss',\n",
    "#     remove_unused_columns=False,\n",
    "#     logging_strategy=\"no\",\n",
    "#     eval_accumulation_steps=8,\n",
    "#     # logging_steps = 20,  # Logs every epoch\n",
    "#     lr_scheduler_type=\"constant\",  # Ensures no decay in learning rate\n",
    "#     # fp16=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f452b6c2-ceb5-4a38-b46b-00e5a84a4f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=dataset[\"train\"],\n",
    "#     eval_dataset=dataset[\"validation\"],\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8d87daca-f710-42e3-8fd2-cebff6951b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8719f6a5-2923-44a1-9b3c-9de62e85d4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.classifier.dense.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "700881d5-916b-4486-a2b7-1a4867fc889a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for param in model.parameters():\n",
    "#     param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "63ed2c46-f751-48cf-8f2c-d642ad360374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, param in model.named_parameters():\n",
    "#     if 'ASTModel' or 'classifier' or 'pre_classifier' in name:\n",
    "#         print(f'{name}: {param.requires_grad}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5464d705-cd7e-4f16-af79-5179b41d77c9",
   "metadata": {},
   "source": [
    "### Metrics calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1e1b783f-2609-4be7-a326-8ccf8da713dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Fix metrics calculation\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "recall = evaluate.load(\"recall\")\n",
    "precision = evaluate.load(\"precision\")\n",
    "f1 = evaluate.load(\"f1\")\n",
    "AVERAGE = \"binary\"    # Default behavior for binary classification\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits = eval_pred.predictions\n",
    "    # print(logits)\n",
    "    predictions = np.argmax(logits, axis=1)\n",
    "    metrics = {}\n",
    "    metrics.update(accuracy.compute(predictions=predictions, references=eval_pred.label_ids))\n",
    "    metrics.update(precision.compute(predictions=predictions, references=eval_pred.label_ids, average=AVERAGE))\n",
    "    metrics.update(recall.compute(predictions=predictions, references=eval_pred.label_ids, average=AVERAGE))\n",
    "    metrics.update(f1.compute(predictions=predictions, references=eval_pred.label_ids, average=AVERAGE))\n",
    "    metrics['weighted_f1'] = f1.compute(predictions=predictions, references=eval_pred.label_ids, average=\"weighted\")['f1']\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5e9963-5320-467b-b60a-6979270f7d7a",
   "metadata": {},
   "source": [
    "### Training arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "acc27dcb-0191-41d0-8c62-a1460aa1fe3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_for_best_model = \"loss\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a80f04e5-af21-422e-96ea-6758c635df4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_accumulation_steps = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3382fd55-04ac-406f-afa2-2196c4a5ccd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from torch.optim.lr_scheduler import LambdaLR\n",
    "# from transformers import Trainer, TrainingArguments\n",
    "# from torch.optim import AdamW\n",
    "\n",
    "# # Optimizer\n",
    "# optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# # Define steps per epoch\n",
    "# steps_per_epoch = train_dataset_size // (batch_size * grad_accum_steps)\n",
    "\n",
    "# # Lambda function for learning rate schedule\n",
    "# def lr_lambda(current_step):\n",
    "#     epoch = current_step // steps_per_epoch\n",
    "\n",
    "#     if lr_scheduler_type == \"constant\":\n",
    "#         return 1.0\n",
    "#     else:\n",
    "#         if epoch < 5:\n",
    "#             return 1.0  # Keep learning rate constant for the first 5 epochs\n",
    "#         else:\n",
    "#             return 0.5 ** (((epoch - 5) - 1) // 2)  # Halve every 2 epochs after epoch 5\n",
    "\n",
    "# # Scheduler\n",
    "# scheduler = LambdaLR(optimizer, lr_lambda=lr_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b84e2fe9-21bb-4f15-bedb-092e7c15e693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure training run with TrainingArguments class\n",
    "## TODO: See what happends with loss function\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./runs/cvt_classifier\",\n",
    "    logging_dir=\"./logs/cvt_classifier\",\n",
    "    report_to=\"tensorboard\",\n",
    "    learning_rate=learning_rate,                   \n",
    "    push_to_hub=False,\n",
    "    num_train_epochs=max_epochs,                   \n",
    "    per_device_train_batch_size=batch_size, \n",
    "    gradient_accumulation_steps=grad_accum_steps,    \n",
    "    # per_device_eval_batch_size=1, \n",
    "    eval_strategy=\"epoch\",                       \n",
    "    save_strategy=\"no\",\n",
    "    eval_steps=1,\n",
    "    save_steps=1,\n",
    "    weight_decay=weight_decay,\n",
    "    load_best_model_at_end=False,\n",
    "    # eval_accumulation_steps=64,\n",
    "    # metric_for_best_model=metric_for_best_model,\n",
    "    remove_unused_columns=False,\n",
    "    logging_strategy=\"epoch\",\n",
    "    eval_accumulation_steps=eval_accumulation_steps,\n",
    "    # logging_steps = 20,  # Logs every epoch\n",
    "    lr_scheduler_type=\"constant\",  # Ensures no decay in learning rate\n",
    "    # fp16=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a52e761-a16d-4252-9b1f-c08e2c7ae210",
   "metadata": {},
   "source": [
    "\"Hack\" the `Trainer` in order to insert:\n",
    "- Class weights (since the train set is imbalanced)\n",
    "- Assure that Cross Entropy is used as the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8711b67e-d34c-41d9-ac76-ae0d8b455b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        \n",
    "        # forward pass\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get('logits')\n",
    "        \n",
    "        # compute custom loss\n",
    "        weights  = torch.tensor(class_wts, dtype=torch.float).to(device)\n",
    "        \n",
    "        loss_fct = nn.CrossEntropyLoss(weight=weights)\n",
    "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "        \n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4ccc90-9c22-4c3d-b815-ce5e4f39bd4b",
   "metadata": {},
   "source": [
    "Custom callback to track the best model's epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2b09836d-3e3d-45f2-beb5-077db1043859",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BestModelEpochCallback(TrainerCallback):\n",
    "    def __init__(self):\n",
    "        self.best_loss = float(\"inf\")\n",
    "        self.best_acc = 0.0\n",
    "        self.best_epoch = None\n",
    "        self.training_metrics = []  # Track training loss at the end of each epoch\n",
    "        self.eval_metrics = []      # Track evaluation loss at the end of each epoch\n",
    "\n",
    "    def on_evaluate(self, args, state, control, metrics=None, **kwargs):\n",
    "        if metrics is not None:\n",
    "            if metric_for_best_model == \"loss\":\n",
    "                if \"eval_loss\" in metrics:\n",
    "                    self.eval_metrics.append((state.epoch, metrics[\"eval_loss\"]))\n",
    "                    current_loss = metrics[\"eval_loss\"]\n",
    "                    if current_loss < self.best_loss:\n",
    "                        self.best_loss = current_loss\n",
    "                        self.best_epoch = state.epoch\n",
    "            elif metric_for_best_model == \"accuracy\":\n",
    "                if \"eval_loss\" in metrics:\n",
    "                    self.eval_metrics.append((state.epoch, metrics[\"eval_loss\"]))\n",
    "                    current_acc = metrics[\"eval_accuracy\"]\n",
    "                    if current_acc > self.best_acc:\n",
    "                        self.best_acc = current_acc\n",
    "                        self.best_epoch = state.epoch\n",
    "\n",
    "    def on_epoch_end(self, args, state, control, **kwargs):\n",
    "        # optimizer = kwargs.get(\"optimizer\")\n",
    "        # print(f\"Learning rate: {optimizer.param_groups[0]['lr']}\")\n",
    "        # Log training loss at the end of the epoch\n",
    "        if state.log_history:\n",
    "            # Extract the last logged loss\n",
    "            for log in reversed(state.log_history):\n",
    "                if \"loss\" in log:\n",
    "                    self.training_metrics.append((state.epoch, log[\"loss\"]))\n",
    "                    break\n",
    "\n",
    "    # def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "    #     if logs and \"loss\" in logs:\n",
    "    #         self.training_metrics.append((state.epoch, logs[\"loss\"]))\n",
    "\n",
    "best_model_callback = BestModelEpochCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3e4afed4-a0e7-42cd-acff-612431736603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the trainer\n",
    "trainer_new = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"validation\"],\n",
    "    callbacks=[best_model_callback],  # Not used during CV, only here to find optimal epochs\n",
    "    compute_metrics=compute_metrics,  # Use the metrics function from above\n",
    "    # optimizers=(optimizer, scheduler),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9daa3967",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\".*Converting to np.float32.*\")\n",
    "warnings.filterwarnings(\"ignore\", message=\".*is ill-defined.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "24c7f2da-ca41-4256-8885-3ee92f72ed20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='80' max='80' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [80/80 03:50, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Weighted F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.696300</td>\n",
       "      <td>0.707759</td>\n",
       "      <td>0.550218</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.744526</td>\n",
       "      <td>0.664495</td>\n",
       "      <td>0.525244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.686100</td>\n",
       "      <td>0.722633</td>\n",
       "      <td>0.467249</td>\n",
       "      <td>0.566372</td>\n",
       "      <td>0.467153</td>\n",
       "      <td>0.512000</td>\n",
       "      <td>0.472412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=80, training_loss=0.6911790847778321, metrics={'train_runtime': 234.006, 'train_samples_per_second': 10.974, 'train_steps_per_second': 0.342, 'total_flos': 4.537485049724928e+16, 'train_loss': 0.6911790847778321, 'epoch': 1.9937694704049844})"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_new.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2edb59-8872-40f7-a865-e1ab3984e971",
   "metadata": {},
   "source": [
    "Assert that the model did get trained - Weights changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "84ab702d-f0f9-424a-a7fb-02bf4598d8b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0679, -0.0910, -0.0906,  ..., -0.1141,  0.1387,  0.1046],\n",
       "        [-0.0093, -0.0808, -0.0300,  ...,  0.2012,  0.0574,  0.0899],\n",
       "        [ 0.0561,  0.0691, -0.1893,  ..., -0.0499, -0.0134, -0.0584],\n",
       "        ...,\n",
       "        [ 0.0585, -0.0701,  0.0411,  ..., -0.0731,  0.2418,  0.0843],\n",
       "        [ 0.0872,  0.2579, -0.1588,  ..., -0.1390, -0.1210, -0.1622],\n",
       "        [ 0.0008, -0.1315, -0.1041,  ...,  0.4577,  0.0509, -0.0024]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cvt.encoder.stages[0].layers[0].attention.attention.projection_query.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f1b3b119-4d96-4040-a0f3-8a07ffc25423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0435,  0.0350,  0.0079,  ..., -0.0373,  0.0045,  0.0011],\n",
       "        [ 0.0312,  0.0424, -0.0117,  ..., -0.0333, -0.0310,  0.0500],\n",
       "        [-0.0464, -0.0100,  0.0010,  ..., -0.0510, -0.0311, -0.0330],\n",
       "        ...,\n",
       "        [ 0.0121, -0.0474, -0.0096,  ...,  0.0502, -0.0334,  0.0392],\n",
       "        [-0.0177,  0.0194,  0.0037,  ...,  0.0202, -0.0201,  0.0132],\n",
       "        [ 0.0139, -0.0138,  0.0152,  ..., -0.0503, -0.0085,  0.0326]],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classifier.dense.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ef317b-fd7d-47a2-837b-c94f0a72c740",
   "metadata": {},
   "source": [
    "### Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6e50630e-2402-4939-b921-0d4e1e1e543b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extract metrics\n",
    "epochs, training_losses = zip(*best_model_callback.training_metrics)\n",
    "eval_epochs, eval_losses = zip(*best_model_callback.eval_metrics)\n",
    "\n",
    "# Plot learning curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, training_losses, \n",
    "         label=\"Training Loss\")\n",
    "plt.plot(eval_epochs, eval_losses, \n",
    "         label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.xticks(range(1, max_epochs+1))\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8aabef6-61f4-4e78-b483-b4d3f490df00",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "17d81acf-dcf7-42dd-a211-4ff9c819854a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_args = TrainingArguments(\n",
    "    output_dir=\"./runs/cvt_classifier\",\n",
    "    report_to=\"tensorboard\",\n",
    "    do_train=False,\n",
    "    do_predict=True,\n",
    "    remove_unused_columns=False,\n",
    "    per_device_eval_batch_size=batch_size, \n",
    "    gradient_accumulation_steps=grad_accum_steps,\n",
    "    eval_accumulation_steps=eval_accumulation_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4a828773-c586-43f6-a008-2c64004b4e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inferer = Trainer(\n",
    "    model=trainer_new.model, \n",
    "    args=test_args, \n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7121c972-57e2-4863-889c-75ecce199ab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics = inferer.predict(dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f7eac8-6438-48fc-959e-3dd649d96e3e",
   "metadata": {},
   "source": [
    "## Test data metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2c1d5137-2dcf-4bcb-ad29-d1ebbddd2a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg. test loss: 0.6851951479911804\n"
     ]
    }
   ],
   "source": [
    "print(f\"Avg. test loss: {metrics.metrics['test_loss']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a1d4f2f5-cce4-4b23-87ba-17f4bf45da6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = np.argmax(metrics.predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "02d9c14c-bfcc-43e7-a971-a8fd793c5226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5885    0.6755    0.6290       379\n",
      "           1     0.5100    0.4169    0.4588       307\n",
      "\n",
      "    accuracy                         0.5598       686\n",
      "   macro avg     0.5492    0.5462    0.5439       686\n",
      "weighted avg     0.5534    0.5598    0.5528       686\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(metrics.label_ids, predicted_labels, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8d58b2-0f0c-4e40-a0f9-ef6a188cd45a",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6fb0da22-8841-411e-bf40-b5196f566da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = pd.crosstab(metrics.label_ids, predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "435f98a1-8fb8-42d2-9310-2032dfd29f61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set the size of the figure\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "# Create a heatmap from the confusion matrix\n",
    "sns.heatmap(confusion_matrix,\n",
    "            annot=True,\n",
    "            fmt='d',\n",
    "            cmap='Blues',\n",
    "            cbar=True)\n",
    "\n",
    "# Set titles and labels\n",
    "plt.title('Fine-Tuned CvT (Optimal Parameters) Confusion Matrix')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4182572-3aec-4e6d-9e6b-262368fecfd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My Enviroment",
   "language": "python",
   "name": "my_enviroment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
