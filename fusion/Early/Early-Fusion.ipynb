{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a4c3bdd-9fbf-4954-8552-0d55f297bc1d",
   "metadata": {
    "executionInfo": {
     "elapsed": 41297,
     "status": "ok",
     "timestamp": 1740571506614,
     "user": {
      "displayName": "Kyparissis Kyparissis",
      "userId": "18280909670100413703"
     },
     "user_tz": -120
    },
    "id": "4a4c3bdd-9fbf-4954-8552-0d55f297bc1d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-27 00:55:16.061405: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1740610516.083284  557354 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1740610516.090011  557354 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-27 00:55:16.112684: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import Trainer, TrainingArguments\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3bb3e62-809e-4df5-86bb-a5c2cb07e75b",
   "metadata": {
    "executionInfo": {
     "elapsed": 1046,
     "status": "ok",
     "timestamp": 1740571915175,
     "user": {
      "displayName": "Kyparissis Kyparissis",
      "userId": "18280909670100413703"
     },
     "user_tz": -120
    },
    "id": "a3bb3e62-809e-4df5-86bb-a5c2cb07e75b"
   },
   "outputs": [],
   "source": [
    "# Load the CSV files into DataFrames\n",
    "df1 = pd.read_csv('all_text_features.csv')\n",
    "df2 = pd.read_csv('all_audio_features.csv')\n",
    "df3 = pd.read_csv('all_video_features.csv')\n",
    "\n",
    "# Merge the DataFrames on 'row_id' and 'clip_id'\n",
    "text_audio_merged_df = pd.merge(df1, df2, on=['video_id', 'clip_id', 'mode', 'annotation_label'], how='inner')\n",
    "audio_video_merged_df = pd.merge(df3, df2, on=['video_id', 'clip_id', 'mode', 'annotation_label'], how='inner')\n",
    "text_video_merged_df = pd.merge(df3, df1, on=['video_id', 'clip_id', 'mode', 'annotation_label'], how='inner')\n",
    "all_merged_df = pd.merge(text_audio_merged_df, df3, on=['video_id', 'clip_id', 'mode', 'annotation_label'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7cbde4d-c36c-4327-babc-e8ac2f142f32",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "executionInfo": {
     "elapsed": 164,
     "status": "ok",
     "timestamp": 1740571916663,
     "user": {
      "displayName": "Kyparissis Kyparissis",
      "userId": "18280909670100413703"
     },
     "user_tz": -120
    },
    "id": "d7cbde4d-c36c-4327-babc-e8ac2f142f32",
    "outputId": "a102c440-87fa-4531-e523-00d9bf6e205f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>clip_id</th>\n",
       "      <th>mode</th>\n",
       "      <th>annotation_label</th>\n",
       "      <th>text_feature_0</th>\n",
       "      <th>text_feature_1</th>\n",
       "      <th>text_feature_2</th>\n",
       "      <th>text_feature_3</th>\n",
       "      <th>text_feature_4</th>\n",
       "      <th>text_feature_5</th>\n",
       "      <th>...</th>\n",
       "      <th>video_feature_758</th>\n",
       "      <th>video_feature_759</th>\n",
       "      <th>video_feature_760</th>\n",
       "      <th>video_feature_761</th>\n",
       "      <th>video_feature_762</th>\n",
       "      <th>video_feature_763</th>\n",
       "      <th>video_feature_764</th>\n",
       "      <th>video_feature_765</th>\n",
       "      <th>video_feature_766</th>\n",
       "      <th>video_feature_767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>11</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.270479</td>\n",
       "      <td>0.996873</td>\n",
       "      <td>-0.641382</td>\n",
       "      <td>-0.476987</td>\n",
       "      <td>0.186320</td>\n",
       "      <td>-0.479807</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.078334</td>\n",
       "      <td>-0.212412</td>\n",
       "      <td>-0.014572</td>\n",
       "      <td>-0.375293</td>\n",
       "      <td>0.837917</td>\n",
       "      <td>0.062687</td>\n",
       "      <td>-0.597331</td>\n",
       "      <td>-0.259640</td>\n",
       "      <td>-1.898719</td>\n",
       "      <td>-1.712027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>10</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004698</td>\n",
       "      <td>0.782621</td>\n",
       "      <td>-0.380408</td>\n",
       "      <td>-0.298272</td>\n",
       "      <td>0.170435</td>\n",
       "      <td>-1.098768</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.147198</td>\n",
       "      <td>0.130909</td>\n",
       "      <td>-0.206098</td>\n",
       "      <td>0.206220</td>\n",
       "      <td>0.948254</td>\n",
       "      <td>0.354763</td>\n",
       "      <td>-0.502355</td>\n",
       "      <td>-0.444589</td>\n",
       "      <td>-1.971562</td>\n",
       "      <td>-1.491572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>13</td>\n",
       "      <td>train</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.173633</td>\n",
       "      <td>0.156800</td>\n",
       "      <td>-0.037979</td>\n",
       "      <td>-0.099305</td>\n",
       "      <td>0.478109</td>\n",
       "      <td>0.384305</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.516917</td>\n",
       "      <td>-0.099885</td>\n",
       "      <td>0.251831</td>\n",
       "      <td>-0.179767</td>\n",
       "      <td>0.371510</td>\n",
       "      <td>0.690991</td>\n",
       "      <td>-0.825537</td>\n",
       "      <td>-0.097008</td>\n",
       "      <td>-1.760048</td>\n",
       "      <td>-0.853008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>12</td>\n",
       "      <td>train</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.218314</td>\n",
       "      <td>0.158072</td>\n",
       "      <td>0.014531</td>\n",
       "      <td>-0.098467</td>\n",
       "      <td>0.774070</td>\n",
       "      <td>0.201158</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.019300</td>\n",
       "      <td>0.115281</td>\n",
       "      <td>-0.440721</td>\n",
       "      <td>0.511699</td>\n",
       "      <td>0.359596</td>\n",
       "      <td>0.243479</td>\n",
       "      <td>-0.542120</td>\n",
       "      <td>-0.339106</td>\n",
       "      <td>-1.352056</td>\n",
       "      <td>-1.143122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.010284</td>\n",
       "      <td>1.077508</td>\n",
       "      <td>-0.288741</td>\n",
       "      <td>-0.307522</td>\n",
       "      <td>0.177738</td>\n",
       "      <td>-1.068847</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.380751</td>\n",
       "      <td>0.155880</td>\n",
       "      <td>-0.150362</td>\n",
       "      <td>0.494003</td>\n",
       "      <td>-0.353426</td>\n",
       "      <td>0.795431</td>\n",
       "      <td>-0.958967</td>\n",
       "      <td>-0.645879</td>\n",
       "      <td>-1.676601</td>\n",
       "      <td>-0.627469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2194</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>30</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.049752</td>\n",
       "      <td>0.957713</td>\n",
       "      <td>-0.359034</td>\n",
       "      <td>-0.270461</td>\n",
       "      <td>0.229189</td>\n",
       "      <td>-0.694572</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.228938</td>\n",
       "      <td>0.320100</td>\n",
       "      <td>-0.162853</td>\n",
       "      <td>0.810133</td>\n",
       "      <td>0.515550</td>\n",
       "      <td>-0.156523</td>\n",
       "      <td>0.345616</td>\n",
       "      <td>-0.714201</td>\n",
       "      <td>-0.877672</td>\n",
       "      <td>-0.311081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2195</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>35</td>\n",
       "      <td>test</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.280185</td>\n",
       "      <td>0.325935</td>\n",
       "      <td>0.116856</td>\n",
       "      <td>-0.097485</td>\n",
       "      <td>0.463279</td>\n",
       "      <td>0.388187</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.746198</td>\n",
       "      <td>0.073125</td>\n",
       "      <td>-0.412568</td>\n",
       "      <td>0.249044</td>\n",
       "      <td>-0.190793</td>\n",
       "      <td>-0.707994</td>\n",
       "      <td>0.889685</td>\n",
       "      <td>-0.609933</td>\n",
       "      <td>-0.753124</td>\n",
       "      <td>-0.484004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>34</td>\n",
       "      <td>test</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.269441</td>\n",
       "      <td>0.182711</td>\n",
       "      <td>0.016000</td>\n",
       "      <td>-0.244879</td>\n",
       "      <td>0.844845</td>\n",
       "      <td>0.338559</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.035848</td>\n",
       "      <td>0.008247</td>\n",
       "      <td>-0.900263</td>\n",
       "      <td>0.018754</td>\n",
       "      <td>0.038172</td>\n",
       "      <td>-0.237460</td>\n",
       "      <td>0.659862</td>\n",
       "      <td>-1.022472</td>\n",
       "      <td>-0.690134</td>\n",
       "      <td>-0.631602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2197</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>33</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.085537</td>\n",
       "      <td>0.797328</td>\n",
       "      <td>-0.684733</td>\n",
       "      <td>-0.682357</td>\n",
       "      <td>0.026557</td>\n",
       "      <td>-1.482874</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.822525</td>\n",
       "      <td>0.197105</td>\n",
       "      <td>-1.279548</td>\n",
       "      <td>1.058336</td>\n",
       "      <td>0.070369</td>\n",
       "      <td>-0.570976</td>\n",
       "      <td>0.977215</td>\n",
       "      <td>-0.469761</td>\n",
       "      <td>-0.729410</td>\n",
       "      <td>-0.640767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2198</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>32</td>\n",
       "      <td>test</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.216998</td>\n",
       "      <td>0.612123</td>\n",
       "      <td>0.273865</td>\n",
       "      <td>-0.095879</td>\n",
       "      <td>0.475912</td>\n",
       "      <td>0.547925</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.563939</td>\n",
       "      <td>0.216366</td>\n",
       "      <td>-0.634186</td>\n",
       "      <td>0.500019</td>\n",
       "      <td>-0.275324</td>\n",
       "      <td>-0.410418</td>\n",
       "      <td>0.787863</td>\n",
       "      <td>-1.011445</td>\n",
       "      <td>-0.928194</td>\n",
       "      <td>-0.203594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2199 rows × 1796 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         video_id  clip_id   mode  annotation_label  text_feature_0  \\\n",
       "0     03bSnISJMiM       11  train               0.0        0.270479   \n",
       "1     03bSnISJMiM       10  train               0.0        0.004698   \n",
       "2     03bSnISJMiM       13  train               1.0       -0.173633   \n",
       "3     03bSnISJMiM       12  train               1.0       -0.218314   \n",
       "4     03bSnISJMiM        1  train               1.0        0.010284   \n",
       "...           ...      ...    ...               ...             ...   \n",
       "2194  zhpQhgha_KU       30   test               0.0       -0.049752   \n",
       "2195  zhpQhgha_KU       35   test               1.0       -0.280185   \n",
       "2196  zhpQhgha_KU       34   test               1.0       -0.269441   \n",
       "2197  zhpQhgha_KU       33   test               0.0        0.085537   \n",
       "2198  zhpQhgha_KU       32   test               1.0       -0.216998   \n",
       "\n",
       "      text_feature_1  text_feature_2  text_feature_3  text_feature_4  \\\n",
       "0           0.996873       -0.641382       -0.476987        0.186320   \n",
       "1           0.782621       -0.380408       -0.298272        0.170435   \n",
       "2           0.156800       -0.037979       -0.099305        0.478109   \n",
       "3           0.158072        0.014531       -0.098467        0.774070   \n",
       "4           1.077508       -0.288741       -0.307522        0.177738   \n",
       "...              ...             ...             ...             ...   \n",
       "2194        0.957713       -0.359034       -0.270461        0.229189   \n",
       "2195        0.325935        0.116856       -0.097485        0.463279   \n",
       "2196        0.182711        0.016000       -0.244879        0.844845   \n",
       "2197        0.797328       -0.684733       -0.682357        0.026557   \n",
       "2198        0.612123        0.273865       -0.095879        0.475912   \n",
       "\n",
       "      text_feature_5  ...  video_feature_758  video_feature_759  \\\n",
       "0          -0.479807  ...          -1.078334          -0.212412   \n",
       "1          -1.098768  ...          -1.147198           0.130909   \n",
       "2           0.384305  ...          -0.516917          -0.099885   \n",
       "3           0.201158  ...          -1.019300           0.115281   \n",
       "4          -1.068847  ...          -1.380751           0.155880   \n",
       "...              ...  ...                ...                ...   \n",
       "2194       -0.694572  ...          -0.228938           0.320100   \n",
       "2195        0.388187  ...          -0.746198           0.073125   \n",
       "2196        0.338559  ...          -1.035848           0.008247   \n",
       "2197       -1.482874  ...          -0.822525           0.197105   \n",
       "2198        0.547925  ...          -0.563939           0.216366   \n",
       "\n",
       "      video_feature_760  video_feature_761  video_feature_762  \\\n",
       "0             -0.014572          -0.375293           0.837917   \n",
       "1             -0.206098           0.206220           0.948254   \n",
       "2              0.251831          -0.179767           0.371510   \n",
       "3             -0.440721           0.511699           0.359596   \n",
       "4             -0.150362           0.494003          -0.353426   \n",
       "...                 ...                ...                ...   \n",
       "2194          -0.162853           0.810133           0.515550   \n",
       "2195          -0.412568           0.249044          -0.190793   \n",
       "2196          -0.900263           0.018754           0.038172   \n",
       "2197          -1.279548           1.058336           0.070369   \n",
       "2198          -0.634186           0.500019          -0.275324   \n",
       "\n",
       "      video_feature_763  video_feature_764  video_feature_765  \\\n",
       "0              0.062687          -0.597331          -0.259640   \n",
       "1              0.354763          -0.502355          -0.444589   \n",
       "2              0.690991          -0.825537          -0.097008   \n",
       "3              0.243479          -0.542120          -0.339106   \n",
       "4              0.795431          -0.958967          -0.645879   \n",
       "...                 ...                ...                ...   \n",
       "2194          -0.156523           0.345616          -0.714201   \n",
       "2195          -0.707994           0.889685          -0.609933   \n",
       "2196          -0.237460           0.659862          -1.022472   \n",
       "2197          -0.570976           0.977215          -0.469761   \n",
       "2198          -0.410418           0.787863          -1.011445   \n",
       "\n",
       "      video_feature_766  video_feature_767  \n",
       "0             -1.898719          -1.712027  \n",
       "1             -1.971562          -1.491572  \n",
       "2             -1.760048          -0.853008  \n",
       "3             -1.352056          -1.143122  \n",
       "4             -1.676601          -0.627469  \n",
       "...                 ...                ...  \n",
       "2194          -0.877672          -0.311081  \n",
       "2195          -0.753124          -0.484004  \n",
       "2196          -0.690134          -0.631602  \n",
       "2197          -0.729410          -0.640767  \n",
       "2198          -0.928194          -0.203594  \n",
       "\n",
       "[2199 rows x 1796 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fa647ab-5e38-4227-abbd-1ce363abcda3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1740571918728,
     "user": {
      "displayName": "Kyparissis Kyparissis",
      "userId": "18280909670100413703"
     },
     "user_tz": -120
    },
    "id": "8fa647ab-5e38-4227-abbd-1ce363abcda3",
    "outputId": "7bb5cd6d-b41c-4093-d336-47c41897a4a9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2199, 1796)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_merged_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95954e83-af56-4f4a-88cf-ba8ad4255f23",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "executionInfo": {
     "elapsed": 74,
     "status": "ok",
     "timestamp": 1740571919433,
     "user": {
      "displayName": "Kyparissis Kyparissis",
      "userId": "18280909670100413703"
     },
     "user_tz": -120
    },
    "id": "95954e83-af56-4f4a-88cf-ba8ad4255f23",
    "outputId": "1778d1df-b594-4db2-a8f7-f4ac1930bfcf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>clip_id</th>\n",
       "      <th>annotation_label</th>\n",
       "      <th>mode</th>\n",
       "      <th>video_feature_0</th>\n",
       "      <th>video_feature_1</th>\n",
       "      <th>video_feature_2</th>\n",
       "      <th>video_feature_3</th>\n",
       "      <th>video_feature_4</th>\n",
       "      <th>video_feature_5</th>\n",
       "      <th>...</th>\n",
       "      <th>text_feature_758</th>\n",
       "      <th>text_feature_759</th>\n",
       "      <th>text_feature_760</th>\n",
       "      <th>text_feature_761</th>\n",
       "      <th>text_feature_762</th>\n",
       "      <th>text_feature_763</th>\n",
       "      <th>text_feature_764</th>\n",
       "      <th>text_feature_765</th>\n",
       "      <th>text_feature_766</th>\n",
       "      <th>text_feature_767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>0.439371</td>\n",
       "      <td>0.247791</td>\n",
       "      <td>0.068513</td>\n",
       "      <td>-0.060806</td>\n",
       "      <td>-0.017575</td>\n",
       "      <td>1.074164</td>\n",
       "      <td>...</td>\n",
       "      <td>0.175551</td>\n",
       "      <td>-0.400694</td>\n",
       "      <td>1.523944</td>\n",
       "      <td>-0.462501</td>\n",
       "      <td>-0.536807</td>\n",
       "      <td>-0.280624</td>\n",
       "      <td>-1.016937</td>\n",
       "      <td>1.423308</td>\n",
       "      <td>-0.587316</td>\n",
       "      <td>0.493037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>train</td>\n",
       "      <td>0.522580</td>\n",
       "      <td>-0.117958</td>\n",
       "      <td>0.194243</td>\n",
       "      <td>-0.449619</td>\n",
       "      <td>0.201808</td>\n",
       "      <td>0.718872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017866</td>\n",
       "      <td>-0.578022</td>\n",
       "      <td>1.223537</td>\n",
       "      <td>-0.693100</td>\n",
       "      <td>-0.596493</td>\n",
       "      <td>-0.669539</td>\n",
       "      <td>-1.417102</td>\n",
       "      <td>1.755622</td>\n",
       "      <td>-0.696475</td>\n",
       "      <td>-0.198517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>train</td>\n",
       "      <td>0.552831</td>\n",
       "      <td>-0.262263</td>\n",
       "      <td>-0.262357</td>\n",
       "      <td>-0.497176</td>\n",
       "      <td>-0.030941</td>\n",
       "      <td>0.890128</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.491156</td>\n",
       "      <td>0.374492</td>\n",
       "      <td>-0.868094</td>\n",
       "      <td>0.546483</td>\n",
       "      <td>0.346713</td>\n",
       "      <td>0.978013</td>\n",
       "      <td>1.077066</td>\n",
       "      <td>-1.140594</td>\n",
       "      <td>0.285355</td>\n",
       "      <td>-0.503165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>train</td>\n",
       "      <td>0.857708</td>\n",
       "      <td>-0.255024</td>\n",
       "      <td>-0.243093</td>\n",
       "      <td>-0.587603</td>\n",
       "      <td>0.491963</td>\n",
       "      <td>0.778350</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.324607</td>\n",
       "      <td>0.427225</td>\n",
       "      <td>-0.949620</td>\n",
       "      <td>0.890572</td>\n",
       "      <td>0.344190</td>\n",
       "      <td>0.990553</td>\n",
       "      <td>1.096355</td>\n",
       "      <td>-1.344340</td>\n",
       "      <td>0.151529</td>\n",
       "      <td>-0.253343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>train</td>\n",
       "      <td>1.157361</td>\n",
       "      <td>-0.556899</td>\n",
       "      <td>-0.445768</td>\n",
       "      <td>-0.851537</td>\n",
       "      <td>-0.388610</td>\n",
       "      <td>1.048423</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024403</td>\n",
       "      <td>-0.370995</td>\n",
       "      <td>1.370107</td>\n",
       "      <td>-0.694416</td>\n",
       "      <td>-0.878269</td>\n",
       "      <td>-0.539672</td>\n",
       "      <td>-1.410939</td>\n",
       "      <td>1.602672</td>\n",
       "      <td>-0.701200</td>\n",
       "      <td>-0.343756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2194</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>test</td>\n",
       "      <td>0.831355</td>\n",
       "      <td>0.805724</td>\n",
       "      <td>-0.272573</td>\n",
       "      <td>-0.342349</td>\n",
       "      <td>0.830707</td>\n",
       "      <td>0.128523</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024912</td>\n",
       "      <td>-0.390740</td>\n",
       "      <td>1.362876</td>\n",
       "      <td>-0.757794</td>\n",
       "      <td>-0.340896</td>\n",
       "      <td>-0.683082</td>\n",
       "      <td>-1.307081</td>\n",
       "      <td>1.482841</td>\n",
       "      <td>-0.424735</td>\n",
       "      <td>0.166160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2195</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>test</td>\n",
       "      <td>0.406417</td>\n",
       "      <td>-0.202951</td>\n",
       "      <td>-0.464274</td>\n",
       "      <td>-0.611844</td>\n",
       "      <td>0.705797</td>\n",
       "      <td>1.094925</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.416712</td>\n",
       "      <td>0.185422</td>\n",
       "      <td>-0.952263</td>\n",
       "      <td>0.721526</td>\n",
       "      <td>0.317901</td>\n",
       "      <td>0.984032</td>\n",
       "      <td>1.297174</td>\n",
       "      <td>-1.270689</td>\n",
       "      <td>0.028467</td>\n",
       "      <td>-0.285608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>34</td>\n",
       "      <td>1.0</td>\n",
       "      <td>test</td>\n",
       "      <td>0.376954</td>\n",
       "      <td>0.443066</td>\n",
       "      <td>-0.704081</td>\n",
       "      <td>-1.114472</td>\n",
       "      <td>0.345048</td>\n",
       "      <td>0.574175</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.428979</td>\n",
       "      <td>0.406420</td>\n",
       "      <td>-0.686308</td>\n",
       "      <td>0.709681</td>\n",
       "      <td>0.371721</td>\n",
       "      <td>1.014873</td>\n",
       "      <td>1.001999</td>\n",
       "      <td>-1.066811</td>\n",
       "      <td>0.325641</td>\n",
       "      <td>-0.397676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2197</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>test</td>\n",
       "      <td>0.971935</td>\n",
       "      <td>-0.153978</td>\n",
       "      <td>-0.714686</td>\n",
       "      <td>-0.591438</td>\n",
       "      <td>0.880721</td>\n",
       "      <td>1.153031</td>\n",
       "      <td>...</td>\n",
       "      <td>0.458958</td>\n",
       "      <td>-0.124651</td>\n",
       "      <td>1.233465</td>\n",
       "      <td>-0.427328</td>\n",
       "      <td>-0.985934</td>\n",
       "      <td>-0.367509</td>\n",
       "      <td>-0.899962</td>\n",
       "      <td>1.758477</td>\n",
       "      <td>-0.711113</td>\n",
       "      <td>0.246065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2198</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>32</td>\n",
       "      <td>1.0</td>\n",
       "      <td>test</td>\n",
       "      <td>0.677614</td>\n",
       "      <td>0.599679</td>\n",
       "      <td>-0.471225</td>\n",
       "      <td>-0.572803</td>\n",
       "      <td>0.529248</td>\n",
       "      <td>1.040616</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.499430</td>\n",
       "      <td>0.190872</td>\n",
       "      <td>-1.073085</td>\n",
       "      <td>0.929747</td>\n",
       "      <td>0.147983</td>\n",
       "      <td>1.072922</td>\n",
       "      <td>1.095303</td>\n",
       "      <td>-1.252232</td>\n",
       "      <td>0.166678</td>\n",
       "      <td>-0.046314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2199 rows × 1540 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         video_id  clip_id  annotation_label   mode  video_feature_0  \\\n",
       "0     03bSnISJMiM       11               0.0  train         0.439371   \n",
       "1     03bSnISJMiM       10               0.0  train         0.522580   \n",
       "2     03bSnISJMiM       13               1.0  train         0.552831   \n",
       "3     03bSnISJMiM       12               1.0  train         0.857708   \n",
       "4     03bSnISJMiM        1               1.0  train         1.157361   \n",
       "...           ...      ...               ...    ...              ...   \n",
       "2194  zhpQhgha_KU       30               0.0   test         0.831355   \n",
       "2195  zhpQhgha_KU       35               1.0   test         0.406417   \n",
       "2196  zhpQhgha_KU       34               1.0   test         0.376954   \n",
       "2197  zhpQhgha_KU       33               0.0   test         0.971935   \n",
       "2198  zhpQhgha_KU       32               1.0   test         0.677614   \n",
       "\n",
       "      video_feature_1  video_feature_2  video_feature_3  video_feature_4  \\\n",
       "0            0.247791         0.068513        -0.060806        -0.017575   \n",
       "1           -0.117958         0.194243        -0.449619         0.201808   \n",
       "2           -0.262263        -0.262357        -0.497176        -0.030941   \n",
       "3           -0.255024        -0.243093        -0.587603         0.491963   \n",
       "4           -0.556899        -0.445768        -0.851537        -0.388610   \n",
       "...               ...              ...              ...              ...   \n",
       "2194         0.805724        -0.272573        -0.342349         0.830707   \n",
       "2195        -0.202951        -0.464274        -0.611844         0.705797   \n",
       "2196         0.443066        -0.704081        -1.114472         0.345048   \n",
       "2197        -0.153978        -0.714686        -0.591438         0.880721   \n",
       "2198         0.599679        -0.471225        -0.572803         0.529248   \n",
       "\n",
       "      video_feature_5  ...  text_feature_758  text_feature_759  \\\n",
       "0            1.074164  ...          0.175551         -0.400694   \n",
       "1            0.718872  ...          0.017866         -0.578022   \n",
       "2            0.890128  ...         -0.491156          0.374492   \n",
       "3            0.778350  ...         -0.324607          0.427225   \n",
       "4            1.048423  ...          0.024403         -0.370995   \n",
       "...               ...  ...               ...               ...   \n",
       "2194         0.128523  ...          0.024912         -0.390740   \n",
       "2195         1.094925  ...         -0.416712          0.185422   \n",
       "2196         0.574175  ...         -0.428979          0.406420   \n",
       "2197         1.153031  ...          0.458958         -0.124651   \n",
       "2198         1.040616  ...         -0.499430          0.190872   \n",
       "\n",
       "      text_feature_760  text_feature_761  text_feature_762  text_feature_763  \\\n",
       "0             1.523944         -0.462501         -0.536807         -0.280624   \n",
       "1             1.223537         -0.693100         -0.596493         -0.669539   \n",
       "2            -0.868094          0.546483          0.346713          0.978013   \n",
       "3            -0.949620          0.890572          0.344190          0.990553   \n",
       "4             1.370107         -0.694416         -0.878269         -0.539672   \n",
       "...                ...               ...               ...               ...   \n",
       "2194          1.362876         -0.757794         -0.340896         -0.683082   \n",
       "2195         -0.952263          0.721526          0.317901          0.984032   \n",
       "2196         -0.686308          0.709681          0.371721          1.014873   \n",
       "2197          1.233465         -0.427328         -0.985934         -0.367509   \n",
       "2198         -1.073085          0.929747          0.147983          1.072922   \n",
       "\n",
       "      text_feature_764  text_feature_765  text_feature_766  text_feature_767  \n",
       "0            -1.016937          1.423308         -0.587316          0.493037  \n",
       "1            -1.417102          1.755622         -0.696475         -0.198517  \n",
       "2             1.077066         -1.140594          0.285355         -0.503165  \n",
       "3             1.096355         -1.344340          0.151529         -0.253343  \n",
       "4            -1.410939          1.602672         -0.701200         -0.343756  \n",
       "...                ...               ...               ...               ...  \n",
       "2194         -1.307081          1.482841         -0.424735          0.166160  \n",
       "2195          1.297174         -1.270689          0.028467         -0.285608  \n",
       "2196          1.001999         -1.066811          0.325641         -0.397676  \n",
       "2197         -0.899962          1.758477         -0.711113          0.246065  \n",
       "2198          1.095303         -1.252232          0.166678         -0.046314  \n",
       "\n",
       "[2199 rows x 1540 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_video_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7499bdd-28a0-42ff-a748-d7b7bd7b9eca",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1740571921162,
     "user": {
      "displayName": "Kyparissis Kyparissis",
      "userId": "18280909670100413703"
     },
     "user_tz": -120
    },
    "id": "d7499bdd-28a0-42ff-a748-d7b7bd7b9eca"
   },
   "outputs": [],
   "source": [
    "# merged_df.to_csv('all_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26da8b9f-f55a-4f49-a851-9f3cd653bbc6",
   "metadata": {
    "executionInfo": {
     "elapsed": 78,
     "status": "ok",
     "timestamp": 1740571921785,
     "user": {
      "displayName": "Kyparissis Kyparissis",
      "userId": "18280909670100413703"
     },
     "user_tz": -120
    },
    "id": "26da8b9f-f55a-4f49-a851-9f3cd653bbc6"
   },
   "outputs": [],
   "source": [
    "# Filter the DataFrame by mode (train, valid, test) to create subsets\n",
    "train_all_merged_df = all_merged_df[all_merged_df[\"mode\"] == \"train\"].drop(columns=[\"mode\"])\n",
    "train_text_audio_merged_df = text_audio_merged_df[text_audio_merged_df[\"mode\"] == \"train\"].drop(columns=[\"mode\"])\n",
    "train_audio_video_merged_df = audio_video_merged_df[audio_video_merged_df[\"mode\"] == \"train\"].drop(columns=[\"mode\"])\n",
    "train_text_video_merged_df = text_video_merged_df[text_video_merged_df[\"mode\"] == \"train\"].drop(columns=[\"mode\"])\n",
    "\n",
    "valid_all_merged_df = all_merged_df[all_merged_df[\"mode\"] == \"valid\"].drop(columns=[\"mode\"])\n",
    "valid_text_audio_merged_df = text_audio_merged_df[text_audio_merged_df[\"mode\"] == \"valid\"].drop(columns=[\"mode\"])\n",
    "valid_audio_video_merged_df = audio_video_merged_df[audio_video_merged_df[\"mode\"] == \"valid\"].drop(columns=[\"mode\"])\n",
    "valid_text_video_merged_df = text_video_merged_df[text_video_merged_df[\"mode\"] == \"valid\"].drop(columns=[\"mode\"])\n",
    "\n",
    "test_all_merged_df = all_merged_df[all_merged_df[\"mode\"] == \"test\"].drop(columns=[\"mode\"])\n",
    "test_text_audio_merged_df = text_audio_merged_df[text_audio_merged_df[\"mode\"] == \"test\"].drop(columns=[\"mode\"])\n",
    "test_audio_video_merged_df = audio_video_merged_df[audio_video_merged_df[\"mode\"] == \"test\"].drop(columns=[\"mode\"])\n",
    "test_text_video_merged_df = text_video_merged_df[text_video_merged_df[\"mode\"] == \"test\"].drop(columns=[\"mode\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22513ee5-2b88-451b-a01c-62c8e6c8a96d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "executionInfo": {
     "elapsed": 70,
     "status": "ok",
     "timestamp": 1740571923745,
     "user": {
      "displayName": "Kyparissis Kyparissis",
      "userId": "18280909670100413703"
     },
     "user_tz": -120
    },
    "id": "22513ee5-2b88-451b-a01c-62c8e6c8a96d",
    "outputId": "5b2cf44a-6f32-4cbd-b693-93853ee2f98e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>clip_id</th>\n",
       "      <th>annotation_label</th>\n",
       "      <th>text_feature_0</th>\n",
       "      <th>text_feature_1</th>\n",
       "      <th>text_feature_2</th>\n",
       "      <th>text_feature_3</th>\n",
       "      <th>text_feature_4</th>\n",
       "      <th>text_feature_5</th>\n",
       "      <th>text_feature_6</th>\n",
       "      <th>...</th>\n",
       "      <th>video_feature_758</th>\n",
       "      <th>video_feature_759</th>\n",
       "      <th>video_feature_760</th>\n",
       "      <th>video_feature_761</th>\n",
       "      <th>video_feature_762</th>\n",
       "      <th>video_feature_763</th>\n",
       "      <th>video_feature_764</th>\n",
       "      <th>video_feature_765</th>\n",
       "      <th>video_feature_766</th>\n",
       "      <th>video_feature_767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.270479</td>\n",
       "      <td>0.996873</td>\n",
       "      <td>-0.641382</td>\n",
       "      <td>-0.476987</td>\n",
       "      <td>0.186320</td>\n",
       "      <td>-0.479807</td>\n",
       "      <td>0.271487</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.078334</td>\n",
       "      <td>-0.212412</td>\n",
       "      <td>-0.014572</td>\n",
       "      <td>-0.375293</td>\n",
       "      <td>0.837917</td>\n",
       "      <td>0.062687</td>\n",
       "      <td>-0.597331</td>\n",
       "      <td>-0.259640</td>\n",
       "      <td>-1.898719</td>\n",
       "      <td>-1.712027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004698</td>\n",
       "      <td>0.782621</td>\n",
       "      <td>-0.380408</td>\n",
       "      <td>-0.298272</td>\n",
       "      <td>0.170435</td>\n",
       "      <td>-1.098768</td>\n",
       "      <td>-0.181759</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.147198</td>\n",
       "      <td>0.130909</td>\n",
       "      <td>-0.206098</td>\n",
       "      <td>0.206220</td>\n",
       "      <td>0.948254</td>\n",
       "      <td>0.354763</td>\n",
       "      <td>-0.502355</td>\n",
       "      <td>-0.444589</td>\n",
       "      <td>-1.971562</td>\n",
       "      <td>-1.491572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.173633</td>\n",
       "      <td>0.156800</td>\n",
       "      <td>-0.037979</td>\n",
       "      <td>-0.099305</td>\n",
       "      <td>0.478109</td>\n",
       "      <td>0.384305</td>\n",
       "      <td>-0.058273</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.516917</td>\n",
       "      <td>-0.099885</td>\n",
       "      <td>0.251831</td>\n",
       "      <td>-0.179767</td>\n",
       "      <td>0.371510</td>\n",
       "      <td>0.690991</td>\n",
       "      <td>-0.825537</td>\n",
       "      <td>-0.097008</td>\n",
       "      <td>-1.760048</td>\n",
       "      <td>-0.853008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.218314</td>\n",
       "      <td>0.158072</td>\n",
       "      <td>0.014531</td>\n",
       "      <td>-0.098467</td>\n",
       "      <td>0.774070</td>\n",
       "      <td>0.201158</td>\n",
       "      <td>-0.369480</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.019300</td>\n",
       "      <td>0.115281</td>\n",
       "      <td>-0.440721</td>\n",
       "      <td>0.511699</td>\n",
       "      <td>0.359596</td>\n",
       "      <td>0.243479</td>\n",
       "      <td>-0.542120</td>\n",
       "      <td>-0.339106</td>\n",
       "      <td>-1.352056</td>\n",
       "      <td>-1.143122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.010284</td>\n",
       "      <td>1.077508</td>\n",
       "      <td>-0.288741</td>\n",
       "      <td>-0.307522</td>\n",
       "      <td>0.177738</td>\n",
       "      <td>-1.068847</td>\n",
       "      <td>-0.060524</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.380751</td>\n",
       "      <td>0.155880</td>\n",
       "      <td>-0.150362</td>\n",
       "      <td>0.494003</td>\n",
       "      <td>-0.353426</td>\n",
       "      <td>0.795431</td>\n",
       "      <td>-0.958967</td>\n",
       "      <td>-0.645879</td>\n",
       "      <td>-1.676601</td>\n",
       "      <td>-0.627469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1279</th>\n",
       "      <td>W8NXH0Djyww</td>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.072391</td>\n",
       "      <td>0.765663</td>\n",
       "      <td>-0.559932</td>\n",
       "      <td>-0.240193</td>\n",
       "      <td>0.214473</td>\n",
       "      <td>-0.933237</td>\n",
       "      <td>0.202434</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.049781</td>\n",
       "      <td>-0.097843</td>\n",
       "      <td>0.535710</td>\n",
       "      <td>-0.125911</td>\n",
       "      <td>-0.487650</td>\n",
       "      <td>0.725425</td>\n",
       "      <td>-0.131264</td>\n",
       "      <td>-0.814491</td>\n",
       "      <td>-0.474926</td>\n",
       "      <td>0.298997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1280</th>\n",
       "      <td>W8NXH0Djyww</td>\n",
       "      <td>18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.273359</td>\n",
       "      <td>0.135727</td>\n",
       "      <td>0.261043</td>\n",
       "      <td>-0.124110</td>\n",
       "      <td>0.093434</td>\n",
       "      <td>0.186650</td>\n",
       "      <td>-0.098025</td>\n",
       "      <td>...</td>\n",
       "      <td>0.653575</td>\n",
       "      <td>-0.126224</td>\n",
       "      <td>0.412706</td>\n",
       "      <td>0.129997</td>\n",
       "      <td>0.412914</td>\n",
       "      <td>0.953175</td>\n",
       "      <td>-0.251088</td>\n",
       "      <td>-1.235145</td>\n",
       "      <td>-0.170783</td>\n",
       "      <td>0.061585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1281</th>\n",
       "      <td>W8NXH0Djyww</td>\n",
       "      <td>31</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.080533</td>\n",
       "      <td>0.820012</td>\n",
       "      <td>-0.512017</td>\n",
       "      <td>-0.286724</td>\n",
       "      <td>0.177884</td>\n",
       "      <td>-1.070902</td>\n",
       "      <td>0.127666</td>\n",
       "      <td>...</td>\n",
       "      <td>0.549700</td>\n",
       "      <td>-0.191364</td>\n",
       "      <td>0.192096</td>\n",
       "      <td>0.050092</td>\n",
       "      <td>0.258074</td>\n",
       "      <td>1.061694</td>\n",
       "      <td>-0.261101</td>\n",
       "      <td>-1.281922</td>\n",
       "      <td>-0.064462</td>\n",
       "      <td>0.194249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1282</th>\n",
       "      <td>W8NXH0Djyww</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.373313</td>\n",
       "      <td>0.167305</td>\n",
       "      <td>0.324999</td>\n",
       "      <td>-0.059186</td>\n",
       "      <td>0.566811</td>\n",
       "      <td>0.230739</td>\n",
       "      <td>-0.142146</td>\n",
       "      <td>...</td>\n",
       "      <td>1.057948</td>\n",
       "      <td>-0.183860</td>\n",
       "      <td>-0.168658</td>\n",
       "      <td>0.065459</td>\n",
       "      <td>0.757941</td>\n",
       "      <td>0.713041</td>\n",
       "      <td>-0.255165</td>\n",
       "      <td>-1.426317</td>\n",
       "      <td>-0.134659</td>\n",
       "      <td>0.208903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1283</th>\n",
       "      <td>W8NXH0Djyww</td>\n",
       "      <td>32</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.105332</td>\n",
       "      <td>0.667324</td>\n",
       "      <td>-0.574200</td>\n",
       "      <td>-0.380044</td>\n",
       "      <td>0.313940</td>\n",
       "      <td>-0.780877</td>\n",
       "      <td>0.000623</td>\n",
       "      <td>...</td>\n",
       "      <td>0.890790</td>\n",
       "      <td>-0.276192</td>\n",
       "      <td>0.506767</td>\n",
       "      <td>-0.104024</td>\n",
       "      <td>0.245074</td>\n",
       "      <td>0.874979</td>\n",
       "      <td>-0.461248</td>\n",
       "      <td>-1.432697</td>\n",
       "      <td>-0.000483</td>\n",
       "      <td>-0.007410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1284 rows × 1795 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         video_id  clip_id  annotation_label  text_feature_0  text_feature_1  \\\n",
       "0     03bSnISJMiM       11               0.0        0.270479        0.996873   \n",
       "1     03bSnISJMiM       10               0.0        0.004698        0.782621   \n",
       "2     03bSnISJMiM       13               1.0       -0.173633        0.156800   \n",
       "3     03bSnISJMiM       12               1.0       -0.218314        0.158072   \n",
       "4     03bSnISJMiM        1               1.0        0.010284        1.077508   \n",
       "...           ...      ...               ...             ...             ...   \n",
       "1279  W8NXH0Djyww       19               0.0        0.072391        0.765663   \n",
       "1280  W8NXH0Djyww       18               1.0       -0.273359        0.135727   \n",
       "1281  W8NXH0Djyww       31               1.0       -0.080533        0.820012   \n",
       "1282  W8NXH0Djyww       30               0.0       -0.373313        0.167305   \n",
       "1283  W8NXH0Djyww       32               1.0       -0.105332        0.667324   \n",
       "\n",
       "      text_feature_2  text_feature_3  text_feature_4  text_feature_5  \\\n",
       "0          -0.641382       -0.476987        0.186320       -0.479807   \n",
       "1          -0.380408       -0.298272        0.170435       -1.098768   \n",
       "2          -0.037979       -0.099305        0.478109        0.384305   \n",
       "3           0.014531       -0.098467        0.774070        0.201158   \n",
       "4          -0.288741       -0.307522        0.177738       -1.068847   \n",
       "...              ...             ...             ...             ...   \n",
       "1279       -0.559932       -0.240193        0.214473       -0.933237   \n",
       "1280        0.261043       -0.124110        0.093434        0.186650   \n",
       "1281       -0.512017       -0.286724        0.177884       -1.070902   \n",
       "1282        0.324999       -0.059186        0.566811        0.230739   \n",
       "1283       -0.574200       -0.380044        0.313940       -0.780877   \n",
       "\n",
       "      text_feature_6  ...  video_feature_758  video_feature_759  \\\n",
       "0           0.271487  ...          -1.078334          -0.212412   \n",
       "1          -0.181759  ...          -1.147198           0.130909   \n",
       "2          -0.058273  ...          -0.516917          -0.099885   \n",
       "3          -0.369480  ...          -1.019300           0.115281   \n",
       "4          -0.060524  ...          -1.380751           0.155880   \n",
       "...              ...  ...                ...                ...   \n",
       "1279        0.202434  ...          -1.049781          -0.097843   \n",
       "1280       -0.098025  ...           0.653575          -0.126224   \n",
       "1281        0.127666  ...           0.549700          -0.191364   \n",
       "1282       -0.142146  ...           1.057948          -0.183860   \n",
       "1283        0.000623  ...           0.890790          -0.276192   \n",
       "\n",
       "      video_feature_760  video_feature_761  video_feature_762  \\\n",
       "0             -0.014572          -0.375293           0.837917   \n",
       "1             -0.206098           0.206220           0.948254   \n",
       "2              0.251831          -0.179767           0.371510   \n",
       "3             -0.440721           0.511699           0.359596   \n",
       "4             -0.150362           0.494003          -0.353426   \n",
       "...                 ...                ...                ...   \n",
       "1279           0.535710          -0.125911          -0.487650   \n",
       "1280           0.412706           0.129997           0.412914   \n",
       "1281           0.192096           0.050092           0.258074   \n",
       "1282          -0.168658           0.065459           0.757941   \n",
       "1283           0.506767          -0.104024           0.245074   \n",
       "\n",
       "      video_feature_763  video_feature_764  video_feature_765  \\\n",
       "0              0.062687          -0.597331          -0.259640   \n",
       "1              0.354763          -0.502355          -0.444589   \n",
       "2              0.690991          -0.825537          -0.097008   \n",
       "3              0.243479          -0.542120          -0.339106   \n",
       "4              0.795431          -0.958967          -0.645879   \n",
       "...                 ...                ...                ...   \n",
       "1279           0.725425          -0.131264          -0.814491   \n",
       "1280           0.953175          -0.251088          -1.235145   \n",
       "1281           1.061694          -0.261101          -1.281922   \n",
       "1282           0.713041          -0.255165          -1.426317   \n",
       "1283           0.874979          -0.461248          -1.432697   \n",
       "\n",
       "      video_feature_766  video_feature_767  \n",
       "0             -1.898719          -1.712027  \n",
       "1             -1.971562          -1.491572  \n",
       "2             -1.760048          -0.853008  \n",
       "3             -1.352056          -1.143122  \n",
       "4             -1.676601          -0.627469  \n",
       "...                 ...                ...  \n",
       "1279          -0.474926           0.298997  \n",
       "1280          -0.170783           0.061585  \n",
       "1281          -0.064462           0.194249  \n",
       "1282          -0.134659           0.208903  \n",
       "1283          -0.000483          -0.007410  \n",
       "\n",
       "[1284 rows x 1795 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_all_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb80a7cc-58f9-4c53-b1b6-2c2b4065a9d2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "executionInfo": {
     "elapsed": 81,
     "status": "ok",
     "timestamp": 1740571924645,
     "user": {
      "displayName": "Kyparissis Kyparissis",
      "userId": "18280909670100413703"
     },
     "user_tz": -120
    },
    "id": "cb80a7cc-58f9-4c53-b1b6-2c2b4065a9d2",
    "outputId": "f06824c8-b3d9-477a-f114-b400ec5f39e9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>clip_id</th>\n",
       "      <th>annotation_label</th>\n",
       "      <th>video_feature_0</th>\n",
       "      <th>video_feature_1</th>\n",
       "      <th>video_feature_2</th>\n",
       "      <th>video_feature_3</th>\n",
       "      <th>video_feature_4</th>\n",
       "      <th>video_feature_5</th>\n",
       "      <th>video_feature_6</th>\n",
       "      <th>...</th>\n",
       "      <th>text_feature_758</th>\n",
       "      <th>text_feature_759</th>\n",
       "      <th>text_feature_760</th>\n",
       "      <th>text_feature_761</th>\n",
       "      <th>text_feature_762</th>\n",
       "      <th>text_feature_763</th>\n",
       "      <th>text_feature_764</th>\n",
       "      <th>text_feature_765</th>\n",
       "      <th>text_feature_766</th>\n",
       "      <th>text_feature_767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1513</th>\n",
       "      <td>c7UH_rxdZv4</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.616361</td>\n",
       "      <td>0.415739</td>\n",
       "      <td>-0.622293</td>\n",
       "      <td>-1.296277</td>\n",
       "      <td>-0.342991</td>\n",
       "      <td>1.564045</td>\n",
       "      <td>0.258472</td>\n",
       "      <td>...</td>\n",
       "      <td>0.193118</td>\n",
       "      <td>-0.486089</td>\n",
       "      <td>1.392372</td>\n",
       "      <td>-0.696001</td>\n",
       "      <td>-0.810331</td>\n",
       "      <td>-0.345925</td>\n",
       "      <td>-1.391639</td>\n",
       "      <td>1.704905</td>\n",
       "      <td>-0.736086</td>\n",
       "      <td>0.248847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1514</th>\n",
       "      <td>c7UH_rxdZv4</td>\n",
       "      <td>25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.353537</td>\n",
       "      <td>-0.232666</td>\n",
       "      <td>-0.457549</td>\n",
       "      <td>-1.478246</td>\n",
       "      <td>-0.349484</td>\n",
       "      <td>0.918699</td>\n",
       "      <td>-0.108954</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.440732</td>\n",
       "      <td>0.417015</td>\n",
       "      <td>-0.851555</td>\n",
       "      <td>0.758757</td>\n",
       "      <td>0.419784</td>\n",
       "      <td>1.020385</td>\n",
       "      <td>1.154922</td>\n",
       "      <td>-0.931525</td>\n",
       "      <td>0.181172</td>\n",
       "      <td>-0.477168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1515</th>\n",
       "      <td>c7UH_rxdZv4</td>\n",
       "      <td>26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.226897</td>\n",
       "      <td>1.027227</td>\n",
       "      <td>-0.809006</td>\n",
       "      <td>-0.476973</td>\n",
       "      <td>-0.843320</td>\n",
       "      <td>1.732117</td>\n",
       "      <td>0.456953</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.243117</td>\n",
       "      <td>-0.739573</td>\n",
       "      <td>1.273095</td>\n",
       "      <td>-0.803861</td>\n",
       "      <td>-0.729338</td>\n",
       "      <td>-0.636050</td>\n",
       "      <td>-1.187549</td>\n",
       "      <td>1.671630</td>\n",
       "      <td>-0.736085</td>\n",
       "      <td>-0.493479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1516</th>\n",
       "      <td>c7UH_rxdZv4</td>\n",
       "      <td>27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.349119</td>\n",
       "      <td>0.775047</td>\n",
       "      <td>-0.422119</td>\n",
       "      <td>-0.604920</td>\n",
       "      <td>-0.460934</td>\n",
       "      <td>1.797762</td>\n",
       "      <td>0.439652</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011160</td>\n",
       "      <td>-0.791038</td>\n",
       "      <td>1.196986</td>\n",
       "      <td>-0.641667</td>\n",
       "      <td>-0.666448</td>\n",
       "      <td>-0.845131</td>\n",
       "      <td>-0.939244</td>\n",
       "      <td>1.476472</td>\n",
       "      <td>-0.536616</td>\n",
       "      <td>-0.060048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1517</th>\n",
       "      <td>c7UH_rxdZv4</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.108904</td>\n",
       "      <td>0.677407</td>\n",
       "      <td>-0.420910</td>\n",
       "      <td>-0.962616</td>\n",
       "      <td>-0.487292</td>\n",
       "      <td>2.155302</td>\n",
       "      <td>0.432271</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026676</td>\n",
       "      <td>-0.502513</td>\n",
       "      <td>1.491710</td>\n",
       "      <td>-0.818012</td>\n",
       "      <td>-0.760336</td>\n",
       "      <td>-0.499871</td>\n",
       "      <td>-1.255345</td>\n",
       "      <td>1.668507</td>\n",
       "      <td>-0.587110</td>\n",
       "      <td>0.205102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2194</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.831355</td>\n",
       "      <td>0.805724</td>\n",
       "      <td>-0.272573</td>\n",
       "      <td>-0.342349</td>\n",
       "      <td>0.830707</td>\n",
       "      <td>0.128523</td>\n",
       "      <td>1.396225</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024912</td>\n",
       "      <td>-0.390740</td>\n",
       "      <td>1.362876</td>\n",
       "      <td>-0.757794</td>\n",
       "      <td>-0.340896</td>\n",
       "      <td>-0.683082</td>\n",
       "      <td>-1.307081</td>\n",
       "      <td>1.482841</td>\n",
       "      <td>-0.424735</td>\n",
       "      <td>0.166160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2195</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.406417</td>\n",
       "      <td>-0.202951</td>\n",
       "      <td>-0.464274</td>\n",
       "      <td>-0.611844</td>\n",
       "      <td>0.705797</td>\n",
       "      <td>1.094925</td>\n",
       "      <td>0.821598</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.416712</td>\n",
       "      <td>0.185422</td>\n",
       "      <td>-0.952263</td>\n",
       "      <td>0.721526</td>\n",
       "      <td>0.317901</td>\n",
       "      <td>0.984032</td>\n",
       "      <td>1.297174</td>\n",
       "      <td>-1.270689</td>\n",
       "      <td>0.028467</td>\n",
       "      <td>-0.285608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>34</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.376954</td>\n",
       "      <td>0.443066</td>\n",
       "      <td>-0.704081</td>\n",
       "      <td>-1.114472</td>\n",
       "      <td>0.345048</td>\n",
       "      <td>0.574175</td>\n",
       "      <td>1.111698</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.428979</td>\n",
       "      <td>0.406420</td>\n",
       "      <td>-0.686308</td>\n",
       "      <td>0.709681</td>\n",
       "      <td>0.371721</td>\n",
       "      <td>1.014873</td>\n",
       "      <td>1.001999</td>\n",
       "      <td>-1.066811</td>\n",
       "      <td>0.325641</td>\n",
       "      <td>-0.397676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2197</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.971935</td>\n",
       "      <td>-0.153978</td>\n",
       "      <td>-0.714686</td>\n",
       "      <td>-0.591438</td>\n",
       "      <td>0.880721</td>\n",
       "      <td>1.153031</td>\n",
       "      <td>1.294981</td>\n",
       "      <td>...</td>\n",
       "      <td>0.458958</td>\n",
       "      <td>-0.124651</td>\n",
       "      <td>1.233465</td>\n",
       "      <td>-0.427328</td>\n",
       "      <td>-0.985934</td>\n",
       "      <td>-0.367509</td>\n",
       "      <td>-0.899962</td>\n",
       "      <td>1.758477</td>\n",
       "      <td>-0.711113</td>\n",
       "      <td>0.246065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2198</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>32</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.677614</td>\n",
       "      <td>0.599679</td>\n",
       "      <td>-0.471225</td>\n",
       "      <td>-0.572803</td>\n",
       "      <td>0.529248</td>\n",
       "      <td>1.040616</td>\n",
       "      <td>1.183510</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.499430</td>\n",
       "      <td>0.190872</td>\n",
       "      <td>-1.073085</td>\n",
       "      <td>0.929747</td>\n",
       "      <td>0.147983</td>\n",
       "      <td>1.072922</td>\n",
       "      <td>1.095303</td>\n",
       "      <td>-1.252232</td>\n",
       "      <td>0.166678</td>\n",
       "      <td>-0.046314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>686 rows × 1539 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         video_id  clip_id  annotation_label  video_feature_0  \\\n",
       "1513  c7UH_rxdZv4       24               0.0         0.616361   \n",
       "1514  c7UH_rxdZv4       25               1.0         0.353537   \n",
       "1515  c7UH_rxdZv4       26               0.0         0.226897   \n",
       "1516  c7UH_rxdZv4       27               0.0         0.349119   \n",
       "1517  c7UH_rxdZv4       20               0.0        -0.108904   \n",
       "...           ...      ...               ...              ...   \n",
       "2194  zhpQhgha_KU       30               0.0         0.831355   \n",
       "2195  zhpQhgha_KU       35               1.0         0.406417   \n",
       "2196  zhpQhgha_KU       34               1.0         0.376954   \n",
       "2197  zhpQhgha_KU       33               0.0         0.971935   \n",
       "2198  zhpQhgha_KU       32               1.0         0.677614   \n",
       "\n",
       "      video_feature_1  video_feature_2  video_feature_3  video_feature_4  \\\n",
       "1513         0.415739        -0.622293        -1.296277        -0.342991   \n",
       "1514        -0.232666        -0.457549        -1.478246        -0.349484   \n",
       "1515         1.027227        -0.809006        -0.476973        -0.843320   \n",
       "1516         0.775047        -0.422119        -0.604920        -0.460934   \n",
       "1517         0.677407        -0.420910        -0.962616        -0.487292   \n",
       "...               ...              ...              ...              ...   \n",
       "2194         0.805724        -0.272573        -0.342349         0.830707   \n",
       "2195        -0.202951        -0.464274        -0.611844         0.705797   \n",
       "2196         0.443066        -0.704081        -1.114472         0.345048   \n",
       "2197        -0.153978        -0.714686        -0.591438         0.880721   \n",
       "2198         0.599679        -0.471225        -0.572803         0.529248   \n",
       "\n",
       "      video_feature_5  video_feature_6  ...  text_feature_758  \\\n",
       "1513         1.564045         0.258472  ...          0.193118   \n",
       "1514         0.918699        -0.108954  ...         -0.440732   \n",
       "1515         1.732117         0.456953  ...         -0.243117   \n",
       "1516         1.797762         0.439652  ...          0.011160   \n",
       "1517         2.155302         0.432271  ...          0.026676   \n",
       "...               ...              ...  ...               ...   \n",
       "2194         0.128523         1.396225  ...          0.024912   \n",
       "2195         1.094925         0.821598  ...         -0.416712   \n",
       "2196         0.574175         1.111698  ...         -0.428979   \n",
       "2197         1.153031         1.294981  ...          0.458958   \n",
       "2198         1.040616         1.183510  ...         -0.499430   \n",
       "\n",
       "      text_feature_759  text_feature_760  text_feature_761  text_feature_762  \\\n",
       "1513         -0.486089          1.392372         -0.696001         -0.810331   \n",
       "1514          0.417015         -0.851555          0.758757          0.419784   \n",
       "1515         -0.739573          1.273095         -0.803861         -0.729338   \n",
       "1516         -0.791038          1.196986         -0.641667         -0.666448   \n",
       "1517         -0.502513          1.491710         -0.818012         -0.760336   \n",
       "...                ...               ...               ...               ...   \n",
       "2194         -0.390740          1.362876         -0.757794         -0.340896   \n",
       "2195          0.185422         -0.952263          0.721526          0.317901   \n",
       "2196          0.406420         -0.686308          0.709681          0.371721   \n",
       "2197         -0.124651          1.233465         -0.427328         -0.985934   \n",
       "2198          0.190872         -1.073085          0.929747          0.147983   \n",
       "\n",
       "      text_feature_763  text_feature_764  text_feature_765  text_feature_766  \\\n",
       "1513         -0.345925         -1.391639          1.704905         -0.736086   \n",
       "1514          1.020385          1.154922         -0.931525          0.181172   \n",
       "1515         -0.636050         -1.187549          1.671630         -0.736085   \n",
       "1516         -0.845131         -0.939244          1.476472         -0.536616   \n",
       "1517         -0.499871         -1.255345          1.668507         -0.587110   \n",
       "...                ...               ...               ...               ...   \n",
       "2194         -0.683082         -1.307081          1.482841         -0.424735   \n",
       "2195          0.984032          1.297174         -1.270689          0.028467   \n",
       "2196          1.014873          1.001999         -1.066811          0.325641   \n",
       "2197         -0.367509         -0.899962          1.758477         -0.711113   \n",
       "2198          1.072922          1.095303         -1.252232          0.166678   \n",
       "\n",
       "      text_feature_767  \n",
       "1513          0.248847  \n",
       "1514         -0.477168  \n",
       "1515         -0.493479  \n",
       "1516         -0.060048  \n",
       "1517          0.205102  \n",
       "...                ...  \n",
       "2194          0.166160  \n",
       "2195         -0.285608  \n",
       "2196         -0.397676  \n",
       "2197          0.246065  \n",
       "2198         -0.046314  \n",
       "\n",
       "[686 rows x 1539 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text_video_merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c692ce-d074-4e68-82b9-66f65b2e3f09",
   "metadata": {
    "id": "87c692ce-d074-4e68-82b9-66f65b2e3f09"
   },
   "source": [
    "---\n",
    "# Trimodal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff19bd71-de6a-43fa-a216-4bd7541b9d24",
   "metadata": {
    "id": "ff19bd71-de6a-43fa-a216-4bd7541b9d24"
   },
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# # Normalize features\n",
    "# scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b9dd95e-d2b1-475a-b6a6-ad96ff116c04",
   "metadata": {
    "executionInfo": {
     "elapsed": 515,
     "status": "ok",
     "timestamp": 1740571927593,
     "user": {
      "displayName": "Kyparissis Kyparissis",
      "userId": "18280909670100413703"
     },
     "user_tz": -120
    },
    "id": "8b9dd95e-d2b1-475a-b6a6-ad96ff116c04"
   },
   "outputs": [],
   "source": [
    "train_all_merged_labels = train_all_merged_df['annotation_label']\n",
    "train_all_merged_features = train_all_merged_df.drop(columns=['video_id', 'clip_id', 'annotation_label'])\n",
    "train_all_merged_features = train_all_merged_features.values.tolist()\n",
    "# Create datasets with the features and labels\n",
    "train_all_merged_dataset = Dataset.from_dict({\n",
    "    'input_ids': train_all_merged_features,\n",
    "    'labels': train_all_merged_labels.tolist(),\n",
    "    'clip_id': train_all_merged_df['clip_id'].tolist(),\n",
    "    'video_id': train_all_merged_df['video_id'].tolist()\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "578b360b-16e1-4f7e-85c9-2b288189641c",
   "metadata": {
    "executionInfo": {
     "elapsed": 92,
     "status": "ok",
     "timestamp": 1740571927729,
     "user": {
      "displayName": "Kyparissis Kyparissis",
      "userId": "18280909670100413703"
     },
     "user_tz": -120
    },
    "id": "578b360b-16e1-4f7e-85c9-2b288189641c"
   },
   "outputs": [],
   "source": [
    "valid_all_merged_labels = valid_all_merged_df['annotation_label']\n",
    "valid_all_merged_features = valid_all_merged_df.drop(columns=['video_id', 'clip_id', 'annotation_label'])\n",
    "valid_all_merged_features = valid_all_merged_features.values.tolist()\n",
    "# Create datasets with the features and labels\n",
    "valid_all_merged_dataset = Dataset.from_dict({\n",
    "    'input_ids': valid_all_merged_features,\n",
    "    'labels': valid_all_merged_labels.tolist(),\n",
    "    'clip_id': valid_all_merged_df['clip_id'].tolist(),\n",
    "    'video_id': valid_all_merged_df['video_id'].tolist()\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2872b76d-8cb9-4770-820e-f356d7ef995e",
   "metadata": {
    "executionInfo": {
     "elapsed": 268,
     "status": "ok",
     "timestamp": 1740571928660,
     "user": {
      "displayName": "Kyparissis Kyparissis",
      "userId": "18280909670100413703"
     },
     "user_tz": -120
    },
    "id": "2872b76d-8cb9-4770-820e-f356d7ef995e"
   },
   "outputs": [],
   "source": [
    "test_all_merged_labels = test_all_merged_df['annotation_label']\n",
    "test_all_merged_features = test_all_merged_df.drop(columns=['video_id', 'clip_id', 'annotation_label'])\n",
    "test_all_merged_features = test_all_merged_features.values.tolist()\n",
    "# Create datasets with the features and labels\n",
    "test_all_merged_dataset = Dataset.from_dict({\n",
    "    'input_ids': test_all_merged_features,\n",
    "    'labels': test_all_merged_labels.tolist(),\n",
    "    'clip_id': test_all_merged_df['clip_id'].tolist(),\n",
    "    'video_id': test_all_merged_df['video_id'].tolist()\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59f226af-659b-4030-8257-11c2cddd72e8",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1740571929130,
     "user": {
      "displayName": "Kyparissis Kyparissis",
      "userId": "18280909670100413703"
     },
     "user_tz": -120
    },
    "id": "59f226af-659b-4030-8257-11c2cddd72e8"
   },
   "outputs": [],
   "source": [
    "# Create the DatasetDict to hold the subsets\n",
    "dataset_all_merged = DatasetDict({\n",
    "    'train': train_all_merged_dataset,\n",
    "    'valid': valid_all_merged_dataset,\n",
    "    'test': test_all_merged_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7207ef6d-7e3f-4aef-a6e9-fa1bc077669c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1740571930521,
     "user": {
      "displayName": "Kyparissis Kyparissis",
      "userId": "18280909670100413703"
     },
     "user_tz": -120
    },
    "id": "7207ef6d-7e3f-4aef-a6e9-fa1bc077669c",
    "outputId": "f59c23fd-32f9-475e-a799-847a7224b229"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'labels', 'clip_id', 'video_id'],\n",
       "        num_rows: 1284\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['input_ids', 'labels', 'clip_id', 'video_id'],\n",
       "        num_rows: 229\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'labels', 'clip_id', 'video_id'],\n",
       "        num_rows: 686\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_all_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7bd52b0a-ec41-4954-871e-8e532c50ffe9",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1740571932112,
     "user": {
      "displayName": "Kyparissis Kyparissis",
      "userId": "18280909670100413703"
     },
     "user_tz": -120
    },
    "id": "7bd52b0a-ec41-4954-871e-8e532c50ffe9"
   },
   "outputs": [],
   "source": [
    "class MLP_Model(nn.Module):\n",
    "    def __init__(self, layer_sizes, output_dim=2, dropout_p=0, act_func=\"tanh\"):\n",
    "        super(MLP_Model, self).__init__()\n",
    "        self.layer_sizes = layer_sizes\n",
    "        self.output_dim = output_dim\n",
    "        self.dropout_prob = dropout_p\n",
    "\n",
    "        # Create a list to hold all layers\n",
    "        self.layers = nn.ModuleList()\n",
    "\n",
    "        # Input layer normalization\n",
    "        # self.layer_norm1 = nn.LayerNorm(layer_sizes[0])\n",
    "\n",
    "        # Add the first layer\n",
    "        self.layers.append(nn.Linear(layer_sizes[0], layer_sizes[1]))\n",
    "\n",
    "        # Add intermediate layers\n",
    "        for i in range(1, len(layer_sizes) - 1):\n",
    "            self.layers.append(nn.Linear(layer_sizes[i], layer_sizes[i+1]))\n",
    "\n",
    "        # Output layer\n",
    "        self.out = nn.Linear(layer_sizes[-1], output_dim)\n",
    "\n",
    "        # Dropout and activation\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        if act_func == \"tanh\":\n",
    "            self.act = nn.Tanh()\n",
    "        elif act_func == \"relu\":\n",
    "            self.act = nn.ReLU()\n",
    "\n",
    "    def forward(self, x, labels=None):\n",
    "        # Apply LayerNorm to the input\n",
    "        # x = self.layer_norm1(x)\n",
    "\n",
    "        # Pass through all layers\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "            x = self.act(x)\n",
    "            x = self.dropout(x)\n",
    "\n",
    "        # Output layer\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "420d761f-e655-44ee-9bf4-a1fc139ea78e",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1740571937234,
     "user": {
      "displayName": "Kyparissis Kyparissis",
      "userId": "18280909670100413703"
     },
     "user_tz": -120
    },
    "id": "420d761f-e655-44ee-9bf4-a1fc139ea78e"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def collate_fn(batch):\n",
    "    # Convert lists to tensors\n",
    "    input_ids = torch.tensor([item['input_ids'] for item in batch], dtype=torch.float32)\n",
    "    labels = torch.tensor([item['labels'] for item in batch], dtype=torch.long)\n",
    "    video_ids = [item['video_id'] for item in batch]  # Store video_id\n",
    "    clip_ids = [item['clip_id'] for item in batch]  # Store clip_id\n",
    "\n",
    "    return {'input_ids': input_ids,\n",
    "            'labels': labels,\n",
    "            'video_id': video_ids,\n",
    "            'clip_id': clip_ids}\n",
    "\n",
    "# Convert datasets to DataLoaders\n",
    "train_all_loader = DataLoader(dataset_all_merged['train'], batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "valid_all_loader = DataLoader(dataset_all_merged['valid'], batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
    "test_all_loader = DataLoader(dataset_all_merged['test'], batch_size=32, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f9b46855-2d4e-49f8-a5c9-e3ac26e793a9",
   "metadata": {
    "executionInfo": {
     "elapsed": 49,
     "status": "ok",
     "timestamp": 1740572135355,
     "user": {
      "displayName": "Kyparissis Kyparissis",
      "userId": "18280909670100413703"
     },
     "user_tz": -120
    },
    "id": "f9b46855-2d4e-49f8-a5c9-e3ac26e793a9"
   },
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "layer_sizes_all = [(768+256+768), 1024, 1024, 512, 512]\n",
    "dropout_p_all = 0.1\n",
    "all_model = MLP_Model(layer_sizes=layer_sizes_all, dropout_p=dropout_p_all)\n",
    "\n",
    "# Move the model to the appropriate device (GPU if available)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "all_model.to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "all_criterion = nn.CrossEntropyLoss()  # Suitable for classification tasks\n",
    "all_optimizer = optim.AdamW(all_model.parameters(), lr=5e-5, weight_decay=1e-5)  # Adam optimizer with learning rate 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c21d3c4-dae2-4a2e-b6ec-52a5b1e1d052",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1740572136431,
     "user": {
      "displayName": "Kyparissis Kyparissis",
      "userId": "18280909670100413703"
     },
     "user_tz": -120
    },
    "id": "5c21d3c4-dae2-4a2e-b6ec-52a5b1e1d052",
    "outputId": "addf35fc-6643-4793-d727-d8b38d2ba232"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP_Model(\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=1792, out_features=1024, bias=True)\n",
       "    (1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "  )\n",
       "  (out): Linear(in_features=512, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (act): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "997687a2-80d7-4282-8f1d-5bc8abfd7a7a",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1740572137344,
     "user": {
      "displayName": "Kyparissis Kyparissis",
      "userId": "18280909670100413703"
     },
     "user_tz": -120
    },
    "id": "997687a2-80d7-4282-8f1d-5bc8abfd7a7a"
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion, optimizer):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []  # To store all predictions\n",
    "    all_labels = []  # To store all ground truth labels\n",
    "\n",
    "    for batch in train_loader:\n",
    "        input_ids = batch['input_ids'].to(device).float()\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(input_ids)  # Forward pass\n",
    "        loss = criterion(outputs, labels)  # Compute loss\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Update weights\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # Store predictions and labels\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Calculate average loss and accuracy\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    accuracy = correct / total\n",
    "\n",
    "    return avg_loss, accuracy, all_preds, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1cc3db3a-3226-4f00-b0f5-b443f8c0216d",
   "metadata": {
    "executionInfo": {
     "elapsed": 52,
     "status": "ok",
     "timestamp": 1740575355364,
     "user": {
      "displayName": "Kyparissis Kyparissis",
      "userId": "18280909670100413703"
     },
     "user_tz": -120
    },
    "id": "1cc3db3a-3226-4f00-b0f5-b443f8c0216d"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader, criterion, optimizer, track_clipVideo_id=False):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []  # To store all predictions\n",
    "    all_labels = []  # To store all ground truth labels\n",
    "    all_outputs = []\n",
    "\n",
    "    if track_clipVideo_id:\n",
    "        all_video_ids = []\n",
    "        all_clip_ids = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            input_ids = batch['input_ids'].to(device).float()\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids)  # Forward pass\n",
    "            loss = criterion(outputs, labels)  # Compute loss\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            # Store predictions and labels\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_outputs.extend(outputs.cpu().numpy())\n",
    "\n",
    "            # Store video_id and clip_id\n",
    "            if track_clipVideo_id:\n",
    "                all_video_ids.extend(batch['video_id'])  # Ensure batch contains these fields\n",
    "                all_clip_ids.extend(batch['clip_id'])\n",
    "\n",
    "    # Calculate average loss and accuracy\n",
    "    avg_loss = running_loss / len(data_loader)\n",
    "    accuracy = correct / total\n",
    "\n",
    "    if track_clipVideo_id:\n",
    "        return avg_loss, accuracy, all_preds, all_labels, all_outputs, all_video_ids, all_clip_ids\n",
    "    return avg_loss, accuracy, all_preds, all_labels, all_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "93f63e78-090f-4d97-9bbf-74aa361b9d43",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10467,
     "status": "ok",
     "timestamp": 1740572152674,
     "user": {
      "displayName": "Kyparissis Kyparissis",
      "userId": "18280909670100413703"
     },
     "user_tz": -120
    },
    "id": "93f63e78-090f-4d97-9bbf-74aa361b9d43",
    "outputId": "5226286a-6735-439e-9b64-911ec666573b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1 / 7\n",
      "Training Loss: 0.594\n",
      "Validation Loss: 0.958\n",
      "\n",
      " Epoch 2 / 7\n",
      "Training Loss: 0.479\n",
      "Validation Loss: 0.795\n",
      "\n",
      " Epoch 3 / 7\n",
      "Training Loss: 0.467\n",
      "Validation Loss: 0.848\n",
      "\n",
      " Epoch 4 / 7\n",
      "Training Loss: 0.461\n",
      "Validation Loss: 0.941\n",
      "\n",
      " Epoch 5 / 7\n",
      "Training Loss: 0.431\n",
      "Validation Loss: 0.780\n",
      "\n",
      " Epoch 6 / 7\n",
      "Training Loss: 0.422\n",
      "Validation Loss: 0.677\n",
      "\n",
      " Epoch 7 / 7\n",
      "Training Loss: 0.423\n",
      "Validation Loss: 0.909\n"
     ]
    }
   ],
   "source": [
    "# # Main training loop\n",
    "# epochs_all_model = 15\n",
    "\n",
    "# train_losses_all_model, valid_losses_all_model = [], []\n",
    "# best_valid_loss_all_model = float('inf')\n",
    "# best_valid_loss_epoch_all_model = 0\n",
    "\n",
    "# for epoch in range(epochs_all_model):\n",
    "#     print(f'\\n Epoch {epoch + 1} / {epochs_all_model}')\n",
    "\n",
    "#     # Training step\n",
    "#     train_loss_all_model, _, _, _ = train(all_model, train_all_loader, all_criterion, all_optimizer)\n",
    "#     train_losses_all_model.append(train_loss_all_model)\n",
    "\n",
    "#     # Validation step (optional)\n",
    "#     valid_loss_all_model, _, _, _, _  = evaluate(all_model, valid_all_loader, all_criterion, all_optimizer)\n",
    "#     valid_losses_all_model.append(valid_loss_all_model)\n",
    "\n",
    "#     print(f'Training Loss: {train_loss_all_model:.3f}')\n",
    "#     print(f'Validation Loss: {valid_loss_all_model:.3f}')\n",
    "\n",
    "#     # Save the model if it has the best validation loss so far\n",
    "#     if valid_loss_all_model <= best_valid_loss_all_model:   # If we find one with the same, keep the one with the biggest epoch\n",
    "#         best_valid_loss_all_model = valid_loss_all_model\n",
    "#         best_valid_loss_epoch_all_model = epoch + 1\n",
    "#         torch.save(all_model.state_dict(), 'MLP_ealyFusion_all_model_best_model_state.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6db9157e-dfff-4faf-933c-eb7f6b634cdc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1740572155031,
     "user": {
      "displayName": "Kyparissis Kyparissis",
      "userId": "18280909670100413703"
     },
     "user_tz": -120
    },
    "id": "6db9157e-dfff-4faf-933c-eb7f6b634cdc",
    "outputId": "d7109395-6f63-43b2-9dfa-c07d8b6cd8bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal epoch:  6\n"
     ]
    }
   ],
   "source": [
    "print(\"Optimal epoch: \", best_valid_loss_epoch_all_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ae55b1ea-bfd7-47ae-981f-a48e20cf6a41",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 54,
     "status": "ok",
     "timestamp": 1740572158427,
     "user": {
      "displayName": "Kyparissis Kyparissis",
      "userId": "18280909670100413703"
     },
     "user_tz": -120
    },
    "id": "ae55b1ea-bfd7-47ae-981f-a48e20cf6a41",
    "outputId": "c2c6664f-1918-4d7a-d510-68c21625ec7e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_557354/895741786.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  all_model_opt.load_state_dict(torch.load('MLP_ealyFusion_all_model_best_model_state.bin'))      # Load the saved state dictionary\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP_Model(\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=1792, out_features=1024, bias=True)\n",
       "    (1): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "  )\n",
       "  (out): Linear(in_features=512, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (act): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize a model and move it to GPU\n",
    "all_model_opt = MLP_Model(layer_sizes=layer_sizes_all, dropout_p=dropout_p_all)\n",
    "all_model_opt = all_model_opt.to(device)\n",
    "\n",
    "# Load\n",
    "all_model_opt.load_state_dict(torch.load('MLP_ealyFusion_all_model_best_model_state.bin'))      # Load the saved state dictionary\n",
    "all_model_opt.eval()                                                                # Set the model to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "347c3576-fe9f-482a-8170-7bea523ce18a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 886,
     "status": "ok",
     "timestamp": 1740575361226,
     "user": {
      "displayName": "Kyparissis Kyparissis",
      "userId": "18280909670100413703"
     },
     "user_tz": -120
    },
    "id": "347c3576-fe9f-482a-8170-7bea523ce18a",
    "outputId": "54a5ab36-820a-4546-f63a-83d2a24d5ca3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_557354/2779074390.py:6: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  labels = torch.tensor([item['labels'] for item in batch], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 0.6835\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have already created test_dataloader\n",
    "test_avg_loss_all_model, _, test_preds_all_model, _ , test_outputs_all_model, test_video_ids_all_model, test_clip_ids_all_model  = evaluate(all_model_opt, test_all_loader, all_criterion, all_optimizer, track_clipVideo_id=True)\n",
    "\n",
    "# Print the results\n",
    "print(f'Average Loss: {test_avg_loss_all_model:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e4fd1274-bdec-496b-897e-3d1680b0dbd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_557354/2830919683.py:2: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
      "  test_outputs_all_model = torch.tensor(test_outputs_all_model)  # Convert to tensor\n"
     ]
    }
   ],
   "source": [
    "# Apply softmax\n",
    "test_outputs_all_model = torch.tensor(test_outputs_all_model)  # Convert to tensor\n",
    "test_trimodal_probabilities = torch.nn.functional.softmax(test_outputs_all_model, dim=1).cpu().numpy()  # Compute probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "48hor1D1WiED",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 267,
     "status": "ok",
     "timestamp": 1740575394787,
     "user": {
      "displayName": "Kyparissis Kyparissis",
      "userId": "18280909670100413703"
     },
     "user_tz": -120
    },
    "id": "48hor1D1WiED",
    "outputId": "923601d1-6b10-4ac5-bd54-d2456ba2e1f9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.18063408, 0.819366  ],\n",
       "       [0.03664706, 0.963353  ],\n",
       "       [0.6669514 , 0.3330486 ],\n",
       "       ...,\n",
       "       [0.09317502, 0.90682495],\n",
       "       [0.3790978 , 0.62090224],\n",
       "       [0.15478534, 0.8452147 ]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_trimodal_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "012d79be-a0b2-40ee-8110-8250607847f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with the required information\n",
    "trimodal_test_results_df = pd.DataFrame({\n",
    "    'video_id': test_video_ids_all_model,\n",
    "    'clip_id': test_clip_ids_all_model,\n",
    "    'annotation_label': test_all_merged_labels,\n",
    "    'trimodal_prob_0': test_trimodal_probabilities[:, 0],  # Probability of class 0\n",
    "    'trimodal_prob_1': test_trimodal_probabilities[:, 1],   # Probability of class 1\n",
    "    'trimodal_preds': test_preds_all_model,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ba06829e-0dca-4585-9f45-2e075eea9eaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>clip_id</th>\n",
       "      <th>annotation_label</th>\n",
       "      <th>trimodal_prob_0</th>\n",
       "      <th>trimodal_prob_1</th>\n",
       "      <th>trimodal_preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1513</th>\n",
       "      <td>c7UH_rxdZv4</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.180634</td>\n",
       "      <td>0.819366</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1514</th>\n",
       "      <td>c7UH_rxdZv4</td>\n",
       "      <td>25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.036647</td>\n",
       "      <td>0.963353</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1515</th>\n",
       "      <td>c7UH_rxdZv4</td>\n",
       "      <td>26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666951</td>\n",
       "      <td>0.333049</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1516</th>\n",
       "      <td>c7UH_rxdZv4</td>\n",
       "      <td>27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.615005</td>\n",
       "      <td>0.384995</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1517</th>\n",
       "      <td>c7UH_rxdZv4</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.712141</td>\n",
       "      <td>0.287859</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2194</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.916739</td>\n",
       "      <td>0.083261</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2195</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.329535</td>\n",
       "      <td>0.670465</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>34</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.093175</td>\n",
       "      <td>0.906825</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2197</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.379098</td>\n",
       "      <td>0.620902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2198</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>32</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.154785</td>\n",
       "      <td>0.845215</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>686 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         video_id  clip_id  annotation_label  trimodal_prob_0  \\\n",
       "1513  c7UH_rxdZv4       24               0.0         0.180634   \n",
       "1514  c7UH_rxdZv4       25               1.0         0.036647   \n",
       "1515  c7UH_rxdZv4       26               0.0         0.666951   \n",
       "1516  c7UH_rxdZv4       27               0.0         0.615005   \n",
       "1517  c7UH_rxdZv4       20               0.0         0.712141   \n",
       "...           ...      ...               ...              ...   \n",
       "2194  zhpQhgha_KU       30               0.0         0.916739   \n",
       "2195  zhpQhgha_KU       35               1.0         0.329535   \n",
       "2196  zhpQhgha_KU       34               1.0         0.093175   \n",
       "2197  zhpQhgha_KU       33               0.0         0.379098   \n",
       "2198  zhpQhgha_KU       32               1.0         0.154785   \n",
       "\n",
       "      trimodal_prob_1  trimodal_preds  \n",
       "1513         0.819366               1  \n",
       "1514         0.963353               1  \n",
       "1515         0.333049               0  \n",
       "1516         0.384995               0  \n",
       "1517         0.287859               0  \n",
       "...               ...             ...  \n",
       "2194         0.083261               0  \n",
       "2195         0.670465               1  \n",
       "2196         0.906825               1  \n",
       "2197         0.620902               1  \n",
       "2198         0.845215               1  \n",
       "\n",
       "[686 rows x 6 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trimodal_test_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "20f4141b-a271-4f03-9cc5-c5ac209489dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6472303206997084\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "accuracy = (trimodal_test_results_df['annotation_label'] == trimodal_test_results_df['trimodal_preds']).mean()\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0959969e-d71e-494f-8061-5f40b761a44d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_557354/2779074390.py:6: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  labels = torch.tensor([item['labels'] for item in batch], dtype=torch.long)\n"
     ]
    }
   ],
   "source": [
    "valid_avg_loss_all_model, _, valid_preds_all_model, _ , valid_outputs_all_model, valid_video_ids_all_model, valid_clip_ids_all_model  = evaluate(all_model_opt, valid_all_loader, all_criterion, all_optimizer, track_clipVideo_id=True)\n",
    "# Apply softmax\n",
    "valid_outputs_all_model = torch.tensor(valid_outputs_all_model)  # Convert to tensor\n",
    "valid_trimodal_probabilities = torch.nn.functional.softmax(valid_outputs_all_model, dim=1).cpu().numpy()  # Compute probabilities\n",
    "# Create a DataFrame with the required information\n",
    "trimodal_valid_results_df = pd.DataFrame({\n",
    "    'video_id': valid_video_ids_all_model,\n",
    "    'clip_id': valid_clip_ids_all_model,\n",
    "    'annotation_label': valid_all_merged_labels,\n",
    "    'trimodal_prob_0': valid_trimodal_probabilities[:, 0],  # Probability of class 0\n",
    "    'trimodal_prob_1': valid_trimodal_probabilities[:, 1],   # Probability of class 1\n",
    "    'trimodal_preds': valid_preds_all_model,\n",
    "})\n",
    "\n",
    "trainSerial_all_loader = DataLoader(dataset_all_merged['train'], batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
    "train_avg_loss_all_model, _, train_preds_all_model, _ , train_outputs_all_model, train_video_ids_all_model, train_clip_ids_all_model  = evaluate(all_model_opt, trainSerial_all_loader, all_criterion, all_optimizer, track_clipVideo_id=True)\n",
    "# Apply softmax\n",
    "train_outputs_all_model = torch.tensor(train_outputs_all_model)  # Convert to tensor\n",
    "train_trimodal_probabilities = torch.nn.functional.softmax(train_outputs_all_model, dim=1).cpu().numpy()  # Compute probabilities\n",
    "# Create a DataFrame with the required information\n",
    "trimodal_train_results_df = pd.DataFrame({\n",
    "    'video_id': train_video_ids_all_model,\n",
    "    'clip_id': train_clip_ids_all_model,\n",
    "    'annotation_label': train_all_merged_labels,\n",
    "    'trimodal_prob_0': train_trimodal_probabilities[:, 0],  # Probability of class 0\n",
    "    'trimodal_prob_1': train_trimodal_probabilities[:, 1],   # Probability of class 1\n",
    "    'trimodal_preds': train_preds_all_model,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f8f1dfe3-be5d-47bb-bf59-5b36032523fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>clip_id</th>\n",
       "      <th>annotation_label</th>\n",
       "      <th>trimodal_prob_0</th>\n",
       "      <th>trimodal_prob_1</th>\n",
       "      <th>trimodal_preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1284</th>\n",
       "      <td>WKA5OygbEKI</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.625984</td>\n",
       "      <td>0.374015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1285</th>\n",
       "      <td>WKA5OygbEKI</td>\n",
       "      <td>21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.167053</td>\n",
       "      <td>0.832947</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1286</th>\n",
       "      <td>WKA5OygbEKI</td>\n",
       "      <td>22</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.051265</td>\n",
       "      <td>0.948735</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1287</th>\n",
       "      <td>WKA5OygbEKI</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.219811</td>\n",
       "      <td>0.780189</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1288</th>\n",
       "      <td>WKA5OygbEKI</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.126784</td>\n",
       "      <td>0.873216</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1508</th>\n",
       "      <td>c5xsKMxpXnc</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.165243</td>\n",
       "      <td>0.834757</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1509</th>\n",
       "      <td>c5xsKMxpXnc</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.189147</td>\n",
       "      <td>0.810853</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1510</th>\n",
       "      <td>c5xsKMxpXnc</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.480337</td>\n",
       "      <td>0.519663</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1511</th>\n",
       "      <td>c5xsKMxpXnc</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.804215</td>\n",
       "      <td>0.195785</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512</th>\n",
       "      <td>c5xsKMxpXnc</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.320049</td>\n",
       "      <td>0.679951</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>229 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         video_id  clip_id  annotation_label  trimodal_prob_0  \\\n",
       "1284  WKA5OygbEKI       20               1.0         0.625984   \n",
       "1285  WKA5OygbEKI       21               1.0         0.167053   \n",
       "1286  WKA5OygbEKI       22               1.0         0.051265   \n",
       "1287  WKA5OygbEKI        1               1.0         0.219811   \n",
       "1288  WKA5OygbEKI        3               1.0         0.126784   \n",
       "...           ...      ...               ...              ...   \n",
       "1508  c5xsKMxpXnc        4               1.0         0.165243   \n",
       "1509  c5xsKMxpXnc        7               0.0         0.189147   \n",
       "1510  c5xsKMxpXnc        6               0.0         0.480337   \n",
       "1511  c5xsKMxpXnc        9               0.0         0.804215   \n",
       "1512  c5xsKMxpXnc        8               0.0         0.320049   \n",
       "\n",
       "      trimodal_prob_1  trimodal_preds  \n",
       "1284         0.374015               0  \n",
       "1285         0.832947               1  \n",
       "1286         0.948735               1  \n",
       "1287         0.780189               1  \n",
       "1288         0.873216               1  \n",
       "...               ...             ...  \n",
       "1508         0.834757               1  \n",
       "1509         0.810853               1  \n",
       "1510         0.519663               1  \n",
       "1511         0.195785               0  \n",
       "1512         0.679951               1  \n",
       "\n",
       "[229 rows x 6 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trimodal_valid_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "59894081-d1c3-4e1c-a719-dd5d946104b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>clip_id</th>\n",
       "      <th>annotation_label</th>\n",
       "      <th>trimodal_prob_0</th>\n",
       "      <th>trimodal_prob_1</th>\n",
       "      <th>trimodal_preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.459776</td>\n",
       "      <td>0.540224</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.564226</td>\n",
       "      <td>0.435774</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.080895</td>\n",
       "      <td>0.919105</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.070363</td>\n",
       "      <td>0.929637</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.276498</td>\n",
       "      <td>0.723502</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1279</th>\n",
       "      <td>W8NXH0Djyww</td>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.886717</td>\n",
       "      <td>0.113283</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1280</th>\n",
       "      <td>W8NXH0Djyww</td>\n",
       "      <td>18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.268010</td>\n",
       "      <td>0.731990</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1281</th>\n",
       "      <td>W8NXH0Djyww</td>\n",
       "      <td>31</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.174045</td>\n",
       "      <td>0.825955</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1282</th>\n",
       "      <td>W8NXH0Djyww</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.123947</td>\n",
       "      <td>0.876053</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1283</th>\n",
       "      <td>W8NXH0Djyww</td>\n",
       "      <td>32</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.192672</td>\n",
       "      <td>0.807328</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1284 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         video_id  clip_id  annotation_label  trimodal_prob_0  \\\n",
       "0     03bSnISJMiM       11               0.0         0.459776   \n",
       "1     03bSnISJMiM       10               0.0         0.564226   \n",
       "2     03bSnISJMiM       13               1.0         0.080895   \n",
       "3     03bSnISJMiM       12               1.0         0.070363   \n",
       "4     03bSnISJMiM        1               1.0         0.276498   \n",
       "...           ...      ...               ...              ...   \n",
       "1279  W8NXH0Djyww       19               0.0         0.886717   \n",
       "1280  W8NXH0Djyww       18               1.0         0.268010   \n",
       "1281  W8NXH0Djyww       31               1.0         0.174045   \n",
       "1282  W8NXH0Djyww       30               0.0         0.123947   \n",
       "1283  W8NXH0Djyww       32               1.0         0.192672   \n",
       "\n",
       "      trimodal_prob_1  trimodal_preds  \n",
       "0            0.540224               1  \n",
       "1            0.435774               0  \n",
       "2            0.919105               1  \n",
       "3            0.929637               1  \n",
       "4            0.723502               1  \n",
       "...               ...             ...  \n",
       "1279         0.113283               0  \n",
       "1280         0.731990               1  \n",
       "1281         0.825955               1  \n",
       "1282         0.876053               1  \n",
       "1283         0.807328               1  \n",
       "\n",
       "[1284 rows x 6 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trimodal_train_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3cad3e1d-112f-4f52-8e87-2604ffa9b732",
   "metadata": {},
   "outputs": [],
   "source": [
    "trimodal_results_df = pd.concat([trimodal_train_results_df, trimodal_valid_results_df, trimodal_test_results_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f9183a79-5c99-4624-8a6c-b3381c725da6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>clip_id</th>\n",
       "      <th>annotation_label</th>\n",
       "      <th>trimodal_prob_0</th>\n",
       "      <th>trimodal_prob_1</th>\n",
       "      <th>trimodal_preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.459776</td>\n",
       "      <td>0.540224</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.564226</td>\n",
       "      <td>0.435774</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.080895</td>\n",
       "      <td>0.919105</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.070363</td>\n",
       "      <td>0.929637</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.276498</td>\n",
       "      <td>0.723502</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2194</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.916739</td>\n",
       "      <td>0.083261</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2195</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.329535</td>\n",
       "      <td>0.670465</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>34</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.093175</td>\n",
       "      <td>0.906825</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2197</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.379098</td>\n",
       "      <td>0.620902</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2198</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>32</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.154785</td>\n",
       "      <td>0.845215</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2199 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         video_id  clip_id  annotation_label  trimodal_prob_0  \\\n",
       "0     03bSnISJMiM       11               0.0         0.459776   \n",
       "1     03bSnISJMiM       10               0.0         0.564226   \n",
       "2     03bSnISJMiM       13               1.0         0.080895   \n",
       "3     03bSnISJMiM       12               1.0         0.070363   \n",
       "4     03bSnISJMiM        1               1.0         0.276498   \n",
       "...           ...      ...               ...              ...   \n",
       "2194  zhpQhgha_KU       30               0.0         0.916739   \n",
       "2195  zhpQhgha_KU       35               1.0         0.329535   \n",
       "2196  zhpQhgha_KU       34               1.0         0.093175   \n",
       "2197  zhpQhgha_KU       33               0.0         0.379098   \n",
       "2198  zhpQhgha_KU       32               1.0         0.154785   \n",
       "\n",
       "      trimodal_prob_1  trimodal_preds  \n",
       "0            0.540224               1  \n",
       "1            0.435774               0  \n",
       "2            0.919105               1  \n",
       "3            0.929637               1  \n",
       "4            0.723502               1  \n",
       "...               ...             ...  \n",
       "2194         0.083261               0  \n",
       "2195         0.670465               1  \n",
       "2196         0.906825               1  \n",
       "2197         0.620902               1  \n",
       "2198         0.845215               1  \n",
       "\n",
       "[2199 rows x 6 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trimodal_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ac9fd43e-977f-4b74-9e2e-d2cfa09349dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do the columns match? True\n",
      "Do the columns match? True\n"
     ]
    }
   ],
   "source": [
    "columns_to_check = ['video_id', 'clip_id', 'annotation_label']\n",
    "match1 = (trimodal_results_df[columns_to_check] == df1[columns_to_check]).all().all()\n",
    "\n",
    "print(f\"Do the columns match? {match1}\")\n",
    "\n",
    "match2 = trimodal_results_df[columns_to_check].equals(df1[columns_to_check])\n",
    "\n",
    "print(f\"Do the columns match? {match2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "86c32732-9096-41c5-a7dc-b9a98e8c6f2b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1740572161763,
     "user": {
      "displayName": "Kyparissis Kyparissis",
      "userId": "18280909670100413703"
     },
     "user_tz": -120
    },
    "id": "86c32732-9096-41c5-a7dc-b9a98e8c6f2b",
    "outputId": "202cd00e-77cf-47e6-e4a5-f8639871ebf9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7890    0.4934    0.6071       379\n",
      "         1.0     0.5724    0.8371    0.6799       307\n",
      "\n",
      "    accuracy                         0.6472       686\n",
      "   macro avg     0.6807    0.6653    0.6435       686\n",
      "weighted avg     0.6921    0.6472    0.6397       686\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the classification report\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(test_all_merged_labels, test_preds_all_model, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4dac42a4-6237-4201-a25b-af778b1496b3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 641
    },
    "executionInfo": {
     "elapsed": 543,
     "status": "ok",
     "timestamp": 1740572165233,
     "user": {
      "displayName": "Kyparissis Kyparissis",
      "userId": "18280909670100413703"
     },
     "user_tz": -120
    },
    "id": "4dac42a4-6237-4201-a25b-af778b1496b3",
    "outputId": "bd02bb37-4861-4548-e057-f2afa3b26234"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the size of the figure\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "# Create a heatmap from the confusion matrix\n",
    "confusion_matrix = pd.crosstab(test_all_merged_labels, test_preds_all_model)\n",
    "sns.heatmap(confusion_matrix,\n",
    "            annot=True,\n",
    "            fmt='d',\n",
    "            cmap='Blues',\n",
    "            cbar=True)\n",
    "\n",
    "# Set titles and labels\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a470211-2a27-423f-b0b2-8d1b1df4252d",
   "metadata": {
    "id": "9a470211-2a27-423f-b0b2-8d1b1df4252d"
   },
   "source": [
    "---\n",
    "---\n",
    "\n",
    "# Bimodal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f45d3a-09a0-4021-99ec-a12654f86755",
   "metadata": {
    "id": "21f45d3a-09a0-4021-99ec-a12654f86755"
   },
   "source": [
    "## Text and Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "75645b3c-2333-4f3c-9e1b-c0d8a926898a",
   "metadata": {
    "executionInfo": {
     "elapsed": 404,
     "status": "ok",
     "timestamp": 1740572228138,
     "user": {
      "displayName": "Kyparissis Kyparissis",
      "userId": "18280909670100413703"
     },
     "user_tz": -120
    },
    "id": "75645b3c-2333-4f3c-9e1b-c0d8a926898a"
   },
   "outputs": [],
   "source": [
    "train_text_audio_merged_labels = train_text_audio_merged_df['annotation_label']\n",
    "train_text_audio_merged_features = train_text_audio_merged_df.drop(columns=['video_id', 'clip_id', 'annotation_label'])\n",
    "train_text_audio_merged_features = train_text_audio_merged_features.values.tolist()\n",
    "# Create datasets with the features and labels\n",
    "train_text_audio_merged_dataset = Dataset.from_dict({\n",
    "    'input_ids': train_text_audio_merged_features,\n",
    "    'labels': train_text_audio_merged_labels.tolist(),\n",
    "    'clip_id': train_text_audio_merged_df['clip_id'].tolist(),\n",
    "    'video_id': train_text_audio_merged_df['video_id'].tolist()\n",
    "})\n",
    "\n",
    "valid_text_audio_merged_labels = valid_text_audio_merged_df['annotation_label']\n",
    "valid_text_audio_merged_features = valid_text_audio_merged_df.drop(columns=['video_id', 'clip_id', 'annotation_label'])\n",
    "valid_text_audio_merged_features = valid_text_audio_merged_features.values.tolist()\n",
    "# Create datasets with the features and labels\n",
    "valid_text_audio_merged_dataset = Dataset.from_dict({\n",
    "    'input_ids': valid_text_audio_merged_features,\n",
    "    'labels': valid_text_audio_merged_labels.tolist(),\n",
    "    'clip_id': valid_text_audio_merged_df['clip_id'].tolist(),\n",
    "    'video_id': valid_text_audio_merged_df['video_id'].tolist()\n",
    "})\n",
    "\n",
    "test_text_audio_merged_labels = test_text_audio_merged_df['annotation_label']\n",
    "test_text_audio_merged_features = test_text_audio_merged_df.drop(columns=['video_id', 'clip_id', 'annotation_label'])\n",
    "test_text_audio_merged_features = test_text_audio_merged_features.values.tolist()\n",
    "# Create datasets with the features and labels\n",
    "test_text_audio_merged_dataset = Dataset.from_dict({\n",
    "    'input_ids': test_text_audio_merged_features,\n",
    "    'labels': test_text_audio_merged_labels.tolist(),\n",
    "    'clip_id': test_text_audio_merged_df['clip_id'].tolist(),\n",
    "    'video_id': test_text_audio_merged_df['video_id'].tolist()\n",
    "})\n",
    "\n",
    "# Create the DatasetDict to hold the subsets\n",
    "dataset_text_audio_merged = DatasetDict({\n",
    "    'train': train_text_audio_merged_dataset,\n",
    "    'valid': valid_text_audio_merged_dataset,\n",
    "    'test': test_text_audio_merged_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "81a74f90-b98c-4c74-ac91-8607da115184",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1740575265826,
     "user": {
      "displayName": "Kyparissis Kyparissis",
      "userId": "18280909670100413703"
     },
     "user_tz": -120
    },
    "id": "81a74f90-b98c-4c74-ac91-8607da115184"
   },
   "outputs": [],
   "source": [
    "# Convert datasets to DataLoaders\n",
    "train_text_audio_loader = DataLoader(dataset_text_audio_merged['train'], batch_size=128, shuffle=True, collate_fn=collate_fn)\n",
    "valid_text_audio_loader = DataLoader(dataset_text_audio_merged['valid'], batch_size=128, shuffle=False, collate_fn=collate_fn)\n",
    "test_text_audio_loader = DataLoader(dataset_text_audio_merged['test'], batch_size=1, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "39eb3c6b-0977-4e57-93c8-63414ba122b1",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1740572229587,
     "user": {
      "displayName": "Kyparissis Kyparissis",
      "userId": "18280909670100413703"
     },
     "user_tz": -120
    },
    "id": "39eb3c6b-0977-4e57-93c8-63414ba122b1"
   },
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "layer_sizes_text_audio = [1024, 32]\n",
    "dropout_p_text_audio = 0.3\n",
    "text_audio_model = MLP_Model(layer_sizes=layer_sizes_text_audio, dropout_p=dropout_p_text_audio, act_func=\"relu\")\n",
    "\n",
    "# Move the model to the appropriate device (GPU if available)\n",
    "text_audio_model.to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "text_audio_criterion = nn.CrossEntropyLoss()  # Suitable for classification tasks\n",
    "text_audio_optimizer = optim.AdamW(text_audio_model.parameters(), lr=5e-6, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3543b8c2-78f0-458e-ac8b-37a639b4a7c2",
   "metadata": {
    "id": "3543b8c2-78f0-458e-ac8b-37a639b4a7c2"
   },
   "outputs": [],
   "source": [
    "# import itertools\n",
    "# import torch.optim as optim\n",
    "# def grid_search(layer_size_options, dropout_options, act_func_options, batch_options, lr_options, weightdecay_options,\n",
    "#                 train_set, valid_set,\n",
    "#                 device,\n",
    "#                 max_epochs=15):\n",
    "#     best_model = None\n",
    "#     best_valid_accuracy = 0.0\n",
    "#     best_params = None\n",
    "#     best_epoch = 0\n",
    "\n",
    "#     param_combinations = list(itertools.product(layer_size_options, dropout_options, act_func_options, batch_options, lr_options, weightdecay_options))\n",
    "\n",
    "#     model_versions = []  # Store the best model for each hyperparameter combination\n",
    "\n",
    "#     for layer_sizes, dropout_p, act_func, batch_size, lr, wd in param_combinations:\n",
    "#         print(f\"Testing configuration: layer_sizes={layer_sizes}, dropout_p={dropout_p}, act_func={act_func}, batch_size={batch_size} , lr={lr}, wd={wd}\")\n",
    "\n",
    "#         train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "#         valid_loader = DataLoader(valid_set, batch_size=128, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "#         # Initialize the model\n",
    "#         model = MLP_Model(layer_sizes=layer_sizes, dropout_p=dropout_p, act_func=act_func)\n",
    "#         model.to(device)\n",
    "\n",
    "#         criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#         # Define optimizer\n",
    "#         optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=wd)\n",
    "\n",
    "#         best_loss_for_config = float('inf')\n",
    "#         best_accuracy_for_config = 0.0\n",
    "#         best_epoch_for_config = 0\n",
    "#         best_model_for_config = None\n",
    "\n",
    "#         for epoch in range(max_epochs):\n",
    "#             # print(f'Epoch {epoch + 1} / {max_epochs}')\n",
    "#             train_loss, _, _, _ = train(model, train_loader, criterion, optimizer)\n",
    "#             valid_loss, valid_accuracy, _, _ = evaluate(model, valid_loader, criterion, optimizer)\n",
    "\n",
    "#             # print(f'Validation Loss: {valid_loss:.3f}, Validation Accuracy: {valid_accuracy:.3f}')\n",
    "\n",
    "#             if valid_loss < best_loss_for_config:\n",
    "#                 best_loss_for_config = valid_loss\n",
    "#                 best_accuracy_for_config = valid_accuracy\n",
    "#                 best_epoch_for_config = epoch + 1\n",
    "#                 best_model_for_config = model\n",
    "#                 torch.save(model.state_dict(), f'model_config_{layer_sizes}_{dropout_p}_{act_func}_best.bin')\n",
    "\n",
    "#         model_versions.append((best_accuracy_for_config, best_loss_for_config, best_model_for_config, layer_sizes, dropout_p, act_func, best_epoch_for_config))\n",
    "\n",
    "#     # Select the best model: highest accuracy among the best-loss models\n",
    "#     model_versions.sort(key=lambda x: -x[0])  # Sort by accuracy (descending)\n",
    "#     best_valid_accuracy, best_valid_loss, best_model, best_layer_sizes, best_dropout_p, best_act_func, best_epoch = model_versions[0]\n",
    "\n",
    "#     print(f'Best Configuration: layer_sizes={best_layer_sizes}, dropout_p={best_dropout_p}, act_func={best_act_func}')\n",
    "#     print(f'Best Validation Loss: {best_valid_loss:.3f}, Best Validation Accuracy: {best_valid_accuracy:.3f}, Best Epoch: {best_epoch}')\n",
    "\n",
    "#     return best_model, (best_layer_sizes, best_dropout_p, best_act_func)\n",
    "\n",
    "# # Define parameter search space\n",
    "# layer_sizes_options = [[1024, 1024],\n",
    "#                        [1024, 512],\n",
    "#                        [1024, 256],\n",
    "#                        [1024, 128],\n",
    "#                        [1024, 32],\n",
    "#                        [1024, 1024, 512],\n",
    "#                        [1024, 1024, 256],\n",
    "#                        [1024, 1024, 128],\n",
    "#                        [1024, 1024, 32],\n",
    "#                        [1024, 512, 256],\n",
    "#                        [1024, 512, 128],\n",
    "#                        [1024, 512, 32],\n",
    "#                        [1024, 1024, 512, 256],\n",
    "#                        [1024, 1024, 512, 128],\n",
    "#                        [1024, 1024, 512, 32],\n",
    "#                        [1024, 512, 256, 128],\n",
    "#                        [1024, 512, 256, 32],\n",
    "#                        [1024, 512, 128, 32],\n",
    "#                        [1024, 1024, 512, 256, 128],\n",
    "#                        [1024, 1024, 512, 256, 32],\n",
    "#                        [1024, 1024, 512, 128, 32],\n",
    "#                        [1024, 512, 256, 128, 64],\n",
    "#                        [1024, 512, 256, 128, 32]]\n",
    "# batch_options = [16, 32, 64, 128, 256]\n",
    "# lr_options = [5e-5, 1e-5, 5e-6]\n",
    "# weightdecay_options = [1e-3, 1e-4, 1e-5]\n",
    "# dropout_options = [0.1, 0.3, 0.5]\n",
    "# act_func_options = [\"tanh\", \"relu\"]\n",
    "\n",
    "# # Run grid search\n",
    "# best_model, best_params = grid_search(\n",
    "#     layer_sizes_options, dropout_options, act_func_options, batch_options, lr_options, weightdecay_options,\n",
    "#     dataset_text_audio_merged['train'], dataset_text_audio_merged['valid'],\n",
    "#     device\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "673feb90-5e3a-45b1-a8ca-2f696820e7e6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11220,
     "status": "ok",
     "timestamp": 1740572244892,
     "user": {
      "displayName": "Kyparissis Kyparissis",
      "userId": "18280909670100413703"
     },
     "user_tz": -120
    },
    "id": "673feb90-5e3a-45b1-a8ca-2f696820e7e6",
    "outputId": "d364379a-38c5-430e-f5dc-aae74d06fb7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1 / 15\n",
      "Training Loss: 0.696\n",
      "Validation Loss: 0.625\n",
      "\n",
      " Epoch 2 / 15\n",
      "Training Loss: 0.687\n",
      "Validation Loss: 0.623\n",
      "\n",
      " Epoch 3 / 15\n",
      "Training Loss: 0.701\n",
      "Validation Loss: 0.621\n",
      "\n",
      " Epoch 4 / 15\n",
      "Training Loss: 0.694\n",
      "Validation Loss: 0.621\n",
      "\n",
      " Epoch 5 / 15\n",
      "Training Loss: 0.693\n",
      "Validation Loss: 0.622\n",
      "\n",
      " Epoch 6 / 15\n",
      "Training Loss: 0.686\n",
      "Validation Loss: 0.624\n",
      "\n",
      " Epoch 7 / 15\n",
      "Training Loss: 0.690\n",
      "Validation Loss: 0.625\n",
      "\n",
      " Epoch 8 / 15\n",
      "Training Loss: 0.691\n",
      "Validation Loss: 0.626\n",
      "\n",
      " Epoch 9 / 15\n",
      "Training Loss: 0.687\n",
      "Validation Loss: 0.628\n",
      "\n",
      " Epoch 10 / 15\n",
      "Training Loss: 0.692\n",
      "Validation Loss: 0.632\n",
      "\n",
      " Epoch 11 / 15\n",
      "Training Loss: 0.676\n",
      "Validation Loss: 0.635\n",
      "\n",
      " Epoch 12 / 15\n",
      "Training Loss: 0.673\n",
      "Validation Loss: 0.637\n",
      "\n",
      " Epoch 13 / 15\n",
      "Training Loss: 0.675\n",
      "Validation Loss: 0.636\n",
      "\n",
      " Epoch 14 / 15\n",
      "Training Loss: 0.676\n",
      "Validation Loss: 0.632\n",
      "\n",
      " Epoch 15 / 15\n",
      "Training Loss: 0.673\n",
      "Validation Loss: 0.630\n"
     ]
    }
   ],
   "source": [
    "# # Main training loop\n",
    "# epochs_text_audio_model = 15\n",
    "\n",
    "# train_losses_text_audio_model, valid_losses_text_audio_model = [], []\n",
    "# best_valid_loss_text_audio_model = float('inf')\n",
    "# best_valid_loss_epoch_text_audio_model = 0\n",
    "\n",
    "# for epoch in range(epochs_text_audio_model):\n",
    "#     print(f'\\n Epoch {epoch + 1} / {epochs_text_audio_model}')\n",
    "\n",
    "#     # Training step\n",
    "#     train_loss_text_audio_model, _, _, _ = train(text_audio_model, train_text_audio_loader, text_audio_criterion, text_audio_optimizer)\n",
    "#     train_losses_text_audio_model.append(train_loss_text_audio_model)\n",
    "\n",
    "#     # Validation step (optional)\n",
    "#     valid_loss_text_audio_model, _, _, _, _  = evaluate(text_audio_model, valid_text_audio_loader, text_audio_criterion, text_audio_optimizer)\n",
    "#     valid_losses_text_audio_model.append(valid_loss_text_audio_model)\n",
    "\n",
    "#     print(f'Training Loss: {train_loss_text_audio_model:.3f}')\n",
    "#     print(f'Validation Loss: {valid_loss_text_audio_model:.3f}')\n",
    "\n",
    "#     # Save the model if it has the best validation loss so far\n",
    "#     if valid_loss_text_audio_model <= best_valid_loss_text_audio_model:   # If we find one with the same, keep the one with the biggest epoch\n",
    "#         best_valid_loss_text_audio_model = valid_loss_text_audio_model\n",
    "#         best_valid_loss_epoch_text_audio_model = epoch + 1\n",
    "#         torch.save(text_audio_model.state_dict(), 'MLP_ealyFusion_text_audio_model_best_model_state.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f01c0134-33f7-4fe1-8bc6-4ce524f4c355",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1740572247477,
     "user": {
      "displayName": "Kyparissis Kyparissis",
      "userId": "18280909670100413703"
     },
     "user_tz": -120
    },
    "id": "f01c0134-33f7-4fe1-8bc6-4ce524f4c355",
    "outputId": "67ba82d3-8265-4226-b158-a463e24f82ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal epoch:  4\n"
     ]
    }
   ],
   "source": [
    "print(\"Optimal epoch: \", best_valid_loss_epoch_text_audio_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ce43a497-a471-420f-a68a-1ee7d9b0ca4a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 45,
     "status": "ok",
     "timestamp": 1740572248500,
     "user": {
      "displayName": "Kyparissis Kyparissis",
      "userId": "18280909670100413703"
     },
     "user_tz": -120
    },
    "id": "ce43a497-a471-420f-a68a-1ee7d9b0ca4a",
    "outputId": "ef5e0aa6-4258-4187-bdbb-e14e12134d07"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_557354/2246518797.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  text_audio_model_opt.load_state_dict(torch.load('MLP_ealyFusion_text_audio_model_best_model_state.bin'))      # Load the saved state dictionary\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP_Model(\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=1024, out_features=32, bias=True)\n",
       "  )\n",
       "  (out): Linear(in_features=32, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (act): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize a model and move it to GPU\n",
    "text_audio_model_opt = MLP_Model(layer_sizes=layer_sizes_text_audio, dropout_p=dropout_p_text_audio)\n",
    "text_audio_model_opt = text_audio_model_opt.to(device)\n",
    "\n",
    "# Load\n",
    "text_audio_model_opt.load_state_dict(torch.load('MLP_ealyFusion_text_audio_model_best_model_state.bin'))      # Load the saved state dictionary\n",
    "text_audio_model_opt.eval()                                                                # Set the model to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "808e4c64-2cf1-442d-88f2-0aa930556c8e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 801,
     "status": "ok",
     "timestamp": 1740575408671,
     "user": {
      "displayName": "Kyparissis Kyparissis",
      "userId": "18280909670100413703"
     },
     "user_tz": -120
    },
    "id": "808e4c64-2cf1-442d-88f2-0aa930556c8e",
    "outputId": "dbc84c55-43d0-428d-d180-887aa6cfec63"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_557354/2779074390.py:6: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  labels = torch.tensor([item['labels'] for item in batch], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 0.5946\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have already created test_dataloader\n",
    "test_avg_loss_text_audio_model, _, test_preds_text_audio_model, _ , test_outputs_text_audio_model, test_video_ids_text_audio_model, test_clip_ids_text_audio_model  = evaluate(text_audio_model_opt, test_text_audio_loader, text_audio_criterion, text_audio_optimizer, track_clipVideo_id=True)\n",
    "\n",
    "# Print the results\n",
    "print(f'Average Loss: {test_avg_loss_text_audio_model:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "gTV2LqPuXWF4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 131,
     "status": "ok",
     "timestamp": 1740575409517,
     "user": {
      "displayName": "Kyparissis Kyparissis",
      "userId": "18280909670100413703"
     },
     "user_tz": -120
    },
    "id": "gTV2LqPuXWF4",
    "outputId": "039cfb07-98b8-424f-e47d-aa10e068c472"
   },
   "outputs": [],
   "source": [
    "# Apply softmax\n",
    "test_outputs_text_audio_model = torch.tensor(test_outputs_text_audio_model)  # Convert to tensor\n",
    "test_text_audio_probabilities = torch.nn.functional.softmax(test_outputs_text_audio_model, dim=1).cpu().numpy()  # Compute probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bcb3844c-9e18-428a-bff4-92b9663430ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5314093 , 0.46859065],\n",
       "       [0.34380442, 0.65619564],\n",
       "       [0.5437573 , 0.45624265],\n",
       "       ...,\n",
       "       [0.34493247, 0.65506756],\n",
       "       [0.4818356 , 0.51816434],\n",
       "       [0.36118698, 0.638813  ]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text_audio_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "27885ff2-8d22-4716-9792-abbbef1b1f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with the required information\n",
    "text_audio_test_results_df = pd.DataFrame({\n",
    "    'video_id': test_video_ids_text_audio_model,\n",
    "    'clip_id': test_clip_ids_text_audio_model,\n",
    "    'annotation_label': test_text_audio_merged_labels,\n",
    "    'text_audio_prob_0': test_text_audio_probabilities[:, 0],  # Probability of class 0\n",
    "    'text_audio_prob_1': test_text_audio_probabilities[:, 1],   # Probability of class 1\n",
    "    'text_audio_preds': test_preds_text_audio_model,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1ef43b37-6b43-48d5-a1f0-ce04c9df43fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>clip_id</th>\n",
       "      <th>annotation_label</th>\n",
       "      <th>text_audio_prob_0</th>\n",
       "      <th>text_audio_prob_1</th>\n",
       "      <th>text_audio_preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1513</th>\n",
       "      <td>c7UH_rxdZv4</td>\n",
       "      <td>24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.531409</td>\n",
       "      <td>0.468591</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1514</th>\n",
       "      <td>c7UH_rxdZv4</td>\n",
       "      <td>25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.343804</td>\n",
       "      <td>0.656196</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1515</th>\n",
       "      <td>c7UH_rxdZv4</td>\n",
       "      <td>26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.543757</td>\n",
       "      <td>0.456243</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1516</th>\n",
       "      <td>c7UH_rxdZv4</td>\n",
       "      <td>27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.563868</td>\n",
       "      <td>0.436132</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1517</th>\n",
       "      <td>c7UH_rxdZv4</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.563983</td>\n",
       "      <td>0.436017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2194</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.559317</td>\n",
       "      <td>0.440684</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2195</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.334322</td>\n",
       "      <td>0.665678</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>34</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.344932</td>\n",
       "      <td>0.655068</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2197</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.481836</td>\n",
       "      <td>0.518164</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2198</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>32</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.361187</td>\n",
       "      <td>0.638813</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>686 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         video_id  clip_id  annotation_label  text_audio_prob_0  \\\n",
       "1513  c7UH_rxdZv4       24               0.0           0.531409   \n",
       "1514  c7UH_rxdZv4       25               1.0           0.343804   \n",
       "1515  c7UH_rxdZv4       26               0.0           0.543757   \n",
       "1516  c7UH_rxdZv4       27               0.0           0.563868   \n",
       "1517  c7UH_rxdZv4       20               0.0           0.563983   \n",
       "...           ...      ...               ...                ...   \n",
       "2194  zhpQhgha_KU       30               0.0           0.559317   \n",
       "2195  zhpQhgha_KU       35               1.0           0.334322   \n",
       "2196  zhpQhgha_KU       34               1.0           0.344932   \n",
       "2197  zhpQhgha_KU       33               0.0           0.481836   \n",
       "2198  zhpQhgha_KU       32               1.0           0.361187   \n",
       "\n",
       "      text_audio_prob_1  text_audio_preds  \n",
       "1513           0.468591                 0  \n",
       "1514           0.656196                 1  \n",
       "1515           0.456243                 0  \n",
       "1516           0.436132                 0  \n",
       "1517           0.436017                 0  \n",
       "...                 ...               ...  \n",
       "2194           0.440684                 0  \n",
       "2195           0.665678                 1  \n",
       "2196           0.655068                 1  \n",
       "2197           0.518164                 1  \n",
       "2198           0.638813                 1  \n",
       "\n",
       "[686 rows x 6 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_audio_test_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "043382df-919a-4829-a8db-e6f24e85e03d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8367346938775511\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "accuracy = (text_audio_test_results_df['annotation_label'] == text_audio_test_results_df['text_audio_preds']).mean()\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cd27024c-1b0a-43a1-96ba-1e80de3881fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_557354/2779074390.py:6: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  labels = torch.tensor([item['labels'] for item in batch], dtype=torch.long)\n"
     ]
    }
   ],
   "source": [
    "valid_avg_loss_text_audio_model, _, valid_preds_text_audio_model, _ , valid_outputs_text_audio_model, valid_video_ids_text_audio_model, valid_clip_ids_text_audio_model  = evaluate(text_audio_model_opt, valid_text_audio_loader, text_audio_criterion, text_audio_optimizer, track_clipVideo_id=True)\n",
    "# Apply softmax\n",
    "valid_outputs_text_audio_model = torch.tensor(valid_outputs_text_audio_model)  # Convert to tensor\n",
    "valid_text_audio_probabilities = torch.nn.functional.softmax(valid_outputs_text_audio_model, dim=1).cpu().numpy()  # Compute probabilities\n",
    "# Create a DataFrame with the required information\n",
    "text_audio_valid_results_df = pd.DataFrame({\n",
    "    'video_id': valid_video_ids_text_audio_model,\n",
    "    'clip_id': valid_clip_ids_text_audio_model,\n",
    "    'annotation_label': valid_text_audio_merged_labels,\n",
    "    'text_audio_prob_0': valid_text_audio_probabilities[:, 0],  # Probability of class 0\n",
    "    'text_audio_prob_1': valid_text_audio_probabilities[:, 1],   # Probability of class 1\n",
    "    'text_audio_preds': valid_preds_text_audio_model,\n",
    "})\n",
    "\n",
    "trainSerial_text_audio_loader = DataLoader(dataset_text_audio_merged['train'], batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
    "train_avg_loss_text_audio_model, _, train_preds_text_audio_model, _ , train_outputs_text_audio_model, train_video_ids_text_audio_model, train_clip_ids_text_audio_model  = evaluate(text_audio_model_opt, trainSerial_text_audio_loader, text_audio_criterion, text_audio_optimizer, track_clipVideo_id=True)\n",
    "# Apply softmax\n",
    "train_outputs_text_audio_model = torch.tensor(train_outputs_text_audio_model)  # Convert to tensor\n",
    "train_text_audio_probabilities = torch.nn.functional.softmax(train_outputs_text_audio_model, dim=1).cpu().numpy()  # Compute probabilities\n",
    "# Create a DataFrame with the required information\n",
    "text_audio_train_results_df = pd.DataFrame({\n",
    "    'video_id': train_video_ids_text_audio_model,\n",
    "    'clip_id': train_clip_ids_text_audio_model,\n",
    "    'annotation_label': train_text_audio_merged_labels,\n",
    "    'text_audio_prob_0': train_text_audio_probabilities[:, 0],  # Probability of class 0\n",
    "    'text_audio_prob_1': train_text_audio_probabilities[:, 1],   # Probability of class 1\n",
    "    'text_audio_preds': train_preds_text_audio_model,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6ff7f2f8-a590-44bc-996b-519740fffafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_audio_results_df = pd.concat([text_audio_train_results_df, text_audio_valid_results_df, text_audio_test_results_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "46a4efda-c0df-435f-bd5e-1ae50d63d371",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>clip_id</th>\n",
       "      <th>annotation_label</th>\n",
       "      <th>text_audio_prob_0</th>\n",
       "      <th>text_audio_prob_1</th>\n",
       "      <th>text_audio_preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.545542</td>\n",
       "      <td>0.454458</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.546001</td>\n",
       "      <td>0.453999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.354512</td>\n",
       "      <td>0.645488</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.349426</td>\n",
       "      <td>0.650574</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.516387</td>\n",
       "      <td>0.483613</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2194</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.559317</td>\n",
       "      <td>0.440684</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2195</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.334322</td>\n",
       "      <td>0.665678</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>34</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.344932</td>\n",
       "      <td>0.655068</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2197</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.481836</td>\n",
       "      <td>0.518164</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2198</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>32</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.361187</td>\n",
       "      <td>0.638813</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2199 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         video_id  clip_id  annotation_label  text_audio_prob_0  \\\n",
       "0     03bSnISJMiM       11               0.0           0.545542   \n",
       "1     03bSnISJMiM       10               0.0           0.546001   \n",
       "2     03bSnISJMiM       13               1.0           0.354512   \n",
       "3     03bSnISJMiM       12               1.0           0.349426   \n",
       "4     03bSnISJMiM        1               1.0           0.516387   \n",
       "...           ...      ...               ...                ...   \n",
       "2194  zhpQhgha_KU       30               0.0           0.559317   \n",
       "2195  zhpQhgha_KU       35               1.0           0.334322   \n",
       "2196  zhpQhgha_KU       34               1.0           0.344932   \n",
       "2197  zhpQhgha_KU       33               0.0           0.481836   \n",
       "2198  zhpQhgha_KU       32               1.0           0.361187   \n",
       "\n",
       "      text_audio_prob_1  text_audio_preds  \n",
       "0              0.454458                 0  \n",
       "1              0.453999                 0  \n",
       "2              0.645488                 1  \n",
       "3              0.650574                 1  \n",
       "4              0.483613                 0  \n",
       "...                 ...               ...  \n",
       "2194           0.440684                 0  \n",
       "2195           0.665678                 1  \n",
       "2196           0.655068                 1  \n",
       "2197           0.518164                 1  \n",
       "2198           0.638813                 1  \n",
       "\n",
       "[2199 rows x 6 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_audio_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "83adf78a-6c15-4b43-8039-36a7c42b6434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do the columns match? True\n",
      "Do the columns match? True\n"
     ]
    }
   ],
   "source": [
    "columns_to_check = ['video_id', 'clip_id', 'annotation_label']\n",
    "match1 = (text_audio_results_df[columns_to_check] == df1[columns_to_check]).all().all()\n",
    "\n",
    "print(f\"Do the columns match? {match1}\")\n",
    "\n",
    "match2 = text_audio_results_df[columns_to_check].equals(df1[columns_to_check])\n",
    "\n",
    "print(f\"Do the columns match? {match2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "09a08dc9-240f-49cc-b5e4-9abde43d3db1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1740575421649,
     "user": {
      "displayName": "Kyparissis Kyparissis",
      "userId": "18280909670100413703"
     },
     "user_tz": -120
    },
    "id": "09a08dc9-240f-49cc-b5e4-9abde43d3db1",
    "outputId": "94eb3452-ba67-4ba1-bf39-0c2b70869354"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8719    0.8259    0.8482       379\n",
      "         1.0     0.7982    0.8502    0.8233       307\n",
      "\n",
      "    accuracy                         0.8367       686\n",
      "   macro avg     0.8350    0.8380    0.8358       686\n",
      "weighted avg     0.8389    0.8367    0.8371       686\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_text_audio_merged_labels, test_preds_text_audio_model, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338c81b4-49b6-43d0-b58d-99e3971d565f",
   "metadata": {
    "id": "338c81b4-49b6-43d0-b58d-99e3971d565f"
   },
   "source": [
    "---\n",
    "## Text and Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d05a5f11-df99-4146-a481-a5a3a637acf2",
   "metadata": {
    "executionInfo": {
     "elapsed": 593,
     "status": "ok",
     "timestamp": 1740572275708,
     "user": {
      "displayName": "Kyparissis Kyparissis",
      "userId": "18280909670100413703"
     },
     "user_tz": -120
    },
    "id": "d05a5f11-df99-4146-a481-a5a3a637acf2"
   },
   "outputs": [],
   "source": [
    "train_text_video_merged_labels = train_text_video_merged_df['annotation_label']\n",
    "train_text_video_merged_features = train_text_video_merged_df.drop(columns=['video_id', 'clip_id', 'annotation_label'])\n",
    "train_text_video_merged_features = train_text_video_merged_features.values.tolist()\n",
    "# Create datasets with the features and labels\n",
    "train_text_video_merged_dataset = Dataset.from_dict({\n",
    "    'input_ids': train_text_video_merged_features,\n",
    "    'labels': train_text_video_merged_labels.tolist(),\n",
    "    'clip_id': train_text_video_merged_df['clip_id'].tolist(),\n",
    "    'video_id': train_text_video_merged_df['video_id'].tolist()\n",
    "})\n",
    "\n",
    "valid_text_video_merged_labels = valid_text_video_merged_df['annotation_label']\n",
    "valid_text_video_merged_features = valid_text_video_merged_df.drop(columns=['video_id', 'clip_id', 'annotation_label'])\n",
    "valid_text_video_merged_features = valid_text_video_merged_features.values.tolist()\n",
    "# Create datasets with the features and labels\n",
    "valid_text_video_merged_dataset = Dataset.from_dict({\n",
    "    'input_ids': valid_text_video_merged_features,\n",
    "    'labels': valid_text_video_merged_labels.tolist(),\n",
    "    'clip_id': valid_text_video_merged_df['clip_id'].tolist(),\n",
    "    'video_id': valid_text_video_merged_df['video_id'].tolist()\n",
    "})\n",
    "\n",
    "test_text_video_merged_labels = test_text_video_merged_df['annotation_label']\n",
    "test_text_video_merged_features = test_text_video_merged_df.drop(columns=['video_id', 'clip_id', 'annotation_label'])\n",
    "test_text_video_merged_features = test_text_video_merged_features.values.tolist()\n",
    "# Create datasets with the features and labels\n",
    "test_text_video_merged_dataset = Dataset.from_dict({\n",
    "    'input_ids': test_text_video_merged_features,\n",
    "    'labels': test_text_video_merged_labels.tolist(),\n",
    "    'clip_id': test_text_video_merged_df['clip_id'].tolist(),\n",
    "    'video_id': test_text_video_merged_df['video_id'].tolist()\n",
    "})\n",
    "\n",
    "# Create the DatasetDict to hold the subsets\n",
    "dataset_text_video_merged = DatasetDict({\n",
    "    'train': train_text_video_merged_dataset,\n",
    "    'valid': valid_text_video_merged_dataset,\n",
    "    'test': test_text_video_merged_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "42f3b1ff-5f77-4754-937d-7121e2ab7d3a",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1740572276847,
     "user": {
      "displayName": "Kyparissis Kyparissis",
      "userId": "18280909670100413703"
     },
     "user_tz": -120
    },
    "id": "42f3b1ff-5f77-4754-937d-7121e2ab7d3a"
   },
   "outputs": [],
   "source": [
    "# Convert datasets to DataLoaders\n",
    "train_text_video_loader = DataLoader(dataset_text_video_merged['train'], batch_size=128, shuffle=True, collate_fn=collate_fn)\n",
    "valid_text_video_loader = DataLoader(dataset_text_video_merged['valid'], batch_size=128, shuffle=False, collate_fn=collate_fn)\n",
    "test_text_video_loader = DataLoader(dataset_text_video_merged['test'], batch_size=128, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "534d50fb-8e13-4a3f-ac70-9c40b1d547f6",
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1740572277435,
     "user": {
      "displayName": "Kyparissis Kyparissis",
      "userId": "18280909670100413703"
     },
     "user_tz": -120
    },
    "id": "534d50fb-8e13-4a3f-ac70-9c40b1d547f6"
   },
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "layer_sizes_text_video = [(768+768), 256]\n",
    "dropout_p_text_video = 0.1\n",
    "text_video_model = MLP_Model(layer_sizes=layer_sizes_text_video, dropout_p=dropout_p_text_video, act_func=\"relu\")\n",
    "\n",
    "# Move the model to the appropriate device (GPU if available)\n",
    "text_video_model.to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "text_video_criterion = nn.CrossEntropyLoss()  # Suitable for classification tasks\n",
    "text_video_optimizer = optim.AdamW(text_video_model.parameters(), lr=5e-6, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "07b8574b-39df-45df-85a8-da92c957b0f7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11067,
     "status": "ok",
     "timestamp": 1740572292551,
     "user": {
      "displayName": "Kyparissis Kyparissis",
      "userId": "18280909670100413703"
     },
     "user_tz": -120
    },
    "id": "07b8574b-39df-45df-85a8-da92c957b0f7",
    "outputId": "47b33b4f-aa58-49a5-dcdf-df08edda8d4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1 / 10\n",
      "Training Loss: 0.684\n",
      "Validation Loss: 0.641\n",
      "\n",
      " Epoch 2 / 10\n",
      "Training Loss: 0.677\n",
      "Validation Loss: 0.648\n",
      "\n",
      " Epoch 3 / 10\n",
      "Training Loss: 0.676\n",
      "Validation Loss: 0.657\n",
      "\n",
      " Epoch 4 / 10\n",
      "Training Loss: 0.692\n",
      "Validation Loss: 0.650\n",
      "\n",
      " Epoch 5 / 10\n",
      "Training Loss: 0.669\n",
      "Validation Loss: 0.661\n",
      "\n",
      " Epoch 6 / 10\n",
      "Training Loss: 0.665\n",
      "Validation Loss: 0.658\n",
      "\n",
      " Epoch 7 / 10\n",
      "Training Loss: 0.659\n",
      "Validation Loss: 0.651\n",
      "\n",
      " Epoch 8 / 10\n",
      "Training Loss: 0.678\n",
      "Validation Loss: 0.651\n",
      "\n",
      " Epoch 9 / 10\n",
      "Training Loss: 0.667\n",
      "Validation Loss: 0.656\n",
      "\n",
      " Epoch 10 / 10\n",
      "Training Loss: 0.649\n",
      "Validation Loss: 0.656\n"
     ]
    }
   ],
   "source": [
    "# # Main training loop\n",
    "# epochs_text_video_model = 15\n",
    "\n",
    "# train_losses_text_video_model, valid_losses_text_video_model = [], []\n",
    "# best_valid_loss_text_video_model = float('inf')\n",
    "# best_valid_loss_epoch_text_video_model = 0\n",
    "\n",
    "# for epoch in range(epochs_text_video_model):\n",
    "#     print(f'\\n Epoch {epoch + 1} / {epochs_text_video_model}')\n",
    "\n",
    "#     # Training step\n",
    "#     train_loss_text_video_model, _, _, _ = train(text_video_model, train_text_video_loader, text_video_criterion, text_video_optimizer)\n",
    "#     train_losses_text_video_model.append(train_loss_text_video_model)\n",
    "\n",
    "#     # Validation step (optional)\n",
    "#     valid_loss_text_video_model, _, _, _, _  = evaluate(text_video_model, valid_text_video_loader, text_video_criterion, text_video_optimizer)\n",
    "#     valid_losses_text_video_model.append(valid_loss_text_video_model)\n",
    "\n",
    "#     print(f'Training Loss: {train_loss_text_video_model:.3f}')\n",
    "#     print(f'Validation Loss: {valid_loss_text_video_model:.3f}')\n",
    "\n",
    "#     # Save the model if it has the best validation loss so far\n",
    "#     if valid_loss_text_video_model <= best_valid_loss_text_video_model:   # If we find one with the same, keep the one with the biggest epoch\n",
    "#         best_valid_loss_text_video_model = valid_loss_text_video_model\n",
    "#         best_valid_loss_epoch_text_video_model = epoch + 1\n",
    "#         torch.save(text_video_model.state_dict(), 'MLP_ealyFusion_text_video_model_best_model_state.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3a0fd537-284e-4f5e-b5cb-27b68343fc58",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1740572296921,
     "user": {
      "displayName": "Kyparissis Kyparissis",
      "userId": "18280909670100413703"
     },
     "user_tz": -120
    },
    "id": "3a0fd537-284e-4f5e-b5cb-27b68343fc58",
    "outputId": "1bae92c7-fd49-45fb-e044-d39f6ac7b8f4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_557354/3629736115.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  text_video_model_opt.load_state_dict(torch.load('MLP_ealyFusion_text_video_model_best_model_state.bin'))      # Load the saved state dictionary\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP_Model(\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=1536, out_features=256, bias=True)\n",
       "  )\n",
       "  (out): Linear(in_features=256, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (act): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize a model and move it to GPU\n",
    "text_video_model_opt = MLP_Model(layer_sizes=layer_sizes_text_video, dropout_p=dropout_p_text_video)\n",
    "text_video_model_opt = text_video_model_opt.to(device)\n",
    "\n",
    "# Load\n",
    "text_video_model_opt.load_state_dict(torch.load('MLP_ealyFusion_text_video_model_best_model_state.bin'))      # Load the saved state dictionary\n",
    "text_video_model_opt.eval()                                                                                    # Set the model to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c82fd872-cbeb-4683-b28f-48fd91d4a011",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 450,
     "status": "ok",
     "timestamp": 1740575428377,
     "user": {
      "displayName": "Kyparissis Kyparissis",
      "userId": "18280909670100413703"
     },
     "user_tz": -120
    },
    "id": "c82fd872-cbeb-4683-b28f-48fd91d4a011",
    "outputId": "d3a35ba9-48fd-4ea9-aee4-f120ad100f53"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_557354/2779074390.py:6: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  labels = torch.tensor([item['labels'] for item in batch], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 0.5870\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have already created test_dataloader\n",
    "test_avg_loss_text_video_model, _, test_preds_text_video_model, _ , test_outputs_text_video_model, test_video_ids_text_video_model, test_clip_ids_text_video_model  = evaluate(text_video_model_opt, test_text_video_loader, text_video_criterion, text_video_optimizer, track_clipVideo_id=True)\n",
    "\n",
    "# Print the results\n",
    "print(f'Average Loss: {test_avg_loss_text_video_model:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "vToip0_OYcsu",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1740575461520,
     "user": {
      "displayName": "Kyparissis Kyparissis",
      "userId": "18280909670100413703"
     },
     "user_tz": -120
    },
    "id": "vToip0_OYcsu",
    "outputId": "f83c2ec5-ebc0-496e-cdab-430f93505bb9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Apply softmax\n",
    "test_outputs_text_video_model = torch.tensor(test_outputs_text_video_model)  # Convert to tensor\n",
    "test_text_video_probabilities = torch.nn.functional.softmax(test_outputs_text_video_model, dim=1).cpu().numpy()  # Compute probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "_3ONKxEFXS3z",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 129,
     "status": "ok",
     "timestamp": 1740575429154,
     "user": {
      "displayName": "Kyparissis Kyparissis",
      "userId": "18280909670100413703"
     },
     "user_tz": -120
    },
    "id": "_3ONKxEFXS3z",
    "outputId": "ed2fb277-aaf0-477c-8c4d-81e712df91d4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.57492566, 0.42507434],\n",
       "       [0.40531382, 0.59468615],\n",
       "       [0.5453139 , 0.45468608],\n",
       "       ...,\n",
       "       [0.38617435, 0.61382556],\n",
       "       [0.5240288 , 0.47597125],\n",
       "       [0.37103295, 0.62896705]], dtype=float32)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text_video_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8a4d6835-f4b2-4a77-9bb0-7f0d2c9e97d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with the required information\n",
    "text_video_test_results_df = pd.DataFrame({\n",
    "    'video_id': test_video_ids_text_video_model,\n",
    "    'clip_id': test_clip_ids_text_video_model,\n",
    "    'annotation_label': test_text_video_merged_labels,\n",
    "    'text_video_prob_0': test_text_video_probabilities[:, 0],  # Probability of class 0\n",
    "    'text_video_prob_1': test_text_video_probabilities[:, 1],   # Probability of class 1\n",
    "    'text_video_preds': test_preds_text_video_model,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "41c5994b-1321-48c7-baea-5bc73ecd95ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8119533527696793\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "accuracy = (text_video_test_results_df['annotation_label'] == text_video_test_results_df['text_video_preds']).mean()\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "78a39d0f-733a-429d-a4db-b6f94ed66ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_557354/2779074390.py:6: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  labels = torch.tensor([item['labels'] for item in batch], dtype=torch.long)\n"
     ]
    }
   ],
   "source": [
    "valid_avg_loss_text_video_model, _, valid_preds_text_video_model, _ , valid_outputs_text_video_model, valid_video_ids_text_video_model, valid_clip_ids_text_video_model  = evaluate(text_video_model_opt, valid_text_video_loader, text_video_criterion, text_video_optimizer, track_clipVideo_id=True)\n",
    "# Apply softmax\n",
    "valid_outputs_text_video_model = torch.tensor(valid_outputs_text_video_model)  # Convert to tensor\n",
    "valid_text_video_probabilities = torch.nn.functional.softmax(valid_outputs_text_video_model, dim=1).cpu().numpy()  # Compute probabilities\n",
    "# Create a DataFrame with the required information\n",
    "text_video_valid_results_df = pd.DataFrame({\n",
    "    'video_id': valid_video_ids_text_video_model,\n",
    "    'clip_id': valid_clip_ids_text_video_model,\n",
    "    'annotation_label': valid_text_video_merged_labels,\n",
    "    'text_video_prob_0': valid_text_video_probabilities[:, 0],  # Probability of class 0\n",
    "    'text_video_prob_1': valid_text_video_probabilities[:, 1],   # Probability of class 1\n",
    "    'text_video_preds': valid_preds_text_video_model,\n",
    "})\n",
    "\n",
    "trainSerial_text_video_loader = DataLoader(dataset_text_video_merged['train'], batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
    "train_avg_loss_text_video_model, _, train_preds_text_video_model, _ , train_outputs_text_video_model, train_video_ids_text_video_model, train_clip_ids_text_video_model  = evaluate(text_video_model_opt, trainSerial_text_video_loader, text_video_criterion, text_video_optimizer, track_clipVideo_id=True)\n",
    "# Apply softmax\n",
    "train_outputs_text_video_model = torch.tensor(train_outputs_text_video_model)  # Convert to tensor\n",
    "train_text_video_probabilities = torch.nn.functional.softmax(train_outputs_text_video_model, dim=1).cpu().numpy()  # Compute probabilities\n",
    "# Create a DataFrame with the required information\n",
    "text_video_train_results_df = pd.DataFrame({\n",
    "    'video_id': train_video_ids_text_video_model,\n",
    "    'clip_id': train_clip_ids_text_video_model,\n",
    "    'annotation_label': train_text_video_merged_labels,\n",
    "    'text_video_prob_0': train_text_video_probabilities[:, 0],  # Probability of class 0\n",
    "    'text_video_prob_1': train_text_video_probabilities[:, 1],   # Probability of class 1\n",
    "    'text_video_preds': train_preds_text_video_model,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ddea7b76-5073-4a1f-96ab-f8d0a3c0bba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_video_results_df = pd.concat([text_video_train_results_df, text_video_valid_results_df, text_video_test_results_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c83d7cdf-1d47-4ab5-b4b1-b792667b807b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do the columns match? True\n",
      "Do the columns match? True\n"
     ]
    }
   ],
   "source": [
    "columns_to_check = ['video_id', 'clip_id', 'annotation_label']\n",
    "match1 = (text_video_results_df[columns_to_check] == df1[columns_to_check]).all().all()\n",
    "\n",
    "print(f\"Do the columns match? {match1}\")\n",
    "\n",
    "match2 = text_video_results_df[columns_to_check].equals(df1[columns_to_check])\n",
    "\n",
    "print(f\"Do the columns match? {match2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "12f7a801-7fa8-4a56-8000-440afd45ef45",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1740572299589,
     "user": {
      "displayName": "Kyparissis Kyparissis",
      "userId": "18280909670100413703"
     },
     "user_tz": -120
    },
    "id": "12f7a801-7fa8-4a56-8000-440afd45ef45",
    "outputId": "de04d51c-395e-4285-f62c-ad3d85c9a81a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7976    0.8839    0.8385       379\n",
      "         1.0     0.8346    0.7231    0.7749       307\n",
      "\n",
      "    accuracy                         0.8120       686\n",
      "   macro avg     0.8161    0.8035    0.8067       686\n",
      "weighted avg     0.8142    0.8120    0.8101       686\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_text_video_merged_labels, test_preds_text_video_model, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11615d24-b51c-49a3-aeca-514a02b6228b",
   "metadata": {
    "id": "11615d24-b51c-49a3-aeca-514a02b6228b"
   },
   "source": [
    "---\n",
    "## Audio and Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cacf5c03-6b7a-436c-ae30-1ea14e8e605c",
   "metadata": {
    "executionInfo": {
     "elapsed": 336,
     "status": "ok",
     "timestamp": 1740572309474,
     "user": {
      "displayName": "Kyparissis Kyparissis",
      "userId": "18280909670100413703"
     },
     "user_tz": -120
    },
    "id": "cacf5c03-6b7a-436c-ae30-1ea14e8e605c"
   },
   "outputs": [],
   "source": [
    "train_audio_video_merged_labels = train_audio_video_merged_df['annotation_label']\n",
    "train_audio_video_merged_features = train_audio_video_merged_df.drop(columns=['video_id', 'clip_id', 'annotation_label'])\n",
    "train_audio_video_merged_features = train_audio_video_merged_features.values.tolist()\n",
    "# Create datasets with the features and labels\n",
    "train_audio_video_merged_dataset = Dataset.from_dict({\n",
    "    'input_ids': train_audio_video_merged_features,\n",
    "    'labels': train_audio_video_merged_labels.tolist(),\n",
    "    'clip_id': train_audio_video_merged_df['clip_id'].tolist(),\n",
    "    'video_id': train_audio_video_merged_df['video_id'].tolist()\n",
    "})\n",
    "\n",
    "valid_audio_video_merged_labels = valid_audio_video_merged_df['annotation_label']\n",
    "valid_audio_video_merged_features = valid_audio_video_merged_df.drop(columns=['video_id', 'clip_id', 'annotation_label'])\n",
    "valid_audio_video_merged_features = valid_audio_video_merged_features.values.tolist()\n",
    "# Create datasets with the features and labels\n",
    "valid_audio_video_merged_dataset = Dataset.from_dict({\n",
    "    'input_ids': valid_audio_video_merged_features,\n",
    "    'labels': valid_audio_video_merged_labels.tolist(),\n",
    "    'clip_id': valid_audio_video_merged_df['clip_id'].tolist(),\n",
    "    'video_id': valid_audio_video_merged_df['video_id'].tolist()\n",
    "})\n",
    "\n",
    "test_audio_video_merged_labels = test_audio_video_merged_df['annotation_label']\n",
    "test_audio_video_merged_features = test_audio_video_merged_df.drop(columns=['video_id', 'clip_id', 'annotation_label'])\n",
    "test_audio_video_merged_features = test_audio_video_merged_features.values.tolist()\n",
    "# Create datasets with the features and labels\n",
    "test_audio_video_merged_dataset = Dataset.from_dict({\n",
    "    'input_ids': test_audio_video_merged_features,\n",
    "    'labels': test_audio_video_merged_labels.tolist(),\n",
    "    'clip_id': test_audio_video_merged_df['clip_id'].tolist(),\n",
    "    'video_id': test_audio_video_merged_df['video_id'].tolist()\n",
    "})\n",
    "\n",
    "# Create the DatasetDict to hold the subsets\n",
    "dataset_audio_video_merged = DatasetDict({\n",
    "    'train': train_audio_video_merged_dataset,\n",
    "    'valid': valid_audio_video_merged_dataset,\n",
    "    'test': test_audio_video_merged_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "682de0ed-a6f3-4901-bd81-6f9bfc2c03bb",
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1740572310867,
     "user": {
      "displayName": "Kyparissis Kyparissis",
      "userId": "18280909670100413703"
     },
     "user_tz": -120
    },
    "id": "682de0ed-a6f3-4901-bd81-6f9bfc2c03bb"
   },
   "outputs": [],
   "source": [
    "# Convert datasets to DataLoaders\n",
    "train_audio_video_loader = DataLoader(dataset_audio_video_merged['train'], batch_size=128, shuffle=True, collate_fn=collate_fn)\n",
    "valid_audio_video_loader = DataLoader(dataset_audio_video_merged['valid'], batch_size=128, shuffle=False, collate_fn=collate_fn)\n",
    "test_audio_video_loader = DataLoader(dataset_audio_video_merged['test'], batch_size=128, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "64b90b30-7c20-4d76-9158-389951ccf939",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1740573108204,
     "user": {
      "displayName": "Kyparissis Kyparissis",
      "userId": "18280909670100413703"
     },
     "user_tz": -120
    },
    "id": "64b90b30-7c20-4d76-9158-389951ccf939"
   },
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "layer_sizes_audio_video = [(768+256), 128, 128]\n",
    "dropout_p_audio_video = 0.1\n",
    "audio_video_model = MLP_Model(layer_sizes=layer_sizes_audio_video, dropout_p=dropout_p_audio_video, act_func=\"tanh\")\n",
    "\n",
    "# Move the model to the appropriate device (GPU if available)\n",
    "audio_video_model.to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "audio_video_criterion = nn.CrossEntropyLoss()  # Suitable for classification tasks\n",
    "audio_video_optimizer = optim.AdamW(audio_video_model.parameters(), lr=1e-5, weight_decay=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5b47a93c-737e-401e-b56d-9cb0e5644d4a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14748,
     "status": "ok",
     "timestamp": 1740573124664,
     "user": {
      "displayName": "Kyparissis Kyparissis",
      "userId": "18280909670100413703"
     },
     "user_tz": -120
    },
    "id": "5b47a93c-737e-401e-b56d-9cb0e5644d4a",
    "outputId": "62e8daed-0b30-4a07-b253-709407f2fe5d"
   },
   "outputs": [],
   "source": [
    "# # Main training loop\n",
    "# epochs_audio_video_model = 15\n",
    "\n",
    "# train_losses_audio_video_model, valid_losses_audio_video_model = [], []\n",
    "# best_valid_loss_audio_video_model = float('inf')\n",
    "# best_valid_loss_epoch_audio_video_model = 0\n",
    "\n",
    "# for epoch in range(epochs_audio_video_model):\n",
    "#     print(f'\\n Epoch {epoch + 1} / {epochs_audio_video_model}')\n",
    "\n",
    "#     # Training step\n",
    "#     train_loss_audio_video_model, _, _, _ = train(audio_video_model, train_audio_video_loader, audio_video_criterion, audio_video_optimizer)\n",
    "#     train_losses_audio_video_model.append(train_loss_audio_video_model)\n",
    "\n",
    "#     # Validation step (optional)\n",
    "#     valid_loss_audio_video_model, _, _, _, _  = evaluate(audio_video_model, valid_audio_video_loader, audio_video_criterion, audio_video_optimizer)\n",
    "#     valid_losses_audio_video_model.append(valid_loss_audio_video_model)\n",
    "\n",
    "#     print(f'Training Loss: {train_loss_audio_video_model:.3f}')\n",
    "#     print(f'Validation Loss: {valid_loss_audio_video_model:.3f}')\n",
    "\n",
    "#     # Save the model if it has the best validation loss so far\n",
    "#     if valid_loss_audio_video_model <= best_valid_loss_audio_video_model:   # If we find one with the same, keep the one with the biggest epoch\n",
    "#         best_valid_loss_audio_video_model = valid_loss_audio_video_model\n",
    "#         best_valid_loss_epoch_audio_video_model = epoch + 1\n",
    "#         torch.save(audio_video_model.state_dict(), 'MLP_ealyFusion_audio_video_model_best_model_state.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f80a0c64-c814-4f30-b7f5-ad4cccd349c9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1740573127200,
     "user": {
      "displayName": "Kyparissis Kyparissis",
      "userId": "18280909670100413703"
     },
     "user_tz": -120
    },
    "id": "f80a0c64-c814-4f30-b7f5-ad4cccd349c9",
    "outputId": "89edd9e1-1c5e-4492-f24a-1567dd102afc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_557354/4241706333.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  audio_video_model_opt.load_state_dict(torch.load('MLP_ealyFusion_audio_video_model_best_model_state.bin'))      # Load the saved state dictionary\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP_Model(\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=1024, out_features=128, bias=True)\n",
       "    (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       "  (out): Linear(in_features=128, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (act): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize a model and move it to GPU\n",
    "audio_video_model_opt = MLP_Model(layer_sizes=layer_sizes_audio_video, dropout_p=dropout_p_audio_video)\n",
    "audio_video_model_opt = audio_video_model_opt.to(device)\n",
    "\n",
    "# Load\n",
    "audio_video_model_opt.load_state_dict(torch.load('MLP_ealyFusion_audio_video_model_best_model_state.bin'))      # Load the saved state dictionary\n",
    "audio_video_model_opt.eval()                                                                                    # Set the model to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bbe4ed07-00fa-463b-8ea8-08ed20ac6db2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 489,
     "status": "ok",
     "timestamp": 1740575486595,
     "user": {
      "displayName": "Kyparissis Kyparissis",
      "userId": "18280909670100413703"
     },
     "user_tz": -120
    },
    "id": "bbe4ed07-00fa-463b-8ea8-08ed20ac6db2",
    "outputId": "331a9af8-3506-47fe-f157-ecaaa5efc6ed"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_557354/2779074390.py:6: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  labels = torch.tensor([item['labels'] for item in batch], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 0.6996\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have already created test_dataloader\n",
    "test_avg_loss_audio_video_model, _, test_preds_audio_video_model, _ , test_outputs_audio_video_model, test_video_ids_audio_video_model, test_clip_ids_audio_video_model  = evaluate(audio_video_model_opt, test_audio_video_loader, audio_video_criterion, audio_video_optimizer, track_clipVideo_id=True)\n",
    "\n",
    "\n",
    "# Print the results\n",
    "print(f'Average Loss: {test_avg_loss_audio_video_model:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "OPTm_ptkYksD",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 53,
     "status": "ok",
     "timestamp": 1740575494078,
     "user": {
      "displayName": "Kyparissis Kyparissis",
      "userId": "18280909670100413703"
     },
     "user_tz": -120
    },
    "id": "OPTm_ptkYksD",
    "outputId": "93168842-435d-42a3-be5d-7692c87d053e"
   },
   "outputs": [],
   "source": [
    "# Apply softmax\n",
    "test_outputs_audio_video_model = torch.tensor(test_outputs_audio_video_model)  # Convert to tensor\n",
    "test_audio_video_probabilities = torch.nn.functional.softmax(test_outputs_audio_video_model, dim=1).cpu().numpy()  # Compute probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2pgNZSUCW-7Q",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 184,
     "status": "ok",
     "timestamp": 1740575487591,
     "user": {
      "displayName": "Kyparissis Kyparissis",
      "userId": "18280909670100413703"
     },
     "user_tz": -120
    },
    "id": "2pgNZSUCW-7Q",
    "outputId": "208af861-1057-4a03-da66-10b2246a9dfb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.38446894, 0.6155311 ],\n",
       "       [0.3210413 , 0.6789587 ],\n",
       "       [0.50379276, 0.49620727],\n",
       "       ...,\n",
       "       [0.35468748, 0.64531255],\n",
       "       [0.4613342 , 0.5386659 ],\n",
       "       [0.42548615, 0.57451385]], dtype=float32)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_audio_video_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ff9ff8ae-6d0c-4ffb-8dfa-92d365265fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with the required information\n",
    "audio_video_test_results_df = pd.DataFrame({\n",
    "    'video_id': test_video_ids_audio_video_model,\n",
    "    'clip_id': test_clip_ids_audio_video_model,\n",
    "    'annotation_label': test_audio_video_merged_labels,\n",
    "    'audio_video_prob_0': test_audio_video_probabilities[:, 0],  # Probability of class 0\n",
    "    'audio_video_prob_1': test_audio_video_probabilities[:, 1],   # Probability of class 1\n",
    "    'audio_video_preds': test_preds_audio_video_model,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3d62b1ec-e304-4022-8c7a-8b0c169c00a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4970845481049563\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "accuracy = (audio_video_test_results_df['annotation_label'] == audio_video_test_results_df['audio_video_preds']).mean()\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4b42bab3-e5b2-4ecf-aad4-13f0345c78e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_557354/2779074390.py:6: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  labels = torch.tensor([item['labels'] for item in batch], dtype=torch.long)\n"
     ]
    }
   ],
   "source": [
    "valid_avg_loss_audio_video_model, _, valid_preds_audio_video_model, _ , valid_outputs_audio_video_model, valid_video_ids_audio_video_model, valid_clip_ids_audio_video_model  = evaluate(audio_video_model_opt, valid_audio_video_loader, audio_video_criterion, audio_video_optimizer, track_clipVideo_id=True)\n",
    "# Apply softmax\n",
    "valid_outputs_audio_video_model = torch.tensor(valid_outputs_audio_video_model)  # Convert to tensor\n",
    "valid_audio_video_probabilities = torch.nn.functional.softmax(valid_outputs_audio_video_model, dim=1).cpu().numpy()  # Compute probabilities\n",
    "# Create a DataFrame with the required information\n",
    "audio_video_valid_results_df = pd.DataFrame({\n",
    "    'video_id': valid_video_ids_audio_video_model,\n",
    "    'clip_id': valid_clip_ids_audio_video_model,\n",
    "    'annotation_label': valid_audio_video_merged_labels,\n",
    "    'audio_video_prob_0': valid_audio_video_probabilities[:, 0],  # Probability of class 0\n",
    "    'audio_video_prob_1': valid_audio_video_probabilities[:, 1],   # Probability of class 1\n",
    "    'audio_video_preds': valid_preds_audio_video_model,\n",
    "})\n",
    "\n",
    "trainSerial_audio_video_loader = DataLoader(dataset_audio_video_merged['train'], batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
    "train_avg_loss_audio_video_model, _, train_preds_audio_video_model, _ , train_outputs_audio_video_model, train_video_ids_audio_video_model, train_clip_ids_audio_video_model  = evaluate(audio_video_model_opt, trainSerial_audio_video_loader, audio_video_criterion, audio_video_optimizer, track_clipVideo_id=True)\n",
    "# Apply softmax\n",
    "train_outputs_audio_video_model = torch.tensor(train_outputs_audio_video_model)  # Convert to tensor\n",
    "train_audio_video_probabilities = torch.nn.functional.softmax(train_outputs_audio_video_model, dim=1).cpu().numpy()  # Compute probabilities\n",
    "# Create a DataFrame with the required information\n",
    "audio_video_train_results_df = pd.DataFrame({\n",
    "    'video_id': train_video_ids_audio_video_model,\n",
    "    'clip_id': train_clip_ids_audio_video_model,\n",
    "    'annotation_label': train_audio_video_merged_labels,\n",
    "    'audio_video_prob_0': train_audio_video_probabilities[:, 0],  # Probability of class 0\n",
    "    'audio_video_prob_1': train_audio_video_probabilities[:, 1],   # Probability of class 1\n",
    "    'audio_video_preds': train_preds_audio_video_model,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cc73d0e3-94f6-4c55-a18a-40b7d10c3e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_video_results_df = pd.concat([audio_video_train_results_df, audio_video_valid_results_df, audio_video_test_results_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "50ce1117-abfc-43c9-ba2c-e38493b0dc50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do the columns match? True\n",
      "Do the columns match? True\n"
     ]
    }
   ],
   "source": [
    "columns_to_check = ['video_id', 'clip_id', 'annotation_label']\n",
    "match1 = (audio_video_results_df[columns_to_check] == df1[columns_to_check]).all().all()\n",
    "\n",
    "print(f\"Do the columns match? {match1}\")\n",
    "\n",
    "match2 = audio_video_results_df[columns_to_check].equals(df1[columns_to_check])\n",
    "\n",
    "print(f\"Do the columns match? {match2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "389c905c-afdd-4ff1-be36-22c31ae1d5b3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1740575514534,
     "user": {
      "displayName": "Kyparissis Kyparissis",
      "userId": "18280909670100413703"
     },
     "user_tz": -120
    },
    "id": "389c905c-afdd-4ff1-be36-22c31ae1d5b3",
    "outputId": "58adb863-ef19-4c4e-9d9e-310d9b1408d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6518    0.1926    0.2974       379\n",
      "         1.0     0.4669    0.8730    0.6084       307\n",
      "\n",
      "    accuracy                         0.4971       686\n",
      "   macro avg     0.5593    0.5328    0.4529       686\n",
      "weighted avg     0.5690    0.4971    0.4366       686\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_audio_video_merged_labels, test_preds_audio_video_model, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abee765e-0472-4354-b2ac-df3d8720bdf8",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "05eb2f50-a6f9-410c-84da-cd8866fa2c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "earlyFusion_results_df = trimodal_results_df.merge(\n",
    "    text_audio_results_df, on=[\"video_id\", \"clip_id\", \"annotation_label\"], how=\"inner\"\n",
    ").merge(\n",
    "    audio_video_results_df, on=[\"video_id\", \"clip_id\", \"annotation_label\"], how=\"inner\"\n",
    ").merge(\n",
    "    text_video_results_df, on=[\"video_id\", \"clip_id\", \"annotation_label\"], how=\"inner\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "aa8d49b8-ae2b-4d1c-b14b-a12ae1f774ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>clip_id</th>\n",
       "      <th>annotation_label</th>\n",
       "      <th>trimodal_prob_0</th>\n",
       "      <th>trimodal_prob_1</th>\n",
       "      <th>trimodal_preds</th>\n",
       "      <th>text_audio_prob_0</th>\n",
       "      <th>text_audio_prob_1</th>\n",
       "      <th>text_audio_preds</th>\n",
       "      <th>audio_video_prob_0</th>\n",
       "      <th>audio_video_prob_1</th>\n",
       "      <th>audio_video_preds</th>\n",
       "      <th>text_video_prob_0</th>\n",
       "      <th>text_video_prob_1</th>\n",
       "      <th>text_video_preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.459776</td>\n",
       "      <td>0.540224</td>\n",
       "      <td>1</td>\n",
       "      <td>0.545542</td>\n",
       "      <td>0.454458</td>\n",
       "      <td>0</td>\n",
       "      <td>0.410912</td>\n",
       "      <td>0.589088</td>\n",
       "      <td>1</td>\n",
       "      <td>0.547833</td>\n",
       "      <td>0.452167</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.564226</td>\n",
       "      <td>0.435774</td>\n",
       "      <td>0</td>\n",
       "      <td>0.546001</td>\n",
       "      <td>0.453999</td>\n",
       "      <td>0</td>\n",
       "      <td>0.439674</td>\n",
       "      <td>0.560326</td>\n",
       "      <td>1</td>\n",
       "      <td>0.602740</td>\n",
       "      <td>0.397260</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.080895</td>\n",
       "      <td>0.919105</td>\n",
       "      <td>1</td>\n",
       "      <td>0.354512</td>\n",
       "      <td>0.645488</td>\n",
       "      <td>1</td>\n",
       "      <td>0.370054</td>\n",
       "      <td>0.629946</td>\n",
       "      <td>1</td>\n",
       "      <td>0.382594</td>\n",
       "      <td>0.617406</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.070363</td>\n",
       "      <td>0.929637</td>\n",
       "      <td>1</td>\n",
       "      <td>0.349426</td>\n",
       "      <td>0.650574</td>\n",
       "      <td>1</td>\n",
       "      <td>0.358518</td>\n",
       "      <td>0.641482</td>\n",
       "      <td>1</td>\n",
       "      <td>0.386552</td>\n",
       "      <td>0.613448</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.276498</td>\n",
       "      <td>0.723502</td>\n",
       "      <td>1</td>\n",
       "      <td>0.516387</td>\n",
       "      <td>0.483613</td>\n",
       "      <td>0</td>\n",
       "      <td>0.365942</td>\n",
       "      <td>0.634058</td>\n",
       "      <td>1</td>\n",
       "      <td>0.582906</td>\n",
       "      <td>0.417094</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2194</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.916739</td>\n",
       "      <td>0.083261</td>\n",
       "      <td>0</td>\n",
       "      <td>0.559317</td>\n",
       "      <td>0.440684</td>\n",
       "      <td>0</td>\n",
       "      <td>0.546081</td>\n",
       "      <td>0.453919</td>\n",
       "      <td>0</td>\n",
       "      <td>0.542318</td>\n",
       "      <td>0.457682</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2195</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.329535</td>\n",
       "      <td>0.670465</td>\n",
       "      <td>1</td>\n",
       "      <td>0.334322</td>\n",
       "      <td>0.665678</td>\n",
       "      <td>1</td>\n",
       "      <td>0.398728</td>\n",
       "      <td>0.601272</td>\n",
       "      <td>1</td>\n",
       "      <td>0.396127</td>\n",
       "      <td>0.603873</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>34</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.093175</td>\n",
       "      <td>0.906825</td>\n",
       "      <td>1</td>\n",
       "      <td>0.344932</td>\n",
       "      <td>0.655068</td>\n",
       "      <td>1</td>\n",
       "      <td>0.354687</td>\n",
       "      <td>0.645313</td>\n",
       "      <td>1</td>\n",
       "      <td>0.386174</td>\n",
       "      <td>0.613826</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2197</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.379098</td>\n",
       "      <td>0.620902</td>\n",
       "      <td>1</td>\n",
       "      <td>0.481836</td>\n",
       "      <td>0.518164</td>\n",
       "      <td>1</td>\n",
       "      <td>0.461334</td>\n",
       "      <td>0.538666</td>\n",
       "      <td>1</td>\n",
       "      <td>0.524029</td>\n",
       "      <td>0.475971</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2198</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>32</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.154785</td>\n",
       "      <td>0.845215</td>\n",
       "      <td>1</td>\n",
       "      <td>0.361187</td>\n",
       "      <td>0.638813</td>\n",
       "      <td>1</td>\n",
       "      <td>0.425486</td>\n",
       "      <td>0.574514</td>\n",
       "      <td>1</td>\n",
       "      <td>0.371033</td>\n",
       "      <td>0.628967</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2199 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         video_id  clip_id  annotation_label  trimodal_prob_0  \\\n",
       "0     03bSnISJMiM       11               0.0         0.459776   \n",
       "1     03bSnISJMiM       10               0.0         0.564226   \n",
       "2     03bSnISJMiM       13               1.0         0.080895   \n",
       "3     03bSnISJMiM       12               1.0         0.070363   \n",
       "4     03bSnISJMiM        1               1.0         0.276498   \n",
       "...           ...      ...               ...              ...   \n",
       "2194  zhpQhgha_KU       30               0.0         0.916739   \n",
       "2195  zhpQhgha_KU       35               1.0         0.329535   \n",
       "2196  zhpQhgha_KU       34               1.0         0.093175   \n",
       "2197  zhpQhgha_KU       33               0.0         0.379098   \n",
       "2198  zhpQhgha_KU       32               1.0         0.154785   \n",
       "\n",
       "      trimodal_prob_1  trimodal_preds  text_audio_prob_0  text_audio_prob_1  \\\n",
       "0            0.540224               1           0.545542           0.454458   \n",
       "1            0.435774               0           0.546001           0.453999   \n",
       "2            0.919105               1           0.354512           0.645488   \n",
       "3            0.929637               1           0.349426           0.650574   \n",
       "4            0.723502               1           0.516387           0.483613   \n",
       "...               ...             ...                ...                ...   \n",
       "2194         0.083261               0           0.559317           0.440684   \n",
       "2195         0.670465               1           0.334322           0.665678   \n",
       "2196         0.906825               1           0.344932           0.655068   \n",
       "2197         0.620902               1           0.481836           0.518164   \n",
       "2198         0.845215               1           0.361187           0.638813   \n",
       "\n",
       "      text_audio_preds  audio_video_prob_0  audio_video_prob_1  \\\n",
       "0                    0            0.410912            0.589088   \n",
       "1                    0            0.439674            0.560326   \n",
       "2                    1            0.370054            0.629946   \n",
       "3                    1            0.358518            0.641482   \n",
       "4                    0            0.365942            0.634058   \n",
       "...                ...                 ...                 ...   \n",
       "2194                 0            0.546081            0.453919   \n",
       "2195                 1            0.398728            0.601272   \n",
       "2196                 1            0.354687            0.645313   \n",
       "2197                 1            0.461334            0.538666   \n",
       "2198                 1            0.425486            0.574514   \n",
       "\n",
       "      audio_video_preds  text_video_prob_0  text_video_prob_1  \\\n",
       "0                     1           0.547833           0.452167   \n",
       "1                     1           0.602740           0.397260   \n",
       "2                     1           0.382594           0.617406   \n",
       "3                     1           0.386552           0.613448   \n",
       "4                     1           0.582906           0.417094   \n",
       "...                 ...                ...                ...   \n",
       "2194                  0           0.542318           0.457682   \n",
       "2195                  1           0.396127           0.603873   \n",
       "2196                  1           0.386174           0.613826   \n",
       "2197                  1           0.524029           0.475971   \n",
       "2198                  1           0.371033           0.628967   \n",
       "\n",
       "      text_video_preds  \n",
       "0                    0  \n",
       "1                    0  \n",
       "2                    1  \n",
       "3                    1  \n",
       "4                    0  \n",
       "...                ...  \n",
       "2194                 0  \n",
       "2195                 1  \n",
       "2196                 1  \n",
       "2197                 0  \n",
       "2198                 1  \n",
       "\n",
       "[2199 rows x 15 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earlyFusion_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "df7b104f-038f-4e78-a9a7-d17346eef969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earlyFusion_results_df.isna().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8b5e64eb-9c6b-46b5-9642-068bddf93462",
   "metadata": {},
   "outputs": [],
   "source": [
    "earlyFusion_results_df = earlyFusion_results_df.merge(\n",
    "    all_merged_df[['video_id', 'clip_id', 'annotation_label', 'mode']], \n",
    "    on=['video_id', 'clip_id', 'annotation_label'], \n",
    "    how='inner'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1e4baa5c-f3f0-48a3-a47c-9d34d750815d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>clip_id</th>\n",
       "      <th>annotation_label</th>\n",
       "      <th>trimodal_prob_0</th>\n",
       "      <th>trimodal_prob_1</th>\n",
       "      <th>trimodal_preds</th>\n",
       "      <th>text_audio_prob_0</th>\n",
       "      <th>text_audio_prob_1</th>\n",
       "      <th>text_audio_preds</th>\n",
       "      <th>audio_video_prob_0</th>\n",
       "      <th>audio_video_prob_1</th>\n",
       "      <th>audio_video_preds</th>\n",
       "      <th>text_video_prob_0</th>\n",
       "      <th>text_video_prob_1</th>\n",
       "      <th>text_video_preds</th>\n",
       "      <th>mode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.459776</td>\n",
       "      <td>0.540224</td>\n",
       "      <td>1</td>\n",
       "      <td>0.545542</td>\n",
       "      <td>0.454458</td>\n",
       "      <td>0</td>\n",
       "      <td>0.410912</td>\n",
       "      <td>0.589088</td>\n",
       "      <td>1</td>\n",
       "      <td>0.547833</td>\n",
       "      <td>0.452167</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.564226</td>\n",
       "      <td>0.435774</td>\n",
       "      <td>0</td>\n",
       "      <td>0.546001</td>\n",
       "      <td>0.453999</td>\n",
       "      <td>0</td>\n",
       "      <td>0.439674</td>\n",
       "      <td>0.560326</td>\n",
       "      <td>1</td>\n",
       "      <td>0.602740</td>\n",
       "      <td>0.397260</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.080895</td>\n",
       "      <td>0.919105</td>\n",
       "      <td>1</td>\n",
       "      <td>0.354512</td>\n",
       "      <td>0.645488</td>\n",
       "      <td>1</td>\n",
       "      <td>0.370054</td>\n",
       "      <td>0.629946</td>\n",
       "      <td>1</td>\n",
       "      <td>0.382594</td>\n",
       "      <td>0.617406</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.070363</td>\n",
       "      <td>0.929637</td>\n",
       "      <td>1</td>\n",
       "      <td>0.349426</td>\n",
       "      <td>0.650574</td>\n",
       "      <td>1</td>\n",
       "      <td>0.358518</td>\n",
       "      <td>0.641482</td>\n",
       "      <td>1</td>\n",
       "      <td>0.386552</td>\n",
       "      <td>0.613448</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.276498</td>\n",
       "      <td>0.723502</td>\n",
       "      <td>1</td>\n",
       "      <td>0.516387</td>\n",
       "      <td>0.483613</td>\n",
       "      <td>0</td>\n",
       "      <td>0.365942</td>\n",
       "      <td>0.634058</td>\n",
       "      <td>1</td>\n",
       "      <td>0.582906</td>\n",
       "      <td>0.417094</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2194</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.916739</td>\n",
       "      <td>0.083261</td>\n",
       "      <td>0</td>\n",
       "      <td>0.559317</td>\n",
       "      <td>0.440684</td>\n",
       "      <td>0</td>\n",
       "      <td>0.546081</td>\n",
       "      <td>0.453919</td>\n",
       "      <td>0</td>\n",
       "      <td>0.542318</td>\n",
       "      <td>0.457682</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2195</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.329535</td>\n",
       "      <td>0.670465</td>\n",
       "      <td>1</td>\n",
       "      <td>0.334322</td>\n",
       "      <td>0.665678</td>\n",
       "      <td>1</td>\n",
       "      <td>0.398728</td>\n",
       "      <td>0.601272</td>\n",
       "      <td>1</td>\n",
       "      <td>0.396127</td>\n",
       "      <td>0.603873</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>34</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.093175</td>\n",
       "      <td>0.906825</td>\n",
       "      <td>1</td>\n",
       "      <td>0.344932</td>\n",
       "      <td>0.655068</td>\n",
       "      <td>1</td>\n",
       "      <td>0.354687</td>\n",
       "      <td>0.645313</td>\n",
       "      <td>1</td>\n",
       "      <td>0.386174</td>\n",
       "      <td>0.613826</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2197</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.379098</td>\n",
       "      <td>0.620902</td>\n",
       "      <td>1</td>\n",
       "      <td>0.481836</td>\n",
       "      <td>0.518164</td>\n",
       "      <td>1</td>\n",
       "      <td>0.461334</td>\n",
       "      <td>0.538666</td>\n",
       "      <td>1</td>\n",
       "      <td>0.524029</td>\n",
       "      <td>0.475971</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2198</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>32</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.154785</td>\n",
       "      <td>0.845215</td>\n",
       "      <td>1</td>\n",
       "      <td>0.361187</td>\n",
       "      <td>0.638813</td>\n",
       "      <td>1</td>\n",
       "      <td>0.425486</td>\n",
       "      <td>0.574514</td>\n",
       "      <td>1</td>\n",
       "      <td>0.371033</td>\n",
       "      <td>0.628967</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2199 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         video_id  clip_id  annotation_label  trimodal_prob_0  \\\n",
       "0     03bSnISJMiM       11               0.0         0.459776   \n",
       "1     03bSnISJMiM       10               0.0         0.564226   \n",
       "2     03bSnISJMiM       13               1.0         0.080895   \n",
       "3     03bSnISJMiM       12               1.0         0.070363   \n",
       "4     03bSnISJMiM        1               1.0         0.276498   \n",
       "...           ...      ...               ...              ...   \n",
       "2194  zhpQhgha_KU       30               0.0         0.916739   \n",
       "2195  zhpQhgha_KU       35               1.0         0.329535   \n",
       "2196  zhpQhgha_KU       34               1.0         0.093175   \n",
       "2197  zhpQhgha_KU       33               0.0         0.379098   \n",
       "2198  zhpQhgha_KU       32               1.0         0.154785   \n",
       "\n",
       "      trimodal_prob_1  trimodal_preds  text_audio_prob_0  text_audio_prob_1  \\\n",
       "0            0.540224               1           0.545542           0.454458   \n",
       "1            0.435774               0           0.546001           0.453999   \n",
       "2            0.919105               1           0.354512           0.645488   \n",
       "3            0.929637               1           0.349426           0.650574   \n",
       "4            0.723502               1           0.516387           0.483613   \n",
       "...               ...             ...                ...                ...   \n",
       "2194         0.083261               0           0.559317           0.440684   \n",
       "2195         0.670465               1           0.334322           0.665678   \n",
       "2196         0.906825               1           0.344932           0.655068   \n",
       "2197         0.620902               1           0.481836           0.518164   \n",
       "2198         0.845215               1           0.361187           0.638813   \n",
       "\n",
       "      text_audio_preds  audio_video_prob_0  audio_video_prob_1  \\\n",
       "0                    0            0.410912            0.589088   \n",
       "1                    0            0.439674            0.560326   \n",
       "2                    1            0.370054            0.629946   \n",
       "3                    1            0.358518            0.641482   \n",
       "4                    0            0.365942            0.634058   \n",
       "...                ...                 ...                 ...   \n",
       "2194                 0            0.546081            0.453919   \n",
       "2195                 1            0.398728            0.601272   \n",
       "2196                 1            0.354687            0.645313   \n",
       "2197                 1            0.461334            0.538666   \n",
       "2198                 1            0.425486            0.574514   \n",
       "\n",
       "      audio_video_preds  text_video_prob_0  text_video_prob_1  \\\n",
       "0                     1           0.547833           0.452167   \n",
       "1                     1           0.602740           0.397260   \n",
       "2                     1           0.382594           0.617406   \n",
       "3                     1           0.386552           0.613448   \n",
       "4                     1           0.582906           0.417094   \n",
       "...                 ...                ...                ...   \n",
       "2194                  0           0.542318           0.457682   \n",
       "2195                  1           0.396127           0.603873   \n",
       "2196                  1           0.386174           0.613826   \n",
       "2197                  1           0.524029           0.475971   \n",
       "2198                  1           0.371033           0.628967   \n",
       "\n",
       "      text_video_preds   mode  \n",
       "0                    0  train  \n",
       "1                    0  train  \n",
       "2                    1  train  \n",
       "3                    1  train  \n",
       "4                    0  train  \n",
       "...                ...    ...  \n",
       "2194                 0   test  \n",
       "2195                 1   test  \n",
       "2196                 1   test  \n",
       "2197                 0   test  \n",
       "2198                 1   test  \n",
       "\n",
       "[2199 rows x 16 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earlyFusion_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "75a4e14f-2d19-4534-af00-a18383401f2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earlyFusion_results_df.isna().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f0739e4d-bed8-4c57-9698-25bb9917ffce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text_video_accuracy': 0.8119533527696793, 'text_audio_accuracy': 0.8367346938775511, 'audio_video_accuracy': 0.4970845481049563, 'trimodal_accuracy': 0.6472303206997084}\n"
     ]
    }
   ],
   "source": [
    "# Filter the test set\n",
    "temp = earlyFusion_results_df[earlyFusion_results_df['mode'] == 'test']\n",
    "\n",
    "# Display results\n",
    "temp_results = {\n",
    "    'text_video_accuracy': (temp['text_video_preds'] == temp['annotation_label']).mean(),\n",
    "    'text_audio_accuracy': (temp['text_audio_preds'] == temp['annotation_label']).mean(),\n",
    "    'audio_video_accuracy': (temp['audio_video_preds'] == temp['annotation_label']).mean(),\n",
    "    'trimodal_accuracy': (temp['trimodal_preds'] == temp['annotation_label']).mean()\n",
    "}\n",
    "\n",
    "print(temp_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1d4b60cd-9070-4332-9916-d01af67dbf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "earlyFusion_results_df.to_csv('earlyFusion_results_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0696f91f-872e-4a33-b385-b09189269bef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "My Enviroment",
   "language": "python",
   "name": "my_enviroment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
