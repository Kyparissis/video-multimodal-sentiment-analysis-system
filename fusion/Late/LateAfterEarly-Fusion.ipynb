{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "beb63af7-d4dc-4a61-8439-adcffd893638",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from collections import Counter\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a9216a-1b0e-4476-89b4-75b194d8149f",
   "metadata": {},
   "source": [
    "The extensive experiments using different\n",
    "classifiers and combinations of different vision and text features\n",
    "on multiple sentiment scenarios showed that late fusion is more\n",
    "effective than early fusion. The analysis of explainability revealed\n",
    "that in late fusion, the classes were predominantly influenced by\n",
    "the respective uni-modal prediction probabilities, indicating the necessity for extracting more appropriate features through additional\n",
    "fine-tuning procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ce99f41-cef1-484d-8723-baa0fa228023",
   "metadata": {},
   "outputs": [],
   "source": [
    "fusion_df = pd.read_csv(\"outputs_perModel.csv\", \n",
    "                         encoding='utf-8', \n",
    "                         header=0)\n",
    "\n",
    "temp = pd.read_csv('earlyFusion_results_df.csv')\n",
    "\n",
    "fusion_df = fusion_df.merge(\n",
    "    temp, on=[\"video_id\", \"clip_id\", \"annotation_label\", \"mode\"], how=\"inner\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a23fd46-a400-42a1-b077-7b91985ef938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>clip_id</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>mode</th>\n",
       "      <th>annotation_label</th>\n",
       "      <th>probText_0</th>\n",
       "      <th>probText_1</th>\n",
       "      <th>textLabel</th>\n",
       "      <th>probAudio_0</th>\n",
       "      <th>probAudio_1</th>\n",
       "      <th>...</th>\n",
       "      <th>trimodal_preds</th>\n",
       "      <th>text_audio_prob_0</th>\n",
       "      <th>text_audio_prob_1</th>\n",
       "      <th>text_audio_preds</th>\n",
       "      <th>audio_video_prob_0</th>\n",
       "      <th>audio_video_prob_1</th>\n",
       "      <th>audio_video_preds</th>\n",
       "      <th>text_video_prob_0</th>\n",
       "      <th>text_video_prob_1</th>\n",
       "      <th>text_video_preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>11</td>\n",
       "      <td>a lot of sad part</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.997359</td>\n",
       "      <td>0.002641</td>\n",
       "      <td>0</td>\n",
       "      <td>0.399598</td>\n",
       "      <td>0.600402</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.545542</td>\n",
       "      <td>0.454458</td>\n",
       "      <td>0</td>\n",
       "      <td>0.410912</td>\n",
       "      <td>0.589088</td>\n",
       "      <td>1</td>\n",
       "      <td>0.547833</td>\n",
       "      <td>0.452167</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>10</td>\n",
       "      <td>there is sad part</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.997300</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0</td>\n",
       "      <td>0.439418</td>\n",
       "      <td>0.560582</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.546001</td>\n",
       "      <td>0.453999</td>\n",
       "      <td>0</td>\n",
       "      <td>0.439674</td>\n",
       "      <td>0.560326</td>\n",
       "      <td>1</td>\n",
       "      <td>0.602740</td>\n",
       "      <td>0.397260</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>13</td>\n",
       "      <td>and it a really funny</td>\n",
       "      <td>train</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002918</td>\n",
       "      <td>0.997082</td>\n",
       "      <td>1</td>\n",
       "      <td>0.350468</td>\n",
       "      <td>0.649532</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.354512</td>\n",
       "      <td>0.645488</td>\n",
       "      <td>1</td>\n",
       "      <td>0.370054</td>\n",
       "      <td>0.629946</td>\n",
       "      <td>1</td>\n",
       "      <td>0.382594</td>\n",
       "      <td>0.617406</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>12</td>\n",
       "      <td>but it wa really really awesome</td>\n",
       "      <td>train</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002906</td>\n",
       "      <td>0.997094</td>\n",
       "      <td>1</td>\n",
       "      <td>0.347897</td>\n",
       "      <td>0.652103</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.349426</td>\n",
       "      <td>0.650574</td>\n",
       "      <td>1</td>\n",
       "      <td>0.358518</td>\n",
       "      <td>0.641482</td>\n",
       "      <td>1</td>\n",
       "      <td>0.386552</td>\n",
       "      <td>0.613448</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>1</td>\n",
       "      <td>anyhow it wa really good</td>\n",
       "      <td>train</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002872</td>\n",
       "      <td>0.997128</td>\n",
       "      <td>1</td>\n",
       "      <td>0.435212</td>\n",
       "      <td>0.564788</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.516387</td>\n",
       "      <td>0.483613</td>\n",
       "      <td>0</td>\n",
       "      <td>0.365942</td>\n",
       "      <td>0.634058</td>\n",
       "      <td>1</td>\n",
       "      <td>0.582906</td>\n",
       "      <td>0.417094</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2194</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>30</td>\n",
       "      <td>because there really wa not all that much to i...</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.997182</td>\n",
       "      <td>0.002818</td>\n",
       "      <td>0</td>\n",
       "      <td>0.597331</td>\n",
       "      <td>0.402669</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.559316</td>\n",
       "      <td>0.440684</td>\n",
       "      <td>0</td>\n",
       "      <td>0.546081</td>\n",
       "      <td>0.453919</td>\n",
       "      <td>0</td>\n",
       "      <td>0.542318</td>\n",
       "      <td>0.457682</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2195</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>35</td>\n",
       "      <td>so if you like to hear a like more positive re...</td>\n",
       "      <td>test</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.997070</td>\n",
       "      <td>1</td>\n",
       "      <td>0.399418</td>\n",
       "      <td>0.600582</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.334322</td>\n",
       "      <td>0.665678</td>\n",
       "      <td>1</td>\n",
       "      <td>0.398728</td>\n",
       "      <td>0.601272</td>\n",
       "      <td>1</td>\n",
       "      <td>0.396127</td>\n",
       "      <td>0.603873</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>34</td>\n",
       "      <td>and she really enjoyed the film</td>\n",
       "      <td>test</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002905</td>\n",
       "      <td>0.997095</td>\n",
       "      <td>1</td>\n",
       "      <td>0.341855</td>\n",
       "      <td>0.658145</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.344932</td>\n",
       "      <td>0.655068</td>\n",
       "      <td>1</td>\n",
       "      <td>0.354687</td>\n",
       "      <td>0.645313</td>\n",
       "      <td>1</td>\n",
       "      <td>0.386174</td>\n",
       "      <td>0.613826</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2197</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>33</td>\n",
       "      <td>if you do want to see somebody who is possibly...</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.996939</td>\n",
       "      <td>0.003061</td>\n",
       "      <td>0</td>\n",
       "      <td>0.406756</td>\n",
       "      <td>0.593244</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.481836</td>\n",
       "      <td>0.518164</td>\n",
       "      <td>1</td>\n",
       "      <td>0.461334</td>\n",
       "      <td>0.538666</td>\n",
       "      <td>1</td>\n",
       "      <td>0.524029</td>\n",
       "      <td>0.475971</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2198</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>32</td>\n",
       "      <td>yeah i mean if you want to see a video it goin...</td>\n",
       "      <td>test</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.003109</td>\n",
       "      <td>0.996891</td>\n",
       "      <td>1</td>\n",
       "      <td>0.462510</td>\n",
       "      <td>0.537490</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.361187</td>\n",
       "      <td>0.638813</td>\n",
       "      <td>1</td>\n",
       "      <td>0.425486</td>\n",
       "      <td>0.574514</td>\n",
       "      <td>1</td>\n",
       "      <td>0.371033</td>\n",
       "      <td>0.628967</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2199 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         video_id  clip_id                                     processed_text  \\\n",
       "0     03bSnISJMiM       11                                  a lot of sad part   \n",
       "1     03bSnISJMiM       10                                  there is sad part   \n",
       "2     03bSnISJMiM       13                              and it a really funny   \n",
       "3     03bSnISJMiM       12                    but it wa really really awesome   \n",
       "4     03bSnISJMiM        1                           anyhow it wa really good   \n",
       "...           ...      ...                                                ...   \n",
       "2194  zhpQhgha_KU       30  because there really wa not all that much to i...   \n",
       "2195  zhpQhgha_KU       35  so if you like to hear a like more positive re...   \n",
       "2196  zhpQhgha_KU       34                    and she really enjoyed the film   \n",
       "2197  zhpQhgha_KU       33  if you do want to see somebody who is possibly...   \n",
       "2198  zhpQhgha_KU       32  yeah i mean if you want to see a video it goin...   \n",
       "\n",
       "       mode  annotation_label  probText_0  probText_1  textLabel  probAudio_0  \\\n",
       "0     train               0.0    0.997359    0.002641          0     0.399598   \n",
       "1     train               0.0    0.997300    0.002700          0     0.439418   \n",
       "2     train               1.0    0.002918    0.997082          1     0.350468   \n",
       "3     train               1.0    0.002906    0.997094          1     0.347897   \n",
       "4     train               1.0    0.002872    0.997128          1     0.435212   \n",
       "...     ...               ...         ...         ...        ...          ...   \n",
       "2194   test               0.0    0.997182    0.002818          0     0.597331   \n",
       "2195   test               1.0    0.002930    0.997070          1     0.399418   \n",
       "2196   test               1.0    0.002905    0.997095          1     0.341855   \n",
       "2197   test               0.0    0.996939    0.003061          0     0.406756   \n",
       "2198   test               1.0    0.003109    0.996891          1     0.462510   \n",
       "\n",
       "      probAudio_1  ...  trimodal_preds  text_audio_prob_0  text_audio_prob_1  \\\n",
       "0        0.600402  ...               1           0.545542           0.454458   \n",
       "1        0.560582  ...               0           0.546001           0.453999   \n",
       "2        0.649532  ...               1           0.354512           0.645488   \n",
       "3        0.652103  ...               1           0.349426           0.650574   \n",
       "4        0.564788  ...               1           0.516387           0.483613   \n",
       "...           ...  ...             ...                ...                ...   \n",
       "2194     0.402669  ...               0           0.559316           0.440684   \n",
       "2195     0.600582  ...               1           0.334322           0.665678   \n",
       "2196     0.658145  ...               1           0.344932           0.655068   \n",
       "2197     0.593244  ...               1           0.481836           0.518164   \n",
       "2198     0.537490  ...               1           0.361187           0.638813   \n",
       "\n",
       "      text_audio_preds  audio_video_prob_0  audio_video_prob_1  \\\n",
       "0                    0            0.410912            0.589088   \n",
       "1                    0            0.439674            0.560326   \n",
       "2                    1            0.370054            0.629946   \n",
       "3                    1            0.358518            0.641482   \n",
       "4                    0            0.365942            0.634058   \n",
       "...                ...                 ...                 ...   \n",
       "2194                 0            0.546081            0.453919   \n",
       "2195                 1            0.398728            0.601272   \n",
       "2196                 1            0.354687            0.645313   \n",
       "2197                 1            0.461334            0.538666   \n",
       "2198                 1            0.425486            0.574514   \n",
       "\n",
       "      audio_video_preds  text_video_prob_0  text_video_prob_1  \\\n",
       "0                     1           0.547833           0.452167   \n",
       "1                     1           0.602740           0.397260   \n",
       "2                     1           0.382594           0.617406   \n",
       "3                     1           0.386552           0.613448   \n",
       "4                     1           0.582906           0.417094   \n",
       "...                 ...                ...                ...   \n",
       "2194                  0           0.542318           0.457682   \n",
       "2195                  1           0.396127           0.603873   \n",
       "2196                  1           0.386174           0.613826   \n",
       "2197                  1           0.524029           0.475971   \n",
       "2198                  1           0.371033           0.628967   \n",
       "\n",
       "      text_video_preds  \n",
       "0                    0  \n",
       "1                    0  \n",
       "2                    1  \n",
       "3                    1  \n",
       "4                    0  \n",
       "...                ...  \n",
       "2194                 0  \n",
       "2195                 1  \n",
       "2196                 1  \n",
       "2197                 0  \n",
       "2198                 1  \n",
       "\n",
       "[2199 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fusion_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e3190da-5a51-4b36-bcbb-34781e6bda6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "pd.set_option('display.expand_frame_repr', False)  # Prevent line wrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d9be75a-eac9-45f9-a08d-584859c41f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>clip_id</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>mode</th>\n",
       "      <th>annotation_label</th>\n",
       "      <th>probText_0</th>\n",
       "      <th>probText_1</th>\n",
       "      <th>textLabel</th>\n",
       "      <th>probAudio_0</th>\n",
       "      <th>probAudio_1</th>\n",
       "      <th>audioLabel</th>\n",
       "      <th>probVideo_0</th>\n",
       "      <th>probVideo_1</th>\n",
       "      <th>videoLabel</th>\n",
       "      <th>trimodal_prob_0</th>\n",
       "      <th>trimodal_prob_1</th>\n",
       "      <th>trimodal_preds</th>\n",
       "      <th>text_audio_prob_0</th>\n",
       "      <th>text_audio_prob_1</th>\n",
       "      <th>text_audio_preds</th>\n",
       "      <th>audio_video_prob_0</th>\n",
       "      <th>audio_video_prob_1</th>\n",
       "      <th>audio_video_preds</th>\n",
       "      <th>text_video_prob_0</th>\n",
       "      <th>text_video_prob_1</th>\n",
       "      <th>text_video_preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2140</th>\n",
       "      <td>yDtzw_Y-7RU</td>\n",
       "      <td>18</td>\n",
       "      <td>also about the animation the people just like ...</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.996969</td>\n",
       "      <td>0.003031</td>\n",
       "      <td>0</td>\n",
       "      <td>0.471698</td>\n",
       "      <td>0.528302</td>\n",
       "      <td>1</td>\n",
       "      <td>0.51943</td>\n",
       "      <td>0.48057</td>\n",
       "      <td>0</td>\n",
       "      <td>0.269035</td>\n",
       "      <td>0.730965</td>\n",
       "      <td>1</td>\n",
       "      <td>0.507976</td>\n",
       "      <td>0.492024</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458879</td>\n",
       "      <td>0.541121</td>\n",
       "      <td>1</td>\n",
       "      <td>0.609702</td>\n",
       "      <td>0.390298</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         video_id  clip_id                                     processed_text  mode  annotation_label  probText_0  probText_1  textLabel  probAudio_0  probAudio_1  audioLabel  probVideo_0  probVideo_1  videoLabel  trimodal_prob_0  trimodal_prob_1  trimodal_preds  text_audio_prob_0  text_audio_prob_1  text_audio_preds  audio_video_prob_0  audio_video_prob_1  audio_video_preds  text_video_prob_0  text_video_prob_1  text_video_preds\n",
       "2140  yDtzw_Y-7RU       18  also about the animation the people just like ...  test               0.0    0.996969    0.003031          0     0.471698     0.528302           1      0.51943      0.48057           0         0.269035         0.730965               1           0.507976           0.492024                 0            0.458879            0.541121                  1           0.609702           0.390298                 0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fusion_df[(fusion_df['video_id'] == 'yDtzw_Y-7RU') & (fusion_df['clip_id'] == 18)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d57dc88-58b6-4a01-ba46-68be9ae9484b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printReport(df, column_name):\n",
    "    subsets = ['train', 'valid', 'test']\n",
    "        \n",
    "    print(\"Classification Report for the Whole Dataset:\")\n",
    "    print(classification_report(df['annotation_label'], df[column_name], digits=4))\n",
    "    \n",
    "    for subset in subsets:\n",
    "        subset_df = df[df['mode'] == subset]\n",
    "        if not subset_df.empty:\n",
    "            print(f\"\\nClassification Report for {subset.capitalize()} Subset:\")\n",
    "            print(classification_report(subset_df['annotation_label'], subset_df[column_name], digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5501609e-da35-4c03-ab68-5324b24d2e68",
   "metadata": {},
   "source": [
    "---\n",
    "# Hard Fusion (Based on labels)   \n",
    "---\n",
    "\n",
    "https://chatgpt.com/c/67981b72-fdf4-8002-95bd-5a75e258e4c3\n",
    "\n",
    "# Majority Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed9765e7-794c-4c5f-a3dd-7a96ec52a22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for majority voting\n",
    "def majority_vote(row):\n",
    "    # Collect the predicted labels\n",
    "    labels = [row['textLabel'], \n",
    "              row['audioLabel'],\n",
    "              row['videoLabel'],\n",
    "              row['trimodal_preds'],\n",
    "              row['text_audio_preds'],\n",
    "              row['audio_video_preds'],\n",
    "              row['text_video_preds'],\n",
    "             ]\n",
    "    \n",
    "    # Count the occurrences of each class\n",
    "    class_0_count = labels.count(0)\n",
    "    class_1_count = labels.count(1)\n",
    "    \n",
    "    # Apply majority voting\n",
    "    if class_0_count > class_1_count:\n",
    "        return 0\n",
    "    elif class_1_count > class_0_count:\n",
    "        return 1\n",
    "    else:\n",
    "        # Tie-breaking rule (e.g., prioritize textLabel or assign -1 for a tie)\n",
    "        return row['textLabel']  # Example: prioritizing text predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db1eabda-b823-4952-8d78-90ebbb7ed862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply majority voting to each row\n",
    "fusion_df['majorityLabel'] = fusion_df.apply(majority_vote, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e53e7dd4-4ded-4277-9998-9cd193275057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>clip_id</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>mode</th>\n",
       "      <th>annotation_label</th>\n",
       "      <th>probText_0</th>\n",
       "      <th>probText_1</th>\n",
       "      <th>textLabel</th>\n",
       "      <th>probAudio_0</th>\n",
       "      <th>probAudio_1</th>\n",
       "      <th>...</th>\n",
       "      <th>text_audio_prob_0</th>\n",
       "      <th>text_audio_prob_1</th>\n",
       "      <th>text_audio_preds</th>\n",
       "      <th>audio_video_prob_0</th>\n",
       "      <th>audio_video_prob_1</th>\n",
       "      <th>audio_video_preds</th>\n",
       "      <th>text_video_prob_0</th>\n",
       "      <th>text_video_prob_1</th>\n",
       "      <th>text_video_preds</th>\n",
       "      <th>majorityLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>11</td>\n",
       "      <td>a lot of sad part</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.997359</td>\n",
       "      <td>0.002641</td>\n",
       "      <td>0</td>\n",
       "      <td>0.399598</td>\n",
       "      <td>0.600402</td>\n",
       "      <td>...</td>\n",
       "      <td>0.545542</td>\n",
       "      <td>0.454458</td>\n",
       "      <td>0</td>\n",
       "      <td>0.410912</td>\n",
       "      <td>0.589088</td>\n",
       "      <td>1</td>\n",
       "      <td>0.547833</td>\n",
       "      <td>0.452167</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>10</td>\n",
       "      <td>there is sad part</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.997300</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0</td>\n",
       "      <td>0.439418</td>\n",
       "      <td>0.560582</td>\n",
       "      <td>...</td>\n",
       "      <td>0.546001</td>\n",
       "      <td>0.453999</td>\n",
       "      <td>0</td>\n",
       "      <td>0.439674</td>\n",
       "      <td>0.560326</td>\n",
       "      <td>1</td>\n",
       "      <td>0.602740</td>\n",
       "      <td>0.397260</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>13</td>\n",
       "      <td>and it a really funny</td>\n",
       "      <td>train</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002918</td>\n",
       "      <td>0.997082</td>\n",
       "      <td>1</td>\n",
       "      <td>0.350468</td>\n",
       "      <td>0.649532</td>\n",
       "      <td>...</td>\n",
       "      <td>0.354512</td>\n",
       "      <td>0.645488</td>\n",
       "      <td>1</td>\n",
       "      <td>0.370054</td>\n",
       "      <td>0.629946</td>\n",
       "      <td>1</td>\n",
       "      <td>0.382594</td>\n",
       "      <td>0.617406</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>12</td>\n",
       "      <td>but it wa really really awesome</td>\n",
       "      <td>train</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002906</td>\n",
       "      <td>0.997094</td>\n",
       "      <td>1</td>\n",
       "      <td>0.347897</td>\n",
       "      <td>0.652103</td>\n",
       "      <td>...</td>\n",
       "      <td>0.349426</td>\n",
       "      <td>0.650574</td>\n",
       "      <td>1</td>\n",
       "      <td>0.358518</td>\n",
       "      <td>0.641482</td>\n",
       "      <td>1</td>\n",
       "      <td>0.386552</td>\n",
       "      <td>0.613448</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>1</td>\n",
       "      <td>anyhow it wa really good</td>\n",
       "      <td>train</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002872</td>\n",
       "      <td>0.997128</td>\n",
       "      <td>1</td>\n",
       "      <td>0.435212</td>\n",
       "      <td>0.564788</td>\n",
       "      <td>...</td>\n",
       "      <td>0.516387</td>\n",
       "      <td>0.483613</td>\n",
       "      <td>0</td>\n",
       "      <td>0.365942</td>\n",
       "      <td>0.634058</td>\n",
       "      <td>1</td>\n",
       "      <td>0.582906</td>\n",
       "      <td>0.417094</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2194</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>30</td>\n",
       "      <td>because there really wa not all that much to i...</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.997182</td>\n",
       "      <td>0.002818</td>\n",
       "      <td>0</td>\n",
       "      <td>0.597331</td>\n",
       "      <td>0.402669</td>\n",
       "      <td>...</td>\n",
       "      <td>0.559316</td>\n",
       "      <td>0.440684</td>\n",
       "      <td>0</td>\n",
       "      <td>0.546081</td>\n",
       "      <td>0.453919</td>\n",
       "      <td>0</td>\n",
       "      <td>0.542318</td>\n",
       "      <td>0.457682</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2195</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>35</td>\n",
       "      <td>so if you like to hear a like more positive re...</td>\n",
       "      <td>test</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.997070</td>\n",
       "      <td>1</td>\n",
       "      <td>0.399418</td>\n",
       "      <td>0.600582</td>\n",
       "      <td>...</td>\n",
       "      <td>0.334322</td>\n",
       "      <td>0.665678</td>\n",
       "      <td>1</td>\n",
       "      <td>0.398728</td>\n",
       "      <td>0.601272</td>\n",
       "      <td>1</td>\n",
       "      <td>0.396127</td>\n",
       "      <td>0.603873</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>34</td>\n",
       "      <td>and she really enjoyed the film</td>\n",
       "      <td>test</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002905</td>\n",
       "      <td>0.997095</td>\n",
       "      <td>1</td>\n",
       "      <td>0.341855</td>\n",
       "      <td>0.658145</td>\n",
       "      <td>...</td>\n",
       "      <td>0.344932</td>\n",
       "      <td>0.655068</td>\n",
       "      <td>1</td>\n",
       "      <td>0.354687</td>\n",
       "      <td>0.645313</td>\n",
       "      <td>1</td>\n",
       "      <td>0.386174</td>\n",
       "      <td>0.613826</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2197</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>33</td>\n",
       "      <td>if you do want to see somebody who is possibly...</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.996939</td>\n",
       "      <td>0.003061</td>\n",
       "      <td>0</td>\n",
       "      <td>0.406756</td>\n",
       "      <td>0.593244</td>\n",
       "      <td>...</td>\n",
       "      <td>0.481836</td>\n",
       "      <td>0.518164</td>\n",
       "      <td>1</td>\n",
       "      <td>0.461334</td>\n",
       "      <td>0.538666</td>\n",
       "      <td>1</td>\n",
       "      <td>0.524029</td>\n",
       "      <td>0.475971</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2198</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>32</td>\n",
       "      <td>yeah i mean if you want to see a video it goin...</td>\n",
       "      <td>test</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.003109</td>\n",
       "      <td>0.996891</td>\n",
       "      <td>1</td>\n",
       "      <td>0.462510</td>\n",
       "      <td>0.537490</td>\n",
       "      <td>...</td>\n",
       "      <td>0.361187</td>\n",
       "      <td>0.638813</td>\n",
       "      <td>1</td>\n",
       "      <td>0.425486</td>\n",
       "      <td>0.574514</td>\n",
       "      <td>1</td>\n",
       "      <td>0.371033</td>\n",
       "      <td>0.628967</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2199 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         video_id  clip_id                                     processed_text  \\\n",
       "0     03bSnISJMiM       11                                  a lot of sad part   \n",
       "1     03bSnISJMiM       10                                  there is sad part   \n",
       "2     03bSnISJMiM       13                              and it a really funny   \n",
       "3     03bSnISJMiM       12                    but it wa really really awesome   \n",
       "4     03bSnISJMiM        1                           anyhow it wa really good   \n",
       "...           ...      ...                                                ...   \n",
       "2194  zhpQhgha_KU       30  because there really wa not all that much to i...   \n",
       "2195  zhpQhgha_KU       35  so if you like to hear a like more positive re...   \n",
       "2196  zhpQhgha_KU       34                    and she really enjoyed the film   \n",
       "2197  zhpQhgha_KU       33  if you do want to see somebody who is possibly...   \n",
       "2198  zhpQhgha_KU       32  yeah i mean if you want to see a video it goin...   \n",
       "\n",
       "       mode  annotation_label  probText_0  probText_1  textLabel  probAudio_0  \\\n",
       "0     train               0.0    0.997359    0.002641          0     0.399598   \n",
       "1     train               0.0    0.997300    0.002700          0     0.439418   \n",
       "2     train               1.0    0.002918    0.997082          1     0.350468   \n",
       "3     train               1.0    0.002906    0.997094          1     0.347897   \n",
       "4     train               1.0    0.002872    0.997128          1     0.435212   \n",
       "...     ...               ...         ...         ...        ...          ...   \n",
       "2194   test               0.0    0.997182    0.002818          0     0.597331   \n",
       "2195   test               1.0    0.002930    0.997070          1     0.399418   \n",
       "2196   test               1.0    0.002905    0.997095          1     0.341855   \n",
       "2197   test               0.0    0.996939    0.003061          0     0.406756   \n",
       "2198   test               1.0    0.003109    0.996891          1     0.462510   \n",
       "\n",
       "      probAudio_1  ...  text_audio_prob_0  text_audio_prob_1  \\\n",
       "0        0.600402  ...           0.545542           0.454458   \n",
       "1        0.560582  ...           0.546001           0.453999   \n",
       "2        0.649532  ...           0.354512           0.645488   \n",
       "3        0.652103  ...           0.349426           0.650574   \n",
       "4        0.564788  ...           0.516387           0.483613   \n",
       "...           ...  ...                ...                ...   \n",
       "2194     0.402669  ...           0.559316           0.440684   \n",
       "2195     0.600582  ...           0.334322           0.665678   \n",
       "2196     0.658145  ...           0.344932           0.655068   \n",
       "2197     0.593244  ...           0.481836           0.518164   \n",
       "2198     0.537490  ...           0.361187           0.638813   \n",
       "\n",
       "      text_audio_preds  audio_video_prob_0  audio_video_prob_1  \\\n",
       "0                    0            0.410912            0.589088   \n",
       "1                    0            0.439674            0.560326   \n",
       "2                    1            0.370054            0.629946   \n",
       "3                    1            0.358518            0.641482   \n",
       "4                    0            0.365942            0.634058   \n",
       "...                ...                 ...                 ...   \n",
       "2194                 0            0.546081            0.453919   \n",
       "2195                 1            0.398728            0.601272   \n",
       "2196                 1            0.354687            0.645313   \n",
       "2197                 1            0.461334            0.538666   \n",
       "2198                 1            0.425486            0.574514   \n",
       "\n",
       "      audio_video_preds  text_video_prob_0  text_video_prob_1  \\\n",
       "0                     1           0.547833           0.452167   \n",
       "1                     1           0.602740           0.397260   \n",
       "2                     1           0.382594           0.617406   \n",
       "3                     1           0.386552           0.613448   \n",
       "4                     1           0.582906           0.417094   \n",
       "...                 ...                ...                ...   \n",
       "2194                  0           0.542318           0.457682   \n",
       "2195                  1           0.396127           0.603873   \n",
       "2196                  1           0.386174           0.613826   \n",
       "2197                  1           0.524029           0.475971   \n",
       "2198                  1           0.371033           0.628967   \n",
       "\n",
       "      text_video_preds  majorityLabel  \n",
       "0                    0              1  \n",
       "1                    0              0  \n",
       "2                    1              1  \n",
       "3                    1              1  \n",
       "4                    0              1  \n",
       "...                ...            ...  \n",
       "2194                 0              0  \n",
       "2195                 1              1  \n",
       "2196                 1              1  \n",
       "2197                 0              1  \n",
       "2198                 1              1  \n",
       "\n",
       "[2199 rows x 27 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fusion_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c76087f-9535-4f69-a027-f9a559f3d60d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for the Whole Dataset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8277    0.6432    0.7239      1023\n",
      "         1.0     0.7400    0.8835    0.8054      1176\n",
      "\n",
      "    accuracy                         0.7717      2199\n",
      "   macro avg     0.7839    0.7634    0.7646      2199\n",
      "weighted avg     0.7808    0.7717    0.7675      2199\n",
      "\n",
      "\n",
      "Classification Report for Train Subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8510    0.6830    0.7578       552\n",
      "         1.0     0.7919    0.9098    0.8468       732\n",
      "\n",
      "    accuracy                         0.8123      1284\n",
      "   macro avg     0.8215    0.7964    0.8023      1284\n",
      "weighted avg     0.8173    0.8123    0.8085      1284\n",
      "\n",
      "\n",
      "Classification Report for Valid Subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6667    0.4783    0.5570        92\n",
      "         1.0     0.7055    0.8394    0.7667       137\n",
      "\n",
      "    accuracy                         0.6943       229\n",
      "   macro avg     0.6861    0.6588    0.6618       229\n",
      "weighted avg     0.6899    0.6943    0.6824       229\n",
      "\n",
      "\n",
      "Classification Report for Test Subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8287    0.6253    0.7128       379\n",
      "         1.0     0.6450    0.8404    0.7298       307\n",
      "\n",
      "    accuracy                         0.7216       686\n",
      "   macro avg     0.7368    0.7329    0.7213       686\n",
      "weighted avg     0.7465    0.7216    0.7204       686\n",
      "\n"
     ]
    }
   ],
   "source": [
    "printReport(fusion_df, 'majorityLabel')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c164b97b-79d0-4ddb-ac4f-4ebaf4900110",
   "metadata": {},
   "source": [
    "# Weighted Voting\n",
    "\n",
    "## Weights for each modality based on validation set label's accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78cf8a7c-b352-4946-9dac-8154500dfe47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_weights(df, mode='valid'):\n",
    "    \"\"\"Calculate weights for each modality based on validation accuracy.\"\"\"\n",
    "    validation_df = df[df['mode'] == mode]\n",
    "    \n",
    "    text_accuracy = (validation_df['textLabel'] == validation_df['annotation_label']).mean()\n",
    "    audio_accuracy = (validation_df['audioLabel'] == validation_df['annotation_label']).mean()\n",
    "    video_accuracy = (validation_df['videoLabel'] == validation_df['annotation_label']).mean()\n",
    "    trimodal_accuracy = (validation_df['trimodal_preds'] == validation_df['annotation_label']).mean()\n",
    "    text_audio_accuracy = (validation_df['text_audio_preds'] == validation_df['annotation_label']).mean()\n",
    "    audio_video_accuracy = (validation_df['audio_video_preds'] == validation_df['annotation_label']).mean()\n",
    "    text_video_accuracy = (validation_df['text_video_preds'] == validation_df['annotation_label']).mean()\n",
    "    \n",
    "    return {\n",
    "        'text': text_accuracy,\n",
    "        'audio': audio_accuracy,\n",
    "        'video': video_accuracy,\n",
    "        'trimodal': trimodal_accuracy,\n",
    "        'text_audio': text_audio_accuracy,\n",
    "        'audio_video': audio_video_accuracy,\n",
    "        'text_video': text_video_accuracy\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27a0b4ac-a137-40d9-bf77-c81ea2f950ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 0.8646288209606987, 'audio': 0.6069868995633187, 'video': 0.45414847161572053, 'trimodal': 0.6550218340611353, 'text_audio': 0.8558951965065502, 'audio_video': 0.5720524017467249, 'text_video': 0.7161572052401747}\n"
     ]
    }
   ],
   "source": [
    "weights = calculate_weights(fusion_df)\n",
    "\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c52ed2b-d40e-414e-891e-aef4436331ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_voting_fusion(df, weights):\n",
    "    \"\"\"Perform late fusion using Weighted Voting.\"\"\"\n",
    "    def fused_label(row):\n",
    "        # Calculate the weighted votes\n",
    "        votes = Counter({\n",
    "            row['textLabel']: weights['text'],\n",
    "            row['audioLabel']: weights['audio'],\n",
    "            row['videoLabel']: weights['video'],\n",
    "            row['trimodal_preds']: weights['trimodal'],\n",
    "            row['text_audio_preds']: weights['text_audio'],\n",
    "            row['audio_video_preds']: weights['audio_video'],\n",
    "            row['text_video_preds']: weights['text_video']\n",
    "        })\n",
    "        # Return the label with the highest weight\n",
    "        return votes.most_common(1)[0][0]\n",
    "\n",
    "    df['weightedVotingOnLabel_validationAccuracyWeights_Label'] = df.apply(fused_label, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35a3b426-ab45-4035-8086-36902c1019cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fusion_df = weighted_voting_fusion(fusion_df, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c62dceb4-aca3-45af-be8c-3e71ebc6f683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>clip_id</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>mode</th>\n",
       "      <th>annotation_label</th>\n",
       "      <th>probText_0</th>\n",
       "      <th>probText_1</th>\n",
       "      <th>textLabel</th>\n",
       "      <th>probAudio_0</th>\n",
       "      <th>probAudio_1</th>\n",
       "      <th>...</th>\n",
       "      <th>text_audio_prob_1</th>\n",
       "      <th>text_audio_preds</th>\n",
       "      <th>audio_video_prob_0</th>\n",
       "      <th>audio_video_prob_1</th>\n",
       "      <th>audio_video_preds</th>\n",
       "      <th>text_video_prob_0</th>\n",
       "      <th>text_video_prob_1</th>\n",
       "      <th>text_video_preds</th>\n",
       "      <th>majorityLabel</th>\n",
       "      <th>weightedVotingOnLabel_validationAccuracyWeights_Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>11</td>\n",
       "      <td>a lot of sad part</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.997359</td>\n",
       "      <td>0.002641</td>\n",
       "      <td>0</td>\n",
       "      <td>0.399598</td>\n",
       "      <td>0.600402</td>\n",
       "      <td>...</td>\n",
       "      <td>0.454458</td>\n",
       "      <td>0</td>\n",
       "      <td>0.410912</td>\n",
       "      <td>0.589088</td>\n",
       "      <td>1</td>\n",
       "      <td>0.547833</td>\n",
       "      <td>0.452167</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>10</td>\n",
       "      <td>there is sad part</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.997300</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0</td>\n",
       "      <td>0.439418</td>\n",
       "      <td>0.560582</td>\n",
       "      <td>...</td>\n",
       "      <td>0.453999</td>\n",
       "      <td>0</td>\n",
       "      <td>0.439674</td>\n",
       "      <td>0.560326</td>\n",
       "      <td>1</td>\n",
       "      <td>0.602740</td>\n",
       "      <td>0.397260</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>13</td>\n",
       "      <td>and it a really funny</td>\n",
       "      <td>train</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002918</td>\n",
       "      <td>0.997082</td>\n",
       "      <td>1</td>\n",
       "      <td>0.350468</td>\n",
       "      <td>0.649532</td>\n",
       "      <td>...</td>\n",
       "      <td>0.645488</td>\n",
       "      <td>1</td>\n",
       "      <td>0.370054</td>\n",
       "      <td>0.629946</td>\n",
       "      <td>1</td>\n",
       "      <td>0.382594</td>\n",
       "      <td>0.617406</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>12</td>\n",
       "      <td>but it wa really really awesome</td>\n",
       "      <td>train</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002906</td>\n",
       "      <td>0.997094</td>\n",
       "      <td>1</td>\n",
       "      <td>0.347897</td>\n",
       "      <td>0.652103</td>\n",
       "      <td>...</td>\n",
       "      <td>0.650574</td>\n",
       "      <td>1</td>\n",
       "      <td>0.358518</td>\n",
       "      <td>0.641482</td>\n",
       "      <td>1</td>\n",
       "      <td>0.386552</td>\n",
       "      <td>0.613448</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>1</td>\n",
       "      <td>anyhow it wa really good</td>\n",
       "      <td>train</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002872</td>\n",
       "      <td>0.997128</td>\n",
       "      <td>1</td>\n",
       "      <td>0.435212</td>\n",
       "      <td>0.564788</td>\n",
       "      <td>...</td>\n",
       "      <td>0.483613</td>\n",
       "      <td>0</td>\n",
       "      <td>0.365942</td>\n",
       "      <td>0.634058</td>\n",
       "      <td>1</td>\n",
       "      <td>0.582906</td>\n",
       "      <td>0.417094</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2194</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>30</td>\n",
       "      <td>because there really wa not all that much to i...</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.997182</td>\n",
       "      <td>0.002818</td>\n",
       "      <td>0</td>\n",
       "      <td>0.597331</td>\n",
       "      <td>0.402669</td>\n",
       "      <td>...</td>\n",
       "      <td>0.440684</td>\n",
       "      <td>0</td>\n",
       "      <td>0.546081</td>\n",
       "      <td>0.453919</td>\n",
       "      <td>0</td>\n",
       "      <td>0.542318</td>\n",
       "      <td>0.457682</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2195</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>35</td>\n",
       "      <td>so if you like to hear a like more positive re...</td>\n",
       "      <td>test</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.997070</td>\n",
       "      <td>1</td>\n",
       "      <td>0.399418</td>\n",
       "      <td>0.600582</td>\n",
       "      <td>...</td>\n",
       "      <td>0.665678</td>\n",
       "      <td>1</td>\n",
       "      <td>0.398728</td>\n",
       "      <td>0.601272</td>\n",
       "      <td>1</td>\n",
       "      <td>0.396127</td>\n",
       "      <td>0.603873</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>34</td>\n",
       "      <td>and she really enjoyed the film</td>\n",
       "      <td>test</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002905</td>\n",
       "      <td>0.997095</td>\n",
       "      <td>1</td>\n",
       "      <td>0.341855</td>\n",
       "      <td>0.658145</td>\n",
       "      <td>...</td>\n",
       "      <td>0.655068</td>\n",
       "      <td>1</td>\n",
       "      <td>0.354687</td>\n",
       "      <td>0.645313</td>\n",
       "      <td>1</td>\n",
       "      <td>0.386174</td>\n",
       "      <td>0.613826</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2197</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>33</td>\n",
       "      <td>if you do want to see somebody who is possibly...</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.996939</td>\n",
       "      <td>0.003061</td>\n",
       "      <td>0</td>\n",
       "      <td>0.406756</td>\n",
       "      <td>0.593244</td>\n",
       "      <td>...</td>\n",
       "      <td>0.518164</td>\n",
       "      <td>1</td>\n",
       "      <td>0.461334</td>\n",
       "      <td>0.538666</td>\n",
       "      <td>1</td>\n",
       "      <td>0.524029</td>\n",
       "      <td>0.475971</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2198</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>32</td>\n",
       "      <td>yeah i mean if you want to see a video it goin...</td>\n",
       "      <td>test</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.003109</td>\n",
       "      <td>0.996891</td>\n",
       "      <td>1</td>\n",
       "      <td>0.462510</td>\n",
       "      <td>0.537490</td>\n",
       "      <td>...</td>\n",
       "      <td>0.638813</td>\n",
       "      <td>1</td>\n",
       "      <td>0.425486</td>\n",
       "      <td>0.574514</td>\n",
       "      <td>1</td>\n",
       "      <td>0.371033</td>\n",
       "      <td>0.628967</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2199 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         video_id  clip_id                                     processed_text  \\\n",
       "0     03bSnISJMiM       11                                  a lot of sad part   \n",
       "1     03bSnISJMiM       10                                  there is sad part   \n",
       "2     03bSnISJMiM       13                              and it a really funny   \n",
       "3     03bSnISJMiM       12                    but it wa really really awesome   \n",
       "4     03bSnISJMiM        1                           anyhow it wa really good   \n",
       "...           ...      ...                                                ...   \n",
       "2194  zhpQhgha_KU       30  because there really wa not all that much to i...   \n",
       "2195  zhpQhgha_KU       35  so if you like to hear a like more positive re...   \n",
       "2196  zhpQhgha_KU       34                    and she really enjoyed the film   \n",
       "2197  zhpQhgha_KU       33  if you do want to see somebody who is possibly...   \n",
       "2198  zhpQhgha_KU       32  yeah i mean if you want to see a video it goin...   \n",
       "\n",
       "       mode  annotation_label  probText_0  probText_1  textLabel  probAudio_0  \\\n",
       "0     train               0.0    0.997359    0.002641          0     0.399598   \n",
       "1     train               0.0    0.997300    0.002700          0     0.439418   \n",
       "2     train               1.0    0.002918    0.997082          1     0.350468   \n",
       "3     train               1.0    0.002906    0.997094          1     0.347897   \n",
       "4     train               1.0    0.002872    0.997128          1     0.435212   \n",
       "...     ...               ...         ...         ...        ...          ...   \n",
       "2194   test               0.0    0.997182    0.002818          0     0.597331   \n",
       "2195   test               1.0    0.002930    0.997070          1     0.399418   \n",
       "2196   test               1.0    0.002905    0.997095          1     0.341855   \n",
       "2197   test               0.0    0.996939    0.003061          0     0.406756   \n",
       "2198   test               1.0    0.003109    0.996891          1     0.462510   \n",
       "\n",
       "      probAudio_1  ...  text_audio_prob_1  text_audio_preds  \\\n",
       "0        0.600402  ...           0.454458                 0   \n",
       "1        0.560582  ...           0.453999                 0   \n",
       "2        0.649532  ...           0.645488                 1   \n",
       "3        0.652103  ...           0.650574                 1   \n",
       "4        0.564788  ...           0.483613                 0   \n",
       "...           ...  ...                ...               ...   \n",
       "2194     0.402669  ...           0.440684                 0   \n",
       "2195     0.600582  ...           0.665678                 1   \n",
       "2196     0.658145  ...           0.655068                 1   \n",
       "2197     0.593244  ...           0.518164                 1   \n",
       "2198     0.537490  ...           0.638813                 1   \n",
       "\n",
       "      audio_video_prob_0  audio_video_prob_1  audio_video_preds  \\\n",
       "0               0.410912            0.589088                  1   \n",
       "1               0.439674            0.560326                  1   \n",
       "2               0.370054            0.629946                  1   \n",
       "3               0.358518            0.641482                  1   \n",
       "4               0.365942            0.634058                  1   \n",
       "...                  ...                 ...                ...   \n",
       "2194            0.546081            0.453919                  0   \n",
       "2195            0.398728            0.601272                  1   \n",
       "2196            0.354687            0.645313                  1   \n",
       "2197            0.461334            0.538666                  1   \n",
       "2198            0.425486            0.574514                  1   \n",
       "\n",
       "      text_video_prob_0  text_video_prob_1  text_video_preds  majorityLabel  \\\n",
       "0              0.547833           0.452167                 0              1   \n",
       "1              0.602740           0.397260                 0              0   \n",
       "2              0.382594           0.617406                 1              1   \n",
       "3              0.386552           0.613448                 1              1   \n",
       "4              0.582906           0.417094                 0              1   \n",
       "...                 ...                ...               ...            ...   \n",
       "2194           0.542318           0.457682                 0              0   \n",
       "2195           0.396127           0.603873                 1              1   \n",
       "2196           0.386174           0.613826                 1              1   \n",
       "2197           0.524029           0.475971                 0              1   \n",
       "2198           0.371033           0.628967                 1              1   \n",
       "\n",
       "      weightedVotingOnLabel_validationAccuracyWeights_Label  \n",
       "0                                                     0      \n",
       "1                                                     0      \n",
       "2                                                     1      \n",
       "3                                                     1      \n",
       "4                                                     0      \n",
       "...                                                 ...      \n",
       "2194                                                  0      \n",
       "2195                                                  1      \n",
       "2196                                                  1      \n",
       "2197                                                  0      \n",
       "2198                                                  1      \n",
       "\n",
       "[2199 rows x 28 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fusion_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "278fc170-2141-47ab-9378-aa295cb99a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for the Whole Dataset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.5837    0.7087    0.6402      1023\n",
      "         1.0     0.6886    0.5604    0.6179      1176\n",
      "\n",
      "    accuracy                         0.6294      2199\n",
      "   macro avg     0.6362    0.6345    0.6290      2199\n",
      "weighted avg     0.6398    0.6294    0.6283      2199\n",
      "\n",
      "\n",
      "Classification Report for Train Subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.4464    0.5580    0.4960       552\n",
      "         1.0     0.5892    0.4781    0.5279       732\n",
      "\n",
      "    accuracy                         0.5125      1284\n",
      "   macro avg     0.5178    0.5181    0.5119      1284\n",
      "weighted avg     0.5278    0.5125    0.5142      1284\n",
      "\n",
      "\n",
      "Classification Report for Valid Subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6103    0.9022    0.7281        92\n",
      "         1.0     0.9032    0.6131    0.7304       137\n",
      "\n",
      "    accuracy                         0.7293       229\n",
      "   macro avg     0.7568    0.7577    0.7293       229\n",
      "weighted avg     0.7855    0.7293    0.7295       229\n",
      "\n",
      "\n",
      "Classification Report for Test Subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8029    0.8813    0.8403       379\n",
      "         1.0     0.8333    0.7329    0.7799       307\n",
      "\n",
      "    accuracy                         0.8149       686\n",
      "   macro avg     0.8181    0.8071    0.8101       686\n",
      "weighted avg     0.8165    0.8149    0.8132       686\n",
      "\n"
     ]
    }
   ],
   "source": [
    "printReport(fusion_df, 'weightedVotingOnLabel_validationAccuracyWeights_Label')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc8d6ef-9778-41f3-adb6-192358b75c99",
   "metadata": {},
   "source": [
    "## Weights for each modality using logistic regression on labels\n",
    "\n",
    "There is no reason for us to calculate the weights using logistic regression on the predicted labels (not probabilities) since they will give the same results.\n",
    "\n",
    "The test accuracy remains the same whether weights for each modality are calculated using logistic regression on the validation set labels or directly based on validation set accuracy because both methods fundamentally measure the reliability of each modality. \n",
    "\n",
    "Logistic regression, when applied to labels, essentially learns a simple model that reflects the alignment between each modality’s predictions and the ground truth, which is conceptually similar to calculating validation accuracy. \n",
    "\n",
    "In both cases, the derived weights reflect the relative reliability of the modalities and are normalized to ensure comparability. Consequently, the weighted voting process amplifies the influence of more reliable modalities in the same way, leading to similar test accuracy outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "71ef471f-4e36-4b19-9fe0-2aa78224a1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# def calculate_weights_with_logistic_regression(df, mode='valid'):\n",
    "#     \"\"\"Calculate weights for each modality using logistic regression.\"\"\"\n",
    "#     validation_df = df[df['mode'] == mode]\n",
    "#     X = validation_df[['probText_0', 'probText_1', 'probAudio_0', 'probAudio_1', 'probVideo_0', 'probVideo_1']]\n",
    "#     y = validation_df['annotation_label']\n",
    "    \n",
    "#     # Encode labels as integers\n",
    "#     le = LabelEncoder()\n",
    "#     y_encoded = le.fit_transform(y)\n",
    "\n",
    "#     # Train logistic regression models for each modality\n",
    "#     models = {}\n",
    "#     accuracies = {}\n",
    "    \n",
    "#     for modality, cols in {\n",
    "#         'text': ['probText_0', 'probText_1'],\n",
    "#         'audio': ['probAudio_0', 'probAudio_1'],\n",
    "#         'video': ['probVideo_0', 'probVideo_1']\n",
    "#     }.items():\n",
    "#         X_modality = validation_df[cols]\n",
    "#         model = LogisticRegression()\n",
    "#         model.fit(X_modality, y_encoded)\n",
    "#         models[modality] = model\n",
    "        \n",
    "#         # Evaluate accuracy on the validation subset\n",
    "#         y_pred = model.predict(X_modality)\n",
    "#         accuracies[modality] = accuracy_score(y_encoded, y_pred)\n",
    "\n",
    "#     # Normalize weights so they sum to 1\n",
    "#     total_accuracy = sum(accuracies.values())\n",
    "#     weights = {modality: acc / total_accuracy for modality, acc in accuracies.items()}\n",
    "\n",
    "#     return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf4648d-5dae-4dbd-85d3-aecdf5208e83",
   "metadata": {},
   "source": [
    "# k-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e903f253-f26f-4e17-9be3-0c4669301e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def fusion_knn_rule_with_tuning_label(df, k_range, text=\"knnLabel_label\", train_mode=\"valid\"):\n",
    "    \"\"\"\n",
    "    Apply k-Nearest Neighbors (kNN) for late fusion with hyperparameter tuning on k using 5-fold cross-validation.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas DataFrame with columns probText_0, probAudio_0, probVideo_0, probText_1, probAudio_1, probVideo_1\n",
    "    - k_range: list of int, range of k values to tune (e.g., [1, 3, 5, 7, 9])\n",
    "    - text: str, the name of the column to store the resulting labels\n",
    "    - mode_column: str, the name of the column indicating the dataset mode (e.g., 'train', 'valid')\n",
    "    - mode_value: str, the value in mode_column to use for validation (e.g., 'valid')\n",
    "\n",
    "    Returns:\n",
    "    - df: DataFrame with the new column containing the fused labels\n",
    "    - best_k: int, the best k value found during hyperparameter tuning\n",
    "    \"\"\"\n",
    "    # Filter the validation subset\n",
    "    valid_df = df[df['mode'] == train_mode]\n",
    "\n",
    "    # Extract features (probabilities) and labels\n",
    "    X = valid_df[['textLabel', 'audioLabel', 'videoLabel', 'trimodal_preds', 'text_audio_preds', 'audio_video_preds', 'text_video_preds']]\n",
    "    y = valid_df['annotation_label']  # Assuming you have a 'label' column in your DataFrame\n",
    "\n",
    "    # Initialize kNN classifier\n",
    "    knn = KNeighborsClassifier()\n",
    "\n",
    "    # Set up GridSearchCV for hyperparameter tuning\n",
    "    param_grid = {'n_neighbors': range(1, k_range)}\n",
    "    grid_search = GridSearchCV(knn, param_grid, cv=5, scoring='accuracy')  # 5-fold cross-validation\n",
    "\n",
    "    # Perform hyperparameter tuning\n",
    "    grid_search.fit(X, y)\n",
    "\n",
    "    # Get the best k value\n",
    "    best_k = grid_search.best_params_['n_neighbors']\n",
    "    print(\"Best k: \", best_k)\n",
    "\n",
    "    # Train the kNN model on the entire validation set using the best k\n",
    "    best_knn = KNeighborsClassifier(n_neighbors=best_k)\n",
    "    best_knn.fit(X, y)\n",
    "\n",
    "    # Predict labels for the entire dataset using the best kNN model\n",
    "    X_all = df[['textLabel', 'audioLabel', 'videoLabel', 'trimodal_preds', 'text_audio_preds', 'audio_video_preds', 'text_video_preds']]\n",
    "    df[text] = best_knn.predict(X_all)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c94db461-1e2f-437d-a2de-14739db4a38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best k:  7\n"
     ]
    }
   ],
   "source": [
    "fusion_df = fusion_knn_rule_with_tuning_label(fusion_df, k_range=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f4a81025-e072-486d-8cb5-d8a0d01744ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for the Whole Dataset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6623    0.6999    0.6806      1023\n",
      "         1.0     0.7254    0.6896    0.7071      1176\n",
      "\n",
      "    accuracy                         0.6944      2199\n",
      "   macro avg     0.6939    0.6948    0.6938      2199\n",
      "weighted avg     0.6961    0.6944    0.6948      2199\n",
      "\n",
      "\n",
      "Classification Report for Train Subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.5298    0.5960    0.5610       552\n",
      "         1.0     0.6637    0.6011    0.6308       732\n",
      "\n",
      "    accuracy                         0.5989      1284\n",
      "   macro avg     0.5967    0.5986    0.5959      1284\n",
      "weighted avg     0.6061    0.5989    0.6008      1284\n",
      "\n",
      "\n",
      "Classification Report for Valid Subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8316    0.8587    0.8449        92\n",
      "         1.0     0.9030    0.8832    0.8930       137\n",
      "\n",
      "    accuracy                         0.8734       229\n",
      "   macro avg     0.8673    0.8710    0.8690       229\n",
      "weighted avg     0.8743    0.8734    0.8737       229\n",
      "\n",
      "\n",
      "Classification Report for Test Subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8438    0.8127    0.8280       379\n",
      "         1.0     0.7788    0.8143    0.7962       307\n",
      "\n",
      "    accuracy                         0.8134       686\n",
      "   macro avg     0.8113    0.8135    0.8121       686\n",
      "weighted avg     0.8147    0.8134    0.8137       686\n",
      "\n"
     ]
    }
   ],
   "source": [
    "printReport(fusion_df, 'knnLabel_label')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8425d3-74ea-44de-8f24-ebce0494ff86",
   "metadata": {},
   "source": [
    "---\n",
    "# Soft Fusion (Based on class posterior probabilities)   \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97b955c-5dac-40df-b0ab-7353c1f82c42",
   "metadata": {},
   "source": [
    "# Averaging\n",
    "\n",
    "Combine the predicted probabilities by taking their arithmetic mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dca9eaeb-cc17-459b-a597-7da05680a983",
   "metadata": {},
   "outputs": [],
   "source": [
    "def averaging_fusion(df, weights=[1/7, 1/7, 1/7, 1/7, 1/7, 1/7, 1/7], text='averaging_label'):\n",
    "    # Normalize weights to ensure they sum to 1\n",
    "    weights = [w / sum(weights) for w in weights]\n",
    "\n",
    "    def avg_prob_label(row):\n",
    "        # Calculate weighted probabilities for class 0 and class 1\n",
    "        avg_prob_0 = (row['probText_0'] * weights[0] +\n",
    "                      row['probAudio_0'] * weights[1] +\n",
    "                      row['probVideo_0'] * weights[2] +\n",
    "                      row['trimodal_prob_0'] * weights[3] +\n",
    "                      row['text_audio_prob_0'] * weights[4] +\n",
    "                      row['audio_video_prob_0'] * weights[5] +\n",
    "                      row['text_video_prob_0'] * weights[6])\n",
    "        avg_prob_1 = (row['probText_1'] * weights[0] +\n",
    "                      row['probAudio_1'] * weights[1] +\n",
    "                      row['probVideo_1'] * weights[2] +\n",
    "                      row['trimodal_prob_1'] * weights[3] +\n",
    "                      row['text_audio_prob_1'] * weights[4] +\n",
    "                      row['audio_video_prob_1'] * weights[5] +\n",
    "                      row['text_video_prob_1'] * weights[6])\n",
    "        \n",
    "        # Return the final label (0 or 1) based on the higher weighted probability\n",
    "        return 0 if avg_prob_0 > avg_prob_1 else 1\n",
    "\n",
    "    # Apply the nested function to each row of the DataFrame\n",
    "    df[text] = df.apply(avg_prob_label, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6725f910-a2c2-4b06-b90a-cd518b9dc37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fusion_df = averaging_fusion(fusion_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b203352e-7599-4428-8bb8-0536a67d6027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for the Whole Dataset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8750    0.7801    0.8248      1023\n",
      "         1.0     0.8252    0.9031    0.8624      1176\n",
      "\n",
      "    accuracy                         0.8458      2199\n",
      "   macro avg     0.8501    0.8416    0.8436      2199\n",
      "weighted avg     0.8484    0.8458    0.8449      2199\n",
      "\n",
      "\n",
      "Classification Report for Train Subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9051    0.8297    0.8658       552\n",
      "         1.0     0.8792    0.9344    0.9060       732\n",
      "\n",
      "    accuracy                         0.8894      1284\n",
      "   macro avg     0.8922    0.8821    0.8859      1284\n",
      "weighted avg     0.8903    0.8894    0.8887      1284\n",
      "\n",
      "\n",
      "Classification Report for Valid Subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7831    0.7065    0.7429        92\n",
      "         1.0     0.8151    0.8686    0.8410       137\n",
      "\n",
      "    accuracy                         0.8035       229\n",
      "   macro avg     0.7991    0.7876    0.7919       229\n",
      "weighted avg     0.8022    0.8035    0.8016       229\n",
      "\n",
      "\n",
      "Classification Report for Test Subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8514    0.7256    0.7835       379\n",
      "         1.0     0.7135    0.8436    0.7731       307\n",
      "\n",
      "    accuracy                         0.7784       686\n",
      "   macro avg     0.7824    0.7846    0.7783       686\n",
      "weighted avg     0.7897    0.7784    0.7788       686\n",
      "\n"
     ]
    }
   ],
   "source": [
    "printReport(fusion_df, 'averaging_label')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e54750-d2eb-4474-9cf4-7b58ba6a6bb4",
   "metadata": {},
   "source": [
    "## Weighted Averaging\n",
    "\n",
    "### Weights calculating my maximizing the validation set accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2bfd0ecb-026b-4d1b-88cc-c66544d85054",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.preprocessing import normalize\n",
    "import numpy as np\n",
    "\n",
    "def calculate_weights_logistic(df):\n",
    "    \"\"\"\n",
    "    Calculate weights using logistic regression based on probabilities for text, audio, and video.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame containing probabilities and target labels.\n",
    "    - target_column: Name of the column containing the true labels (0 or 1).\n",
    "\n",
    "    Returns:\n",
    "    - Normalized weights for text, audio, and video.\n",
    "    \"\"\"\n",
    "\n",
    "    df = df[fusion_df['mode'] == 'valid']\n",
    "    \n",
    "    # Extract feature columns (probabilities for text, audio, video for class 1)\n",
    "    X = df[['probText_1', 'probAudio_1', 'probVideo_1', 'trimodal_prob_1', 'text_audio_prob_1', 'audio_video_prob_1', 'text_video_prob_1']].values\n",
    "    y = df['annotation_label'].values  # True labels\n",
    "\n",
    "    # Fit logistic regression model\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    # Extract coefficients and normalize to sum to 1\n",
    "    raw_weights = np.abs(model.coef_[0])  # Take absolute values of coefficients\n",
    "    normalized_weights = raw_weights / raw_weights.sum()\n",
    "\n",
    "    return normalized_weights.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "933bb960-e1dd-4018-8c32-da5257465845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5879023514442369, 0.008858806716089572, 0.04878033413320987, 0.11868072407964249, 0.10542304896309844, 0.029106497554291545, 0.10124823710943116]\n"
     ]
    }
   ],
   "source": [
    "weights_weightedAvg = calculate_weights_logistic(fusion_df)\n",
    "\n",
    "print(weights_weightedAvg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8e27a44a-608f-46a5-8217-a10bc6c76f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "fusion_df = averaging_fusion(fusion_df, weights=weights_weightedAvg, text='weightedAveraging_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a7e13f65-8c7b-40b7-ad13-d7d3b70783c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for the Whole Dataset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8649    0.9013    0.8827      1023\n",
      "         1.0     0.9109    0.8776    0.8939      1176\n",
      "\n",
      "    accuracy                         0.8886      2199\n",
      "   macro avg     0.8879    0.8894    0.8883      2199\n",
      "weighted avg     0.8895    0.8886    0.8887      2199\n",
      "\n",
      "\n",
      "Classification Report for Train Subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8898    0.9366    0.9126       552\n",
      "         1.0     0.9502    0.9126    0.9310       732\n",
      "\n",
      "    accuracy                         0.9229      1284\n",
      "   macro avg     0.9200    0.9246    0.9218      1284\n",
      "weighted avg     0.9243    0.9229    0.9231      1284\n",
      "\n",
      "\n",
      "Classification Report for Valid Subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8081    0.8696    0.8377        92\n",
      "         1.0     0.9077    0.8613    0.8839       137\n",
      "\n",
      "    accuracy                         0.8646       229\n",
      "   macro avg     0.8579    0.8654    0.8608       229\n",
      "weighted avg     0.8677    0.8646    0.8653       229\n",
      "\n",
      "\n",
      "Classification Report for Test Subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8420    0.8575    0.8497       379\n",
      "         1.0     0.8200    0.8013    0.8105       307\n",
      "\n",
      "    accuracy                         0.8324       686\n",
      "   macro avg     0.8310    0.8294    0.8301       686\n",
      "weighted avg     0.8321    0.8324    0.8322       686\n",
      "\n"
     ]
    }
   ],
   "source": [
    "printReport(fusion_df, 'weightedAveraging_label')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6626f443-ff56-4db3-90a2-ba8f8867974f",
   "metadata": {},
   "source": [
    "# Min-Max Rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e64e4c89-dea5-420b-9279-d1634d5e54d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fusion_minmax_rule(df, rule, text=\"minmax_label\"):\n",
    "    \"\"\"\n",
    "    Apply the min or max rule for late fusion to assign labels based on probabilities.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas DataFrame with columns probText_0, probAudio_0, probVideo_0, probText_1, probAudio_1, probVideo_1\n",
    "    - rule: str, \"min\" or \"max\" to specify which fusion rule to use\n",
    "    - text: str, the name of the column to store the resulting labels\n",
    "\n",
    "    Returns:\n",
    "    - df: DataFrame with the new column containing the fused labels\n",
    "    \"\"\"\n",
    "    def minmax_prob_label(row):\n",
    "        # Extract probabilities for each class\n",
    "        probs_0 = [row['probText_0'], row['probAudio_0'], row['probVideo_0'],row['trimodal_prob_0'],row['text_audio_prob_0'],row['audio_video_prob_0'],row['text_video_prob_0']]\n",
    "        probs_1 = [row['probText_1'], row['probAudio_1'], row['probVideo_1'],row['trimodal_prob_1'],row['text_audio_prob_1'],row['audio_video_prob_1'],row['text_video_prob_1']]\n",
    "\n",
    "        # Apply the selected rule\n",
    "        if rule == \"min\":\n",
    "            fused_prob_0 = min(probs_0)\n",
    "            fused_prob_1 = min(probs_1)\n",
    "        elif rule == \"max\":\n",
    "            fused_prob_0 = max(probs_0)\n",
    "            fused_prob_1 = max(probs_1)\n",
    "\n",
    "        # Return the final label (0 or 1) based on the higher fused probability\n",
    "        \n",
    "        return 0 if fused_prob_0 > fused_prob_1 else 1\n",
    "\n",
    "    # Apply the nested function to each row of the DataFrame\n",
    "    df[text] = df.apply(minmax_prob_label, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f441a462-2bba-4944-b2b4-c00691be9701",
   "metadata": {},
   "outputs": [],
   "source": [
    "fusion_df = fusion_minmax_rule(fusion_df, rule=\"max\", text=\"max_label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "34ae3677-bda4-4314-9248-26e5a8135c16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>clip_id</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>mode</th>\n",
       "      <th>annotation_label</th>\n",
       "      <th>probText_0</th>\n",
       "      <th>probText_1</th>\n",
       "      <th>textLabel</th>\n",
       "      <th>probAudio_0</th>\n",
       "      <th>probAudio_1</th>\n",
       "      <th>...</th>\n",
       "      <th>audio_video_preds</th>\n",
       "      <th>text_video_prob_0</th>\n",
       "      <th>text_video_prob_1</th>\n",
       "      <th>text_video_preds</th>\n",
       "      <th>majorityLabel</th>\n",
       "      <th>weightedVotingOnLabel_validationAccuracyWeights_Label</th>\n",
       "      <th>knnLabel_label</th>\n",
       "      <th>averaging_label</th>\n",
       "      <th>weightedAveraging_label</th>\n",
       "      <th>max_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>11</td>\n",
       "      <td>a lot of sad part</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.997359</td>\n",
       "      <td>0.002641</td>\n",
       "      <td>0</td>\n",
       "      <td>0.399598</td>\n",
       "      <td>0.600402</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.547833</td>\n",
       "      <td>0.452167</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>10</td>\n",
       "      <td>there is sad part</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.997300</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0</td>\n",
       "      <td>0.439418</td>\n",
       "      <td>0.560582</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.602740</td>\n",
       "      <td>0.397260</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>13</td>\n",
       "      <td>and it a really funny</td>\n",
       "      <td>train</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002918</td>\n",
       "      <td>0.997082</td>\n",
       "      <td>1</td>\n",
       "      <td>0.350468</td>\n",
       "      <td>0.649532</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.382594</td>\n",
       "      <td>0.617406</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>12</td>\n",
       "      <td>but it wa really really awesome</td>\n",
       "      <td>train</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002906</td>\n",
       "      <td>0.997094</td>\n",
       "      <td>1</td>\n",
       "      <td>0.347897</td>\n",
       "      <td>0.652103</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.386552</td>\n",
       "      <td>0.613448</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>1</td>\n",
       "      <td>anyhow it wa really good</td>\n",
       "      <td>train</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002872</td>\n",
       "      <td>0.997128</td>\n",
       "      <td>1</td>\n",
       "      <td>0.435212</td>\n",
       "      <td>0.564788</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.582906</td>\n",
       "      <td>0.417094</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2194</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>30</td>\n",
       "      <td>because there really wa not all that much to i...</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.997182</td>\n",
       "      <td>0.002818</td>\n",
       "      <td>0</td>\n",
       "      <td>0.597331</td>\n",
       "      <td>0.402669</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.542318</td>\n",
       "      <td>0.457682</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2195</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>35</td>\n",
       "      <td>so if you like to hear a like more positive re...</td>\n",
       "      <td>test</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.997070</td>\n",
       "      <td>1</td>\n",
       "      <td>0.399418</td>\n",
       "      <td>0.600582</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.396127</td>\n",
       "      <td>0.603873</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>34</td>\n",
       "      <td>and she really enjoyed the film</td>\n",
       "      <td>test</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002905</td>\n",
       "      <td>0.997095</td>\n",
       "      <td>1</td>\n",
       "      <td>0.341855</td>\n",
       "      <td>0.658145</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.386174</td>\n",
       "      <td>0.613826</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2197</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>33</td>\n",
       "      <td>if you do want to see somebody who is possibly...</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.996939</td>\n",
       "      <td>0.003061</td>\n",
       "      <td>0</td>\n",
       "      <td>0.406756</td>\n",
       "      <td>0.593244</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.524029</td>\n",
       "      <td>0.475971</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2198</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>32</td>\n",
       "      <td>yeah i mean if you want to see a video it goin...</td>\n",
       "      <td>test</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.003109</td>\n",
       "      <td>0.996891</td>\n",
       "      <td>1</td>\n",
       "      <td>0.462510</td>\n",
       "      <td>0.537490</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.371033</td>\n",
       "      <td>0.628967</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2199 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         video_id  clip_id                                     processed_text  \\\n",
       "0     03bSnISJMiM       11                                  a lot of sad part   \n",
       "1     03bSnISJMiM       10                                  there is sad part   \n",
       "2     03bSnISJMiM       13                              and it a really funny   \n",
       "3     03bSnISJMiM       12                    but it wa really really awesome   \n",
       "4     03bSnISJMiM        1                           anyhow it wa really good   \n",
       "...           ...      ...                                                ...   \n",
       "2194  zhpQhgha_KU       30  because there really wa not all that much to i...   \n",
       "2195  zhpQhgha_KU       35  so if you like to hear a like more positive re...   \n",
       "2196  zhpQhgha_KU       34                    and she really enjoyed the film   \n",
       "2197  zhpQhgha_KU       33  if you do want to see somebody who is possibly...   \n",
       "2198  zhpQhgha_KU       32  yeah i mean if you want to see a video it goin...   \n",
       "\n",
       "       mode  annotation_label  probText_0  probText_1  textLabel  probAudio_0  \\\n",
       "0     train               0.0    0.997359    0.002641          0     0.399598   \n",
       "1     train               0.0    0.997300    0.002700          0     0.439418   \n",
       "2     train               1.0    0.002918    0.997082          1     0.350468   \n",
       "3     train               1.0    0.002906    0.997094          1     0.347897   \n",
       "4     train               1.0    0.002872    0.997128          1     0.435212   \n",
       "...     ...               ...         ...         ...        ...          ...   \n",
       "2194   test               0.0    0.997182    0.002818          0     0.597331   \n",
       "2195   test               1.0    0.002930    0.997070          1     0.399418   \n",
       "2196   test               1.0    0.002905    0.997095          1     0.341855   \n",
       "2197   test               0.0    0.996939    0.003061          0     0.406756   \n",
       "2198   test               1.0    0.003109    0.996891          1     0.462510   \n",
       "\n",
       "      probAudio_1  ...  audio_video_preds  text_video_prob_0  \\\n",
       "0        0.600402  ...                  1           0.547833   \n",
       "1        0.560582  ...                  1           0.602740   \n",
       "2        0.649532  ...                  1           0.382594   \n",
       "3        0.652103  ...                  1           0.386552   \n",
       "4        0.564788  ...                  1           0.582906   \n",
       "...           ...  ...                ...                ...   \n",
       "2194     0.402669  ...                  0           0.542318   \n",
       "2195     0.600582  ...                  1           0.396127   \n",
       "2196     0.658145  ...                  1           0.386174   \n",
       "2197     0.593244  ...                  1           0.524029   \n",
       "2198     0.537490  ...                  1           0.371033   \n",
       "\n",
       "      text_video_prob_1  text_video_preds  majorityLabel  \\\n",
       "0              0.452167                 0              1   \n",
       "1              0.397260                 0              0   \n",
       "2              0.617406                 1              1   \n",
       "3              0.613448                 1              1   \n",
       "4              0.417094                 0              1   \n",
       "...                 ...               ...            ...   \n",
       "2194           0.457682                 0              0   \n",
       "2195           0.603873                 1              1   \n",
       "2196           0.613826                 1              1   \n",
       "2197           0.475971                 0              1   \n",
       "2198           0.628967                 1              1   \n",
       "\n",
       "      weightedVotingOnLabel_validationAccuracyWeights_Label  knnLabel_label  \\\n",
       "0                                                     0                 0.0   \n",
       "1                                                     0                 0.0   \n",
       "2                                                     1                 1.0   \n",
       "3                                                     1                 1.0   \n",
       "4                                                     0                 0.0   \n",
       "...                                                 ...                 ...   \n",
       "2194                                                  0                 0.0   \n",
       "2195                                                  1                 1.0   \n",
       "2196                                                  1                 1.0   \n",
       "2197                                                  0                 0.0   \n",
       "2198                                                  1                 1.0   \n",
       "\n",
       "      averaging_label  weightedAveraging_label  max_label  \n",
       "0                   0                        0          0  \n",
       "1                   0                        0          0  \n",
       "2                   1                        1          1  \n",
       "3                   1                        1          1  \n",
       "4                   1                        1          1  \n",
       "...               ...                      ...        ...  \n",
       "2194                0                        0          0  \n",
       "2195                1                        1          1  \n",
       "2196                1                        1          1  \n",
       "2197                0                        0          0  \n",
       "2198                1                        1          1  \n",
       "\n",
       "[2199 rows x 32 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fusion_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9f6b7d39-d41f-4177-8ea8-f6fe6ece640d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for the Whole Dataset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8648    0.9003    0.8822      1023\n",
      "         1.0     0.9101    0.8776    0.8935      1176\n",
      "\n",
      "    accuracy                         0.8881      2199\n",
      "   macro avg     0.8874    0.8889    0.8878      2199\n",
      "weighted avg     0.8890    0.8881    0.8882      2199\n",
      "\n",
      "\n",
      "Classification Report for Train Subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8897    0.9348    0.9117       552\n",
      "         1.0     0.9489    0.9126    0.9304       732\n",
      "\n",
      "    accuracy                         0.9221      1284\n",
      "   macro avg     0.9193    0.9237    0.9210      1284\n",
      "weighted avg     0.9234    0.9221    0.9223      1284\n",
      "\n",
      "\n",
      "Classification Report for Valid Subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8081    0.8696    0.8377        92\n",
      "         1.0     0.9077    0.8613    0.8839       137\n",
      "\n",
      "    accuracy                         0.8646       229\n",
      "   macro avg     0.8579    0.8654    0.8608       229\n",
      "weighted avg     0.8677    0.8646    0.8653       229\n",
      "\n",
      "\n",
      "Classification Report for Test Subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8420    0.8575    0.8497       379\n",
      "         1.0     0.8200    0.8013    0.8105       307\n",
      "\n",
      "    accuracy                         0.8324       686\n",
      "   macro avg     0.8310    0.8294    0.8301       686\n",
      "weighted avg     0.8321    0.8324    0.8322       686\n",
      "\n"
     ]
    }
   ],
   "source": [
    "printReport(fusion_df, 'max_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fbc689ee-f595-4c25-b8d4-5b47cb38119e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fusion_df = fusion_minmax_rule(fusion_df, rule=\"min\", text=\"min_label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9c02c7d4-b840-4614-a801-5f354a06528b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for the Whole Dataset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8648    0.9003    0.8822      1023\n",
      "         1.0     0.9101    0.8776    0.8935      1176\n",
      "\n",
      "    accuracy                         0.8881      2199\n",
      "   macro avg     0.8874    0.8889    0.8878      2199\n",
      "weighted avg     0.8890    0.8881    0.8882      2199\n",
      "\n",
      "\n",
      "Classification Report for Train Subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8897    0.9348    0.9117       552\n",
      "         1.0     0.9489    0.9126    0.9304       732\n",
      "\n",
      "    accuracy                         0.9221      1284\n",
      "   macro avg     0.9193    0.9237    0.9210      1284\n",
      "weighted avg     0.9234    0.9221    0.9223      1284\n",
      "\n",
      "\n",
      "Classification Report for Valid Subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8081    0.8696    0.8377        92\n",
      "         1.0     0.9077    0.8613    0.8839       137\n",
      "\n",
      "    accuracy                         0.8646       229\n",
      "   macro avg     0.8579    0.8654    0.8608       229\n",
      "weighted avg     0.8677    0.8646    0.8653       229\n",
      "\n",
      "\n",
      "Classification Report for Test Subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8420    0.8575    0.8497       379\n",
      "         1.0     0.8200    0.8013    0.8105       307\n",
      "\n",
      "    accuracy                         0.8324       686\n",
      "   macro avg     0.8310    0.8294    0.8301       686\n",
      "weighted avg     0.8321    0.8324    0.8322       686\n",
      "\n"
     ]
    }
   ],
   "source": [
    "printReport(fusion_df, 'min_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "78e4d613-16e1-4a4d-9b28-f38717a27cbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>clip_id</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>mode</th>\n",
       "      <th>annotation_label</th>\n",
       "      <th>probText_0</th>\n",
       "      <th>probText_1</th>\n",
       "      <th>textLabel</th>\n",
       "      <th>probAudio_0</th>\n",
       "      <th>probAudio_1</th>\n",
       "      <th>...</th>\n",
       "      <th>text_video_prob_0</th>\n",
       "      <th>text_video_prob_1</th>\n",
       "      <th>text_video_preds</th>\n",
       "      <th>majorityLabel</th>\n",
       "      <th>weightedVotingOnLabel_validationAccuracyWeights_Label</th>\n",
       "      <th>knnLabel_label</th>\n",
       "      <th>averaging_label</th>\n",
       "      <th>weightedAveraging_label</th>\n",
       "      <th>max_label</th>\n",
       "      <th>min_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>11</td>\n",
       "      <td>a lot of sad part</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.997359</td>\n",
       "      <td>0.002641</td>\n",
       "      <td>0</td>\n",
       "      <td>0.399598</td>\n",
       "      <td>0.600402</td>\n",
       "      <td>...</td>\n",
       "      <td>0.547833</td>\n",
       "      <td>0.452167</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>10</td>\n",
       "      <td>there is sad part</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.997300</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0</td>\n",
       "      <td>0.439418</td>\n",
       "      <td>0.560582</td>\n",
       "      <td>...</td>\n",
       "      <td>0.602740</td>\n",
       "      <td>0.397260</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>13</td>\n",
       "      <td>and it a really funny</td>\n",
       "      <td>train</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002918</td>\n",
       "      <td>0.997082</td>\n",
       "      <td>1</td>\n",
       "      <td>0.350468</td>\n",
       "      <td>0.649532</td>\n",
       "      <td>...</td>\n",
       "      <td>0.382594</td>\n",
       "      <td>0.617406</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>12</td>\n",
       "      <td>but it wa really really awesome</td>\n",
       "      <td>train</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002906</td>\n",
       "      <td>0.997094</td>\n",
       "      <td>1</td>\n",
       "      <td>0.347897</td>\n",
       "      <td>0.652103</td>\n",
       "      <td>...</td>\n",
       "      <td>0.386552</td>\n",
       "      <td>0.613448</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>1</td>\n",
       "      <td>anyhow it wa really good</td>\n",
       "      <td>train</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002872</td>\n",
       "      <td>0.997128</td>\n",
       "      <td>1</td>\n",
       "      <td>0.435212</td>\n",
       "      <td>0.564788</td>\n",
       "      <td>...</td>\n",
       "      <td>0.582906</td>\n",
       "      <td>0.417094</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2194</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>30</td>\n",
       "      <td>because there really wa not all that much to i...</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.997182</td>\n",
       "      <td>0.002818</td>\n",
       "      <td>0</td>\n",
       "      <td>0.597331</td>\n",
       "      <td>0.402669</td>\n",
       "      <td>...</td>\n",
       "      <td>0.542318</td>\n",
       "      <td>0.457682</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2195</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>35</td>\n",
       "      <td>so if you like to hear a like more positive re...</td>\n",
       "      <td>test</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.997070</td>\n",
       "      <td>1</td>\n",
       "      <td>0.399418</td>\n",
       "      <td>0.600582</td>\n",
       "      <td>...</td>\n",
       "      <td>0.396127</td>\n",
       "      <td>0.603873</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>34</td>\n",
       "      <td>and she really enjoyed the film</td>\n",
       "      <td>test</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002905</td>\n",
       "      <td>0.997095</td>\n",
       "      <td>1</td>\n",
       "      <td>0.341855</td>\n",
       "      <td>0.658145</td>\n",
       "      <td>...</td>\n",
       "      <td>0.386174</td>\n",
       "      <td>0.613826</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2197</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>33</td>\n",
       "      <td>if you do want to see somebody who is possibly...</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.996939</td>\n",
       "      <td>0.003061</td>\n",
       "      <td>0</td>\n",
       "      <td>0.406756</td>\n",
       "      <td>0.593244</td>\n",
       "      <td>...</td>\n",
       "      <td>0.524029</td>\n",
       "      <td>0.475971</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2198</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>32</td>\n",
       "      <td>yeah i mean if you want to see a video it goin...</td>\n",
       "      <td>test</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.003109</td>\n",
       "      <td>0.996891</td>\n",
       "      <td>1</td>\n",
       "      <td>0.462510</td>\n",
       "      <td>0.537490</td>\n",
       "      <td>...</td>\n",
       "      <td>0.371033</td>\n",
       "      <td>0.628967</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2199 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         video_id  clip_id                                     processed_text  \\\n",
       "0     03bSnISJMiM       11                                  a lot of sad part   \n",
       "1     03bSnISJMiM       10                                  there is sad part   \n",
       "2     03bSnISJMiM       13                              and it a really funny   \n",
       "3     03bSnISJMiM       12                    but it wa really really awesome   \n",
       "4     03bSnISJMiM        1                           anyhow it wa really good   \n",
       "...           ...      ...                                                ...   \n",
       "2194  zhpQhgha_KU       30  because there really wa not all that much to i...   \n",
       "2195  zhpQhgha_KU       35  so if you like to hear a like more positive re...   \n",
       "2196  zhpQhgha_KU       34                    and she really enjoyed the film   \n",
       "2197  zhpQhgha_KU       33  if you do want to see somebody who is possibly...   \n",
       "2198  zhpQhgha_KU       32  yeah i mean if you want to see a video it goin...   \n",
       "\n",
       "       mode  annotation_label  probText_0  probText_1  textLabel  probAudio_0  \\\n",
       "0     train               0.0    0.997359    0.002641          0     0.399598   \n",
       "1     train               0.0    0.997300    0.002700          0     0.439418   \n",
       "2     train               1.0    0.002918    0.997082          1     0.350468   \n",
       "3     train               1.0    0.002906    0.997094          1     0.347897   \n",
       "4     train               1.0    0.002872    0.997128          1     0.435212   \n",
       "...     ...               ...         ...         ...        ...          ...   \n",
       "2194   test               0.0    0.997182    0.002818          0     0.597331   \n",
       "2195   test               1.0    0.002930    0.997070          1     0.399418   \n",
       "2196   test               1.0    0.002905    0.997095          1     0.341855   \n",
       "2197   test               0.0    0.996939    0.003061          0     0.406756   \n",
       "2198   test               1.0    0.003109    0.996891          1     0.462510   \n",
       "\n",
       "      probAudio_1  ...  text_video_prob_0  text_video_prob_1  \\\n",
       "0        0.600402  ...           0.547833           0.452167   \n",
       "1        0.560582  ...           0.602740           0.397260   \n",
       "2        0.649532  ...           0.382594           0.617406   \n",
       "3        0.652103  ...           0.386552           0.613448   \n",
       "4        0.564788  ...           0.582906           0.417094   \n",
       "...           ...  ...                ...                ...   \n",
       "2194     0.402669  ...           0.542318           0.457682   \n",
       "2195     0.600582  ...           0.396127           0.603873   \n",
       "2196     0.658145  ...           0.386174           0.613826   \n",
       "2197     0.593244  ...           0.524029           0.475971   \n",
       "2198     0.537490  ...           0.371033           0.628967   \n",
       "\n",
       "      text_video_preds  majorityLabel  \\\n",
       "0                    0              1   \n",
       "1                    0              0   \n",
       "2                    1              1   \n",
       "3                    1              1   \n",
       "4                    0              1   \n",
       "...                ...            ...   \n",
       "2194                 0              0   \n",
       "2195                 1              1   \n",
       "2196                 1              1   \n",
       "2197                 0              1   \n",
       "2198                 1              1   \n",
       "\n",
       "      weightedVotingOnLabel_validationAccuracyWeights_Label  knnLabel_label  \\\n",
       "0                                                     0                 0.0   \n",
       "1                                                     0                 0.0   \n",
       "2                                                     1                 1.0   \n",
       "3                                                     1                 1.0   \n",
       "4                                                     0                 0.0   \n",
       "...                                                 ...                 ...   \n",
       "2194                                                  0                 0.0   \n",
       "2195                                                  1                 1.0   \n",
       "2196                                                  1                 1.0   \n",
       "2197                                                  0                 0.0   \n",
       "2198                                                  1                 1.0   \n",
       "\n",
       "      averaging_label  weightedAveraging_label  max_label  min_label  \n",
       "0                   0                        0          0          0  \n",
       "1                   0                        0          0          0  \n",
       "2                   1                        1          1          1  \n",
       "3                   1                        1          1          1  \n",
       "4                   1                        1          1          1  \n",
       "...               ...                      ...        ...        ...  \n",
       "2194                0                        0          0          0  \n",
       "2195                1                        1          1          1  \n",
       "2196                1                        1          1          1  \n",
       "2197                0                        0          0          0  \n",
       "2198                1                        1          1          1  \n",
       "\n",
       "[2199 rows x 33 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fusion_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83511e0-9f70-4cc8-bfe9-26f57a1e75bf",
   "metadata": {},
   "source": [
    "Min and max rules give the same results when the probability rankings across modalities are consistent.   \n",
    "-> This occurs when the relative order of the probabilities for each class (e.g., class 0 and class 1) remains the same across all modalities.   \n",
    "In such cases, the minimum and maximum probabilities for each class will still correctly identify the class with the higher overall likelihood, leading to identical final labels.\n",
    "SO  \n",
    "-> Agreement Among Modalities  \n",
    "If the probabilities from all modalities consistently favor the same class (e.g., class 0 or class 1), both the AVERAGING and MIN-MAX rules will likely produce the same final label.  \n",
    "\n",
    "For example:   \n",
    "Modalities all strongly favor class 0:   \n",
    "Text: 0.8, Audio: 0.7, Video: 0.9 → Final decision = class 0.   \n",
    "In such cases, the actual method of fusion (min, max, or average) does not matter because all modalities already agree.   \n",
    "\n",
    "When there is significant disagreement among modalities, these rules can diverge, and the choice of rule impacts the final classification.\n",
    "\n",
    "\n",
    "Balancing Effect of Averaging   \n",
    "The averaging rule aggregates probabilities, smoothing out extremes.  \n",
    "This is functionally similar to the way the min and max rules act in certain cases:  \n",
    "- The min rule emphasizes the weakest agreement across modalities.\n",
    "- The max rule focuses on the strongest agreement.\n",
    "- Averaging lies between these extremes, blending the influence of all modalities equally. If no extreme disagreement exists among modalities, the averaged probability may still reflect the dominant class.\n",
    "\n",
    "---\n",
    "\n",
    "Situations That Prevent Consistent Results (That would make Min and Max rule give different results)\n",
    "Differences between the min and max rules arise when the rankings of class probabilities are not consistent across modalities. This happens when:\n",
    "\n",
    "- One or more modalities strongly favor one class while others favor another.\n",
    "- Disagreement arises due to noisy or unreliable modalities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0410dc4-27bd-44de-b3be-7f5d9ccec296",
   "metadata": {},
   "source": [
    "# Product Rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "20c7a7b7-51f5-4cef-b111-985c54395d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def product_fusion(df, text='product_label'):\n",
    "    def prod_prob_label(row):\n",
    "        # Calculate product of probabilities for class 0 and class 1\n",
    "        prob_0 = (row['probText_0']*row['probAudio_0']*row['probVideo_0']*row['trimodal_prob_0']*row['text_audio_prob_0']*row['audio_video_prob_0']*row['text_video_prob_0'])\n",
    "        prob_1 = (row['probText_1']*row['probAudio_1']*row['probVideo_1']*row['trimodal_prob_1']*row['text_audio_prob_1']*row['audio_video_prob_1']*row['text_video_prob_1'])\n",
    "        \n",
    "        # Return the final label (0 or 1) based on the higher product probability\n",
    "        return 0 if prob_0 > prob_1 else 1\n",
    "\n",
    "    # Apply the nested function to each row of the DataFrame\n",
    "    df[text] = df.apply(prod_prob_label, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "89be3548-921f-45e4-8165-d2ba48ed3697",
   "metadata": {},
   "outputs": [],
   "source": [
    "fusion_df = product_fusion(fusion_df, text=\"product_label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "adfc8813-8826-4428-b239-1aa1042cfa28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for the Whole Dataset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8671    0.8993    0.8829      1023\n",
      "         1.0     0.9095    0.8801    0.8946      1176\n",
      "\n",
      "    accuracy                         0.8890      2199\n",
      "   macro avg     0.8883    0.8897    0.8887      2199\n",
      "weighted avg     0.8898    0.8890    0.8891      2199\n",
      "\n",
      "\n",
      "Classification Report for Train Subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8946    0.9384    0.9160       552\n",
      "         1.0     0.9518    0.9167    0.9339       732\n",
      "\n",
      "    accuracy                         0.9260      1284\n",
      "   macro avg     0.9232    0.9275    0.9249      1284\n",
      "weighted avg     0.9272    0.9260    0.9262      1284\n",
      "\n",
      "\n",
      "Classification Report for Valid Subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8081    0.8696    0.8377        92\n",
      "         1.0     0.9077    0.8613    0.8839       137\n",
      "\n",
      "    accuracy                         0.8646       229\n",
      "   macro avg     0.8579    0.8654    0.8608       229\n",
      "weighted avg     0.8677    0.8646    0.8653       229\n",
      "\n",
      "\n",
      "Classification Report for Test Subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8407    0.8496    0.8451       379\n",
      "         1.0     0.8119    0.8013    0.8066       307\n",
      "\n",
      "    accuracy                         0.8280       686\n",
      "   macro avg     0.8263    0.8255    0.8259       686\n",
      "weighted avg     0.8278    0.8280    0.8279       686\n",
      "\n"
     ]
    }
   ],
   "source": [
    "printReport(fusion_df, 'product_label')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e78113-c402-4c15-b878-5043a25c93c7",
   "metadata": {},
   "source": [
    "# k-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "089e12a6-f1f5-4135-abe7-0643deeea20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def fusion_knn_rule_with_tuning(df, k_range, text=\"knn_label\", train_mode=\"valid\"):\n",
    "    \"\"\"\n",
    "    Apply k-Nearest Neighbors (kNN) for late fusion with hyperparameter tuning on k using 5-fold cross-validation.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas DataFrame with columns probText_0, probAudio_0, probVideo_0, probText_1, probAudio_1, probVideo_1\n",
    "    - k_range: list of int, range of k values to tune (e.g., [1, 3, 5, 7, 9])\n",
    "    - text: str, the name of the column to store the resulting labels\n",
    "    - mode_column: str, the name of the column indicating the dataset mode (e.g., 'train', 'valid')\n",
    "    - mode_value: str, the value in mode_column to use for validation (e.g., 'valid')\n",
    "\n",
    "    Returns:\n",
    "    - df: DataFrame with the new column containing the fused labels\n",
    "    - best_k: int, the best k value found during hyperparameter tuning\n",
    "    \"\"\"\n",
    "    # Filter the validation subset\n",
    "    valid_df = df[df['mode'] == train_mode]\n",
    "\n",
    "    # Extract features (probabilities) and labels\n",
    "    X = valid_df[['probText_1', 'probAudio_1', 'probVideo_1', 'trimodal_prob_1', 'text_audio_prob_1', 'audio_video_prob_1', 'text_video_prob_1', \n",
    "                  'probText_0', 'probAudio_0', 'probVideo_0', 'trimodal_prob_0', 'text_audio_prob_0', 'audio_video_prob_0', 'text_video_prob_0']]\n",
    "    y = valid_df['annotation_label']  # Assuming you have a 'label' column in your DataFrame\n",
    "\n",
    "    # Initialize kNN classifier\n",
    "    knn = KNeighborsClassifier()\n",
    "\n",
    "    # Set up GridSearchCV for hyperparameter tuning\n",
    "    param_grid = {'n_neighbors': range(1, k_range)}\n",
    "    grid_search = GridSearchCV(knn, param_grid, cv=5, scoring='accuracy')  # 5-fold cross-validation\n",
    "\n",
    "    # Perform hyperparameter tuning\n",
    "    grid_search.fit(X, y)\n",
    "\n",
    "    # Get the best k value\n",
    "    best_k = grid_search.best_params_['n_neighbors']\n",
    "    print(\"Best k: \", best_k)\n",
    "\n",
    "    # Train the kNN model on the entire validation set using the best k\n",
    "    best_knn = KNeighborsClassifier(n_neighbors=best_k)\n",
    "    best_knn.fit(X, y)\n",
    "\n",
    "    # Predict labels for the entire dataset using the best kNN model\n",
    "    X_all = df[['probText_1', 'probAudio_1', 'probVideo_1', 'trimodal_prob_1', 'text_audio_prob_1', 'audio_video_prob_1', 'text_video_prob_1', \n",
    "                'probText_0', 'probAudio_0', 'probVideo_0', 'trimodal_prob_0', 'text_audio_prob_0', 'audio_video_prob_0', 'text_video_prob_0']]\n",
    "    df[text] = best_knn.predict(X_all)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fe8f3cee-9a2f-47dd-8acf-b9c396ccf1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best k:  8\n"
     ]
    }
   ],
   "source": [
    "fusion_df = fusion_knn_rule_with_tuning(fusion_df, k_range=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "825e0b88-eff1-4d17-b11c-6ccbc7e2455d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for the Whole Dataset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8647    0.8935    0.8788      1023\n",
      "         1.0     0.9046    0.8784    0.8913      1176\n",
      "\n",
      "    accuracy                         0.8854      2199\n",
      "   macro avg     0.8846    0.8859    0.8851      2199\n",
      "weighted avg     0.8860    0.8854    0.8855      2199\n",
      "\n",
      "\n",
      "Classification Report for Train Subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8904    0.9275    0.9086       552\n",
      "         1.0     0.9436    0.9139    0.9285       732\n",
      "\n",
      "    accuracy                         0.9198      1284\n",
      "   macro avg     0.9170    0.9207    0.9186      1284\n",
      "weighted avg     0.9207    0.9198    0.9200      1284\n",
      "\n",
      "\n",
      "Classification Report for Valid Subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8163    0.8696    0.8421        92\n",
      "         1.0     0.9084    0.8686    0.8881       137\n",
      "\n",
      "    accuracy                         0.8690       229\n",
      "   macro avg     0.8624    0.8691    0.8651       229\n",
      "weighted avg     0.8714    0.8690    0.8696       229\n",
      "\n",
      "\n",
      "Classification Report for Test Subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8385    0.8496    0.8440       379\n",
      "         1.0     0.8113    0.7980    0.8046       307\n",
      "\n",
      "    accuracy                         0.8265       686\n",
      "   macro avg     0.8249    0.8238    0.8243       686\n",
      "weighted avg     0.8263    0.8265    0.8264       686\n",
      "\n"
     ]
    }
   ],
   "source": [
    "printReport(fusion_df, 'knn_label')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bc4aab-366d-48eb-8238-693c9bcf68b3",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a3f58bfe-44be-4c36-a51d-4a86534725b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "def naive_bayes_fusion(df, text='naive_bayes_label'):\n",
    "    # df_train = df[df['mode'].isin(['train', 'valid'])]\n",
    "    df_train = df[df['mode'] == 'valid']\n",
    "\n",
    "    # Extract the relevant features for probabilities (e.g., probText, probAudio, probVideo for both classes)\n",
    "    feature_columns = ['probText_1', 'probAudio_1', 'probVideo_1', 'trimodal_prob_1', 'text_audio_prob_1', 'audio_video_prob_1', 'text_video_prob_1', \n",
    "                'probText_0', 'probAudio_0', 'probVideo_0', 'trimodal_prob_0', 'text_audio_prob_0', 'audio_video_prob_0', 'text_video_prob_0']\n",
    "\n",
    "    # Prepare the feature matrix (X) and pseudo-labels (y) for training the Naive Bayes model\n",
    "    # We'll assume equal prior probabilities for simplicity.\n",
    "    X = df_train[feature_columns].values\n",
    "    y = df_train['annotation_label']\n",
    "\n",
    "    # Train a Gaussian Naive Bayes model\n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(X, y)\n",
    "\n",
    "    def predict_label(row):\n",
    "        # Prepare row features for prediction\n",
    "        row_features = row[feature_columns].values.reshape(1, -1)\n",
    "        \n",
    "        # Predict the label using Naive Bayes\n",
    "        return gnb.predict(row_features)[0]\n",
    "\n",
    "    # Apply the prediction function to each row of the DataFrame\n",
    "    df[text] = df.apply(predict_label, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d26f240d-3573-4c69-a460-ce70853f7197",
   "metadata": {},
   "outputs": [],
   "source": [
    "fusion_df = naive_bayes_fusion(fusion_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9f5db207-662e-4ecd-97dd-062223c4e30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for the Whole Dataset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7659    0.6139    0.6815      1023\n",
      "         1.0     0.7136    0.8367    0.7703      1176\n",
      "\n",
      "    accuracy                         0.7331      2199\n",
      "   macro avg     0.7397    0.7253    0.7259      2199\n",
      "weighted avg     0.7379    0.7331    0.7290      2199\n",
      "\n",
      "\n",
      "Classification Report for Train Subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6677    0.4076    0.5062       552\n",
      "         1.0     0.6547    0.8470    0.7385       732\n",
      "\n",
      "    accuracy                         0.6581      1284\n",
      "   macro avg     0.6612    0.6273    0.6224      1284\n",
      "weighted avg     0.6603    0.6581    0.6386      1284\n",
      "\n",
      "\n",
      "Classification Report for Valid Subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8081    0.8696    0.8377        92\n",
      "         1.0     0.9077    0.8613    0.8839       137\n",
      "\n",
      "    accuracy                         0.8646       229\n",
      "   macro avg     0.8579    0.8654    0.8608       229\n",
      "weighted avg     0.8677    0.8646    0.8653       229\n",
      "\n",
      "\n",
      "Classification Report for Test Subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8411    0.8522    0.8467       379\n",
      "         1.0     0.8146    0.8013    0.8079       307\n",
      "\n",
      "    accuracy                         0.8294       686\n",
      "   macro avg     0.8279    0.8268    0.8273       686\n",
      "weighted avg     0.8293    0.8294    0.8293       686\n",
      "\n"
     ]
    }
   ],
   "source": [
    "printReport(fusion_df, 'naive_bayes_label')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355e1e94-23ce-4ba4-b048-4f2f917126e1",
   "metadata": {},
   "source": [
    "# Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bdcb2f-734d-4c35-9efe-222560b3027c",
   "metadata": {},
   "source": [
    "## Find oiptimal number of estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "7d2970b4-c930-430d-a68a-a22b66efddde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Prepare the features (model probabilities) and the true labels\n",
    "# X = fusion_df[['probText_0', 'probText_1', \n",
    "#                'probAudio_0', 'probAudio_1',\n",
    "#                'probVideo_0', 'probVideo_1',\n",
    "#               ]]\n",
    "# y = fusion_df['annotation_label']\n",
    "\n",
    "# # Filter out the validation data\n",
    "# valid_data = fusion_df[fusion_df['mode'] == 'valid']\n",
    "# X_valid = valid_data[['probText_0', 'probText_1', \n",
    "#                        'probAudio_0', 'probAudio_1',\n",
    "#                        'probVideo_0', 'probVideo_1',\n",
    "#                       ]]\n",
    "# y_valid = valid_data['annotation_label']\n",
    "\n",
    "# # Initialize variables to store results\n",
    "# best_n_estimators = 0\n",
    "# best_accuracy = 0\n",
    "\n",
    "# # Loop over a range of n_estimators (e.g., from 10 to 200)\n",
    "# for n_estimators in range(1, 201):\n",
    "#     # Create the base model (Decision Tree) for Bagging\n",
    "#     base_model = DecisionTreeClassifier()\n",
    "    \n",
    "#     # Instantiate the BaggingClassifier with the current n_estimators\n",
    "#     bagging_model = BaggingClassifier(estimator=base_model, \n",
    "#                                       n_estimators=n_estimators, \n",
    "#                                       random_state=42)\n",
    "    \n",
    "#     # Train the model on the entire training set\n",
    "#     train_data = fusion_df[fusion_df['mode'] == 'train']\n",
    "#     X_train = train_data[['probText_0', 'probText_1', \n",
    "#                            'probAudio_0', 'probAudio_1',\n",
    "#                            'probVideo_0', 'probVideo_1',\n",
    "#                           ]]\n",
    "#     y_train = train_data['annotation_label']\n",
    "    \n",
    "#     bagging_model.fit(X_train, y_train)\n",
    "    \n",
    "#     # Predict on the validation set\n",
    "#     y_pred_valid = bagging_model.predict(X_valid)\n",
    "    \n",
    "#     # Calculate the accuracy on the validation set\n",
    "#     accuracy = accuracy_score(y_valid, y_pred_valid)\n",
    "    \n",
    "#     # If the current model has a better accuracy, update the best parameters\n",
    "#     if accuracy > best_accuracy:\n",
    "#         best_accuracy = accuracy\n",
    "#         best_n_estimators = n_estimators\n",
    "\n",
    "# # Output the best number of estimators and the corresponding accuracy\n",
    "# print(f\"The best number of estimators is: {best_n_estimators}\")\n",
    "# print(f\"The corresponding validation set accuracy is: {best_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191b3616-7ebc-4ca4-a7b0-86e4274a1bd1",
   "metadata": {},
   "source": [
    "## Calculate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "5e1dd371-b783-4466-88f2-30d4f1258ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Prepare the features (model probabilities) and the true labels\n",
    "# X = fusion_df[['probText_0', 'probText_1', \n",
    "#                'probAudio_0', 'probAudio_1',\n",
    "#                'probVideo_0', 'probVideo_1',\n",
    "#               ]]\n",
    "# y = fusion_df['annotation_label']\n",
    "\n",
    "# # Create the base model (Decision Tree) for Bagging\n",
    "# base_model = DecisionTreeClassifier()\n",
    "\n",
    "# # Instantiate BaggingClassifier with Decision Tree as base model\n",
    "# bagging_model = BaggingClassifier(estimator=base_model, \n",
    "#                                   n_estimators=best_n_estimators, \n",
    "#                                   random_state=42)\n",
    "\n",
    "# # Train the model on the training set\n",
    "# train_data = fusion_df[fusion_df['mode'] == 'train']\n",
    "# X_train = train_data[['probText_0', 'probText_1', \n",
    "#                        'probAudio_0', 'probAudio_1',\n",
    "#                        'probVideo_0', 'probVideo_1',\n",
    "#                       ]]\n",
    "# y_train = train_data['annotation_label']\n",
    "\n",
    "# bagging_model.fit(X_train, y_train)\n",
    "\n",
    "# # Predict on the whole dataset\n",
    "# y_pred = bagging_model.predict(X)\n",
    "\n",
    "# # Classification report for the entire dataset\n",
    "# print(\"Classification Report on the Entire Dataset:\")\n",
    "# print(classification_report(y, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "2ed6fe4d-ca0b-4e10-9c42-1fba8a10465c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for mode in ['train', 'valid', 'test']:\n",
    "#     subset_data = fusion_df[fusion_df['mode'] == mode]\n",
    "#     X_subset = subset_data[['probText_0', 'probText_1', \n",
    "#                             'probAudio_0', 'probAudio_1',\n",
    "#                             'probVideo_0', 'probVideo_1',\n",
    "#                            ]]\n",
    "#     y_subset = subset_data['annotation_label']\n",
    "    \n",
    "#     # Get predictions\n",
    "#     y_pred = bagging_model.predict(X_subset)\n",
    "    \n",
    "#     # Print classification report\n",
    "#     print(f\"\\nClassification Report on the {mode.capitalize()} Subset:\")\n",
    "#     print(classification_report(y_subset, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcf23b8-6d39-4fda-be02-9fab00d6ef12",
   "metadata": {},
   "source": [
    "# Fully Connected Layer\n",
    "\n",
    "https://scikit-learn.org/dev/modules/generated/sklearn.neural_network.MLPClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "daef1160-c0f8-4c38-ba61-34b42a4fa8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def train_mlp_using_labels(df, train_mode='train'):\n",
    "    \"\"\"\n",
    "    Train an MLP classifier using labels as features on the 'train' subset, \n",
    "    perform grid search to maximize accuracy on the 'valid' subset, and \n",
    "    predict final labels for all rows.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame with columns:\n",
    "            'textLabel', 'audioLabel', 'videoLabel', 'annotation_label', 'mode'.\n",
    "        train_mode (str): The mode to filter the training subset (default: 'train').\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with an additional column 'mlp_label' containing the predicted labels.\n",
    "    \"\"\"\n",
    "    # Filter the training and validation subsets\n",
    "    train_df = df[df['mode'] == train_mode]\n",
    "    # train_df = df[df['mode'].isin(['train', 'valid'])]\n",
    "    # valid_df = df[df['mode'] == valid_mode]\n",
    "\n",
    "    # Features (labels from text, audio, and video)\n",
    "    X_train = train_df[['textLabel', 'audioLabel', 'videoLabel', 'trimodal_preds', 'text_audio_preds', 'audio_video_preds', 'text_video_preds']]\n",
    "    y_train = train_df['annotation_label']\n",
    "    # X_valid = valid_df[['textLabel', 'audioLabel', 'videoLabel']]\n",
    "    # y_valid = valid_df['annotation_label']\n",
    "\n",
    "    # Define hyperparameter grid for grid search\n",
    "    param_grid = {\n",
    "        'hidden_layer_sizes': [(64,32), (32,16), (32,), (64,), (128,), (256,), (128, 64), (128, 32), (256, 128), (256, 32), (128, 64, 32), (256, 128, 64), (256, 128, 32), (256, 128, 64, 32), ],\n",
    "        'activation': ['relu', 'tanh'],\n",
    "        'learning_rate_init': [1e-5, 5e-5, 1e-4, 5e-4, 1e-3],\n",
    "        'batch_size': [8, 16, 32, 64, 128],\n",
    "        'max_iter': [500]\n",
    "    }\n",
    "\n",
    "    # Initialize the MLPClassifier\n",
    "    mlp = MLPClassifier(early_stopping=True, tol=1e-5)\n",
    "\n",
    "    # Perform grid search with accuracy as the scoring metric\n",
    "    grid_search = GridSearchCV(estimator=mlp, param_grid=param_grid, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Select the best estimator based on grid search\n",
    "    best_mlp = grid_search.best_estimator_\n",
    "    print(\"Best params: \", grid_search.best_params_)\n",
    "    print(\"Num of iterations: \", best_mlp.n_iter_)\n",
    "\n",
    "    # # Evaluate the best model on the validation subset\n",
    "    # valid_predictions = best_mlp.predict(X_valid)\n",
    "    \n",
    "    # valid_accuracy = accuracy_score(y_valid, valid_predictions)\n",
    "    # print(f\"Validation Accuracy of Best Model: {valid_accuracy:.4f}\")\n",
    "\n",
    "    # Use the trained best MLP model to predict for the entire dataset\n",
    "    all_features = df[['textLabel', 'audioLabel', 'videoLabel', 'trimodal_preds', 'text_audio_preds', 'audio_video_preds', 'text_video_preds']]\n",
    "    df['mlp_label'] = best_mlp.predict(all_features)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc4f7424-c570-4077-ba73-fdd0fd04688c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/my_enviroment/lib64/python3.9/site-packages/sklearn/model_selection/_search.py:412: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.array(param_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:  {'activation': 'relu', 'batch_size': 16, 'hidden_layer_sizes': (32, 16), 'learning_rate_init': 0.0005, 'max_iter': 500}\n",
      "Num of iterations:  14\n"
     ]
    }
   ],
   "source": [
    "fusion_df = train_mlp_using_labels(fusion_df, train_mode='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1092fec4-dca8-45a4-8c73-b8df828e00b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for the Whole Dataset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8714    0.8876    0.8794      1023\n",
      "         1.0     0.9006    0.8861    0.8933      1176\n",
      "\n",
      "    accuracy                         0.8868      2199\n",
      "   macro avg     0.8860    0.8868    0.8863      2199\n",
      "weighted avg     0.8870    0.8868    0.8868      2199\n",
      "\n",
      "\n",
      "Classification Report for Train Subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8914    0.9221    0.9065       552\n",
      "         1.0     0.9397    0.9153    0.9273       732\n",
      "\n",
      "    accuracy                         0.9182      1284\n",
      "   macro avg     0.9156    0.9187    0.9169      1284\n",
      "weighted avg     0.9189    0.9182    0.9184      1284\n",
      "\n",
      "\n",
      "Classification Report for Valid Subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8144    0.8587    0.8360        92\n",
      "         1.0     0.9015    0.8686    0.8848       137\n",
      "\n",
      "    accuracy                         0.8646       229\n",
      "   macro avg     0.8580    0.8637    0.8604       229\n",
      "weighted avg     0.8665    0.8646    0.8652       229\n",
      "\n",
      "\n",
      "Classification Report for Test Subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8556    0.8443    0.8499       379\n",
      "         1.0     0.8109    0.8241    0.8174       307\n",
      "\n",
      "    accuracy                         0.8353       686\n",
      "   macro avg     0.8333    0.8342    0.8337       686\n",
      "weighted avg     0.8356    0.8353    0.8354       686\n",
      "\n"
     ]
    }
   ],
   "source": [
    "printReport(fusion_df, 'mlp_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ae2b3ac-a58e-4939-b390-c76bdc892a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.neural_network import MLPClassifier\n",
    "# import pandas as pd\n",
    "\n",
    "# def train_mlp_using_probabilities(df, mode='valid'):\n",
    "#     \"\"\"\n",
    "#     Train an MLP classifier using probabilities as features from 'text', 'audio', and 'video'\n",
    "#     on the 'valid' subset and predict the final labels for all rows.\n",
    "\n",
    "#     Args:\n",
    "#         df (pd.DataFrame): Input DataFrame with columns:\n",
    "#             'probText_0', 'probText_1', 'probAudio_0', 'probAudio_1',\n",
    "#             'probVideo_0', 'probVideo_1', 'annotation_label', 'mode'.\n",
    "#         mode (str): The mode to filter the validation subset (default: 'valid').\n",
    "\n",
    "#     Returns:\n",
    "#         pd.DataFrame: DataFrame with an additional column 'mlp_label' containing the predicted labels.\n",
    "#     \"\"\"\n",
    "#     # Filter the validation subset\n",
    "#     valid_df = df[df['mode'] == mode]\n",
    "    \n",
    "#     # Features (probabilities from text, audio, and video)\n",
    "#     X = valid_df[['probText_0', 'probText_1', 'probAudio_0', 'probAudio_1', 'probVideo_0', 'probVideo_1']]\n",
    "    \n",
    "#     # Target (ground truth labels)\n",
    "#     y = valid_df['annotation_label']\n",
    "    \n",
    "#     # Train the MLP classifier\n",
    "#     mlp = MLPClassifier(hidden_layer_sizes=(64, ), max_iter=1000000000)\n",
    "#     mlp.fit(X, y)\n",
    "    \n",
    "#     # Use the trained MLP model to predict for the entire dataset\n",
    "#     all_features = df[['probText_0', 'probText_1', 'probAudio_0', 'probAudio_1', 'probVideo_0', 'probVideo_1']]\n",
    "#     df['mlpProb_label'] = mlp.predict(all_features).astype('int')\n",
    "    \n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34a00cb3-ccfb-4fed-b07f-8e9451d3cb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def train_mlp_using_probabilities(df, train_mode='train'):\n",
    "    \"\"\"\n",
    "    Train an MLP classifier using probabiliy scores as features on the 'train' subset, \n",
    "    perform grid search to maximize accuracy on the 'valid' subset, and \n",
    "    predict final labels for all rows.\n",
    "    \"\"\"\n",
    "    # Filter the training and validation subsets\n",
    "    train_df = df[df['mode'] == train_mode]\n",
    "    # train_df = df[df['mode'].isin(['train', 'valid'])]\n",
    "    # valid_df = df[df['mode'] == valid_mode]\n",
    "\n",
    "    # Features (labels from text, audio, and video)\n",
    "    X_train = train_df[['probText_1', 'probAudio_1', 'probVideo_1', 'trimodal_prob_1', 'text_audio_prob_1', 'audio_video_prob_1', 'text_video_prob_1', \n",
    "                'probText_0', 'probAudio_0', 'probVideo_0', 'trimodal_prob_0', 'text_audio_prob_0', 'audio_video_prob_0', 'text_video_prob_0']]\n",
    "    y_train = train_df['annotation_label']\n",
    "    # X_valid = valid_df[['probText_0', 'probText_1', 'probAudio_0', 'probAudio_1', 'probVideo_0', 'probVideo_1']]\n",
    "    # y_valid = valid_df['annotation_label']\n",
    "\n",
    "    # Define hyperparameter grid for grid search\n",
    "    param_grid = {\n",
    "        'hidden_layer_sizes': [(64,32), (32,16), (32,), (64,), (128,), (256,), (128, 64), (128, 32), (256, 128), (256, 32), (128, 64, 32), (256, 128, 64), (256, 128, 32), (256, 128, 64, 32), ],\n",
    "        'activation': ['relu', 'tanh'],\n",
    "        'learning_rate_init': [1e-5, 5e-5, 1e-4, 5e-4, 1e-3],\n",
    "        'batch_size': [8, 16, 32, 64, 128],\n",
    "        'max_iter': [500]\n",
    "    }\n",
    "\n",
    "    # Initialize the MLPClassifier\n",
    "    mlp = MLPClassifier(early_stopping=True, tol=1e-5)\n",
    "\n",
    "    # Perform grid search with accuracy as the scoring metric\n",
    "    grid_search = GridSearchCV(estimator=mlp, param_grid=param_grid, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Select the best estimator based on grid search\n",
    "    best_mlp = grid_search.best_estimator_\n",
    "    print(\"Best params: \", grid_search.best_params_)\n",
    "    print(\"Num of iterations: \", best_mlp.n_iter_)\n",
    "\n",
    "    # # Evaluate the best model on the validation subset\n",
    "    # valid_predictions = best_mlp.predict(X_valid)\n",
    "    \n",
    "    # valid_accuracy = accuracy_score(y_valid, valid_predictions)\n",
    "    # print(f\"Validation Accuracy of Best Model: {valid_accuracy:.4f}\")\n",
    "\n",
    "    # Use the trained best MLP model to predict for the entire dataset\n",
    "    all_features = df[['probText_1', 'probAudio_1', 'probVideo_1', 'trimodal_prob_1', 'text_audio_prob_1', 'audio_video_prob_1', 'text_video_prob_1', \n",
    "                'probText_0', 'probAudio_0', 'probVideo_0', 'trimodal_prob_0', 'text_audio_prob_0', 'audio_video_prob_0', 'text_video_prob_0']]\n",
    "    df['mlpProb_label'] = best_mlp.predict(all_features)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "192974a9-dd49-4fbd-b251-12de8f860f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/my_enviroment/lib64/python3.9/site-packages/sklearn/model_selection/_search.py:412: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.array(param_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:  {'activation': 'relu', 'batch_size': 64, 'hidden_layer_sizes': (256, 128, 64), 'learning_rate_init': 0.001, 'max_iter': 500}\n",
      "Num of iterations:  15\n"
     ]
    }
   ],
   "source": [
    "fusion_df = train_mlp_using_probabilities(fusion_df, train_mode='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ff7ef1a-d3cc-41c1-8447-a31aa76b4ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for the Whole Dataset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8632    0.9130    0.8874      1023\n",
      "         1.0     0.9203    0.8741    0.8966      1176\n",
      "\n",
      "    accuracy                         0.8922      2199\n",
      "   macro avg     0.8918    0.8936    0.8920      2199\n",
      "weighted avg     0.8938    0.8922    0.8923      2199\n",
      "\n",
      "\n",
      "Classification Report for Train Subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8861    0.9583    0.9208       552\n",
      "         1.0     0.9665    0.9071    0.9359       732\n",
      "\n",
      "    accuracy                         0.9291      1284\n",
      "   macro avg     0.9263    0.9327    0.9283      1284\n",
      "weighted avg     0.9319    0.9291    0.9294      1284\n",
      "\n",
      "\n",
      "Classification Report for Valid Subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8081    0.8696    0.8377        92\n",
      "         1.0     0.9077    0.8613    0.8839       137\n",
      "\n",
      "    accuracy                         0.8646       229\n",
      "   macro avg     0.8579    0.8654    0.8608       229\n",
      "weighted avg     0.8677    0.8646    0.8653       229\n",
      "\n",
      "\n",
      "Classification Report for Test Subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8420    0.8575    0.8497       379\n",
      "         1.0     0.8200    0.8013    0.8105       307\n",
      "\n",
      "    accuracy                         0.8324       686\n",
      "   macro avg     0.8310    0.8294    0.8301       686\n",
      "weighted avg     0.8321    0.8324    0.8322       686\n",
      "\n"
     ]
    }
   ],
   "source": [
    "printReport(fusion_df, 'mlpProb_label')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd819f12-7a2c-4c96-9885-29615316a60d",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "3f7193d3-6321-47b6-9882-caba2a107c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from torch.utils.data import DataLoader, TensorDataset\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# class MultiHeadAttentionClassifier(nn.Module):\n",
    "#     def __init__(self, input_dim, num_heads=7, hidden_dim=64, output_dim=2):\n",
    "#         super(MultiHeadAttentionClassifier, self).__init__()\n",
    "#         self.attention = nn.MultiheadAttention(embed_dim=input_dim, num_heads=num_heads, batch_first=True)\n",
    "#         self.fc = nn.Sequential(\n",
    "#             nn.Linear(input_dim, hidden_dim),\n",
    "#             nn.Tanh(),\n",
    "#             nn.Linear(hidden_dim, hidden_dim),\n",
    "#             nn.Tanh(),\n",
    "#             nn.Linear(hidden_dim, output_dim)\n",
    "#         )\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         attn_output, _ = self.attention(x, x, x)\n",
    "#         out = self.fc(attn_output[:, 0, :])  # Take first token output\n",
    "#         return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "a0de2d53-51e0-419f-95f5-8744f159c6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_multihead_attention(df, epochs=3, batch_size=64, lr=0.0001, text='mha_label'):\n",
    "#     features = df[['probText_0', 'probAudio_0', 'probVideo_0', 'trimodal_prob_0',\n",
    "#                    'text_audio_prob_0', 'audio_video_prob_0', 'text_video_prob_0',\n",
    "#                    'probText_1', 'probAudio_1', 'probVideo_1', 'trimodal_prob_1',\n",
    "#                    'text_audio_prob_1', 'audio_video_prob_1', 'text_video_prob_1']].values\n",
    "#     labels = df['annotation_label'].values\n",
    "    \n",
    "#     # Normalize the features\n",
    "#     scaler = StandardScaler()\n",
    "#     features = scaler.fit_transform(features)\n",
    "    \n",
    "#     # Convert to tensors\n",
    "#     X = torch.tensor(features, dtype=torch.float32)\n",
    "#     y = torch.tensor(labels, dtype=torch.long)\n",
    "    \n",
    "#     data_loaders = {}\n",
    "#     for mode in ['train', 'valid', 'test']:\n",
    "#         mask = df['mode'] == mode\n",
    "#         if mask.sum() > 0:  # Ensure mode has data\n",
    "#             X_subset = X[mask].unsqueeze(1)  # Ensure correct dimensions\n",
    "#             if mode != 'test':\n",
    "#                 y_subset = y[mask]\n",
    "#                 dataset = TensorDataset(X_subset, y_subset)\n",
    "#             else:\n",
    "#                 dataset = TensorDataset(X_subset)  # No labels for test mode\n",
    "#             shuffle = mode == 'train'\n",
    "#             data_loaders[mode] = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "    \n",
    "#     model = MultiHeadAttentionClassifier(input_dim=14)  # 14 input probabilities\n",
    "#     criterion = nn.CrossEntropyLoss()\n",
    "#     optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-4)\n",
    "    \n",
    "#     # Training loop\n",
    "#     for epoch in range(epochs):\n",
    "#         model.train()\n",
    "#         for inputs, targets in data_loaders['train']:\n",
    "#             optimizer.zero_grad()\n",
    "#             outputs = model(inputs)\n",
    "#             loss = criterion(outputs, targets)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "    \n",
    "#     # Evaluation for all modes\n",
    "#     model.eval()\n",
    "#     for mode in ['train', 'valid', 'test']:\n",
    "#         if mode in data_loaders:\n",
    "#             predictions = []\n",
    "#             with torch.no_grad():\n",
    "#                 for batch in data_loaders[mode]:\n",
    "#                     inputs = batch[0]\n",
    "#                     outputs = model(inputs)\n",
    "#                     preds = torch.argmax(outputs, dim=1)\n",
    "#                     predictions.extend(preds.numpy())\n",
    "#             df.loc[df['mode'] == mode, text] = predictions  # Assign predictions back to df\n",
    "    \n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "4d3c23b7-95f3-4547-90cd-8265ad19e459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_df = train_multihead_attention(fusion_df, epochs=30, batch_size=128, lr=0.0005, text='mha_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "8c0e308e-2a54-4509-83ad-eeaf8e31f65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "cf07a553-5b8a-4e28-87ae-5dcc01e27ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# printReport(temp_df, 'mha_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7df955-fe98-44e2-b17a-ee14d5ba27de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ceaaf0c-1586-41bf-b935-ed10ceb6f0f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My Enviroment",
   "language": "python",
   "name": "my_enviroment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
