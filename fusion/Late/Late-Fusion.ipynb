{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "beb63af7-d4dc-4a61-8439-adcffd893638",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from collections import Counter\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a9216a-1b0e-4476-89b4-75b194d8149f",
   "metadata": {},
   "source": [
    "The extensive experiments using different\n",
    "classifiers and combinations of different vision and text features\n",
    "on multiple sentiment scenarios showed that late fusion is more\n",
    "effective than early fusion. The analysis of explainability revealed\n",
    "that in late fusion, the classes were predominantly influenced by\n",
    "the respective uni-modal prediction probabilities, indicating the necessity for extracting more appropriate features through additional\n",
    "fine-tuning procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ce99f41-cef1-484d-8723-baa0fa228023",
   "metadata": {},
   "outputs": [],
   "source": [
    "fusion_df = pd.read_csv(\"outputs_perModel.csv\", \n",
    "                         encoding='utf-8', \n",
    "                         header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a23fd46-a400-42a1-b077-7b91985ef938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>clip_id</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>mode</th>\n",
       "      <th>annotation_label</th>\n",
       "      <th>probText_0</th>\n",
       "      <th>probText_1</th>\n",
       "      <th>textLabel</th>\n",
       "      <th>probAudio_0</th>\n",
       "      <th>probAudio_1</th>\n",
       "      <th>audioLabel</th>\n",
       "      <th>probVideo_0</th>\n",
       "      <th>probVideo_1</th>\n",
       "      <th>videoLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>11</td>\n",
       "      <td>a lot of sad part</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.997359</td>\n",
       "      <td>0.002641</td>\n",
       "      <td>0</td>\n",
       "      <td>0.399598</td>\n",
       "      <td>0.600402</td>\n",
       "      <td>1</td>\n",
       "      <td>0.495560</td>\n",
       "      <td>0.504440</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>10</td>\n",
       "      <td>there is sad part</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.997300</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0</td>\n",
       "      <td>0.439418</td>\n",
       "      <td>0.560582</td>\n",
       "      <td>1</td>\n",
       "      <td>0.493912</td>\n",
       "      <td>0.506088</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>13</td>\n",
       "      <td>and it a really funny</td>\n",
       "      <td>train</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002918</td>\n",
       "      <td>0.997082</td>\n",
       "      <td>1</td>\n",
       "      <td>0.350468</td>\n",
       "      <td>0.649532</td>\n",
       "      <td>1</td>\n",
       "      <td>0.450571</td>\n",
       "      <td>0.549429</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>12</td>\n",
       "      <td>but it wa really really awesome</td>\n",
       "      <td>train</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002906</td>\n",
       "      <td>0.997094</td>\n",
       "      <td>1</td>\n",
       "      <td>0.347897</td>\n",
       "      <td>0.652103</td>\n",
       "      <td>1</td>\n",
       "      <td>0.402363</td>\n",
       "      <td>0.597637</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>1</td>\n",
       "      <td>anyhow it wa really good</td>\n",
       "      <td>train</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002872</td>\n",
       "      <td>0.997128</td>\n",
       "      <td>1</td>\n",
       "      <td>0.435212</td>\n",
       "      <td>0.564788</td>\n",
       "      <td>1</td>\n",
       "      <td>0.317268</td>\n",
       "      <td>0.682732</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2194</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>30</td>\n",
       "      <td>because there really wa not all that much to i...</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.997182</td>\n",
       "      <td>0.002818</td>\n",
       "      <td>0</td>\n",
       "      <td>0.597331</td>\n",
       "      <td>0.402669</td>\n",
       "      <td>0</td>\n",
       "      <td>0.445997</td>\n",
       "      <td>0.554003</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2195</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>35</td>\n",
       "      <td>so if you like to hear a like more positive re...</td>\n",
       "      <td>test</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.997070</td>\n",
       "      <td>1</td>\n",
       "      <td>0.399418</td>\n",
       "      <td>0.600582</td>\n",
       "      <td>1</td>\n",
       "      <td>0.545271</td>\n",
       "      <td>0.454729</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>34</td>\n",
       "      <td>and she really enjoyed the film</td>\n",
       "      <td>test</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002905</td>\n",
       "      <td>0.997095</td>\n",
       "      <td>1</td>\n",
       "      <td>0.341855</td>\n",
       "      <td>0.658145</td>\n",
       "      <td>1</td>\n",
       "      <td>0.461881</td>\n",
       "      <td>0.538119</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2197</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>33</td>\n",
       "      <td>if you do want to see somebody who is possibly...</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.996939</td>\n",
       "      <td>0.003061</td>\n",
       "      <td>0</td>\n",
       "      <td>0.406756</td>\n",
       "      <td>0.593244</td>\n",
       "      <td>1</td>\n",
       "      <td>0.504509</td>\n",
       "      <td>0.495491</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2198</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>32</td>\n",
       "      <td>yeah i mean if you want to see a video it goin...</td>\n",
       "      <td>test</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.003109</td>\n",
       "      <td>0.996891</td>\n",
       "      <td>1</td>\n",
       "      <td>0.462510</td>\n",
       "      <td>0.537490</td>\n",
       "      <td>1</td>\n",
       "      <td>0.464074</td>\n",
       "      <td>0.535926</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2199 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         video_id  clip_id                                     processed_text  \\\n",
       "0     03bSnISJMiM       11                                  a lot of sad part   \n",
       "1     03bSnISJMiM       10                                  there is sad part   \n",
       "2     03bSnISJMiM       13                              and it a really funny   \n",
       "3     03bSnISJMiM       12                    but it wa really really awesome   \n",
       "4     03bSnISJMiM        1                           anyhow it wa really good   \n",
       "...           ...      ...                                                ...   \n",
       "2194  zhpQhgha_KU       30  because there really wa not all that much to i...   \n",
       "2195  zhpQhgha_KU       35  so if you like to hear a like more positive re...   \n",
       "2196  zhpQhgha_KU       34                    and she really enjoyed the film   \n",
       "2197  zhpQhgha_KU       33  if you do want to see somebody who is possibly...   \n",
       "2198  zhpQhgha_KU       32  yeah i mean if you want to see a video it goin...   \n",
       "\n",
       "       mode  annotation_label  probText_0  probText_1  textLabel  probAudio_0  \\\n",
       "0     train               0.0    0.997359    0.002641          0     0.399598   \n",
       "1     train               0.0    0.997300    0.002700          0     0.439418   \n",
       "2     train               1.0    0.002918    0.997082          1     0.350468   \n",
       "3     train               1.0    0.002906    0.997094          1     0.347897   \n",
       "4     train               1.0    0.002872    0.997128          1     0.435212   \n",
       "...     ...               ...         ...         ...        ...          ...   \n",
       "2194   test               0.0    0.997182    0.002818          0     0.597331   \n",
       "2195   test               1.0    0.002930    0.997070          1     0.399418   \n",
       "2196   test               1.0    0.002905    0.997095          1     0.341855   \n",
       "2197   test               0.0    0.996939    0.003061          0     0.406756   \n",
       "2198   test               1.0    0.003109    0.996891          1     0.462510   \n",
       "\n",
       "      probAudio_1  audioLabel  probVideo_0  probVideo_1  videoLabel  \n",
       "0        0.600402           1     0.495560     0.504440           1  \n",
       "1        0.560582           1     0.493912     0.506088           1  \n",
       "2        0.649532           1     0.450571     0.549429           1  \n",
       "3        0.652103           1     0.402363     0.597637           1  \n",
       "4        0.564788           1     0.317268     0.682732           1  \n",
       "...           ...         ...          ...          ...         ...  \n",
       "2194     0.402669           0     0.445997     0.554003           1  \n",
       "2195     0.600582           1     0.545271     0.454729           0  \n",
       "2196     0.658145           1     0.461881     0.538119           1  \n",
       "2197     0.593244           1     0.504509     0.495491           0  \n",
       "2198     0.537490           1     0.464074     0.535926           1  \n",
       "\n",
       "[2199 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fusion_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d57dc88-58b6-4a01-ba46-68be9ae9484b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printReport(df, column_name):\n",
    "    subsets = ['train', 'valid', 'test']\n",
    "        \n",
    "    print(\"Classification Report for the Whole Dataset:\")\n",
    "    print(classification_report(df['annotation_label'], df[column_name], digits=4))\n",
    "    \n",
    "    for subset in subsets:\n",
    "        subset_df = df[df['mode'] == subset]\n",
    "        if not subset_df.empty:\n",
    "            print(f\"\\nClassification Report for {subset.capitalize()} Subset:\")\n",
    "            print(classification_report(subset_df['annotation_label'], subset_df[column_name], digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5501609e-da35-4c03-ab68-5324b24d2e68",
   "metadata": {},
   "source": [
    "---\n",
    "# Hard Fusion (Based on labels)   \n",
    "---\n",
    "\n",
    "https://chatgpt.com/c/67981b72-fdf4-8002-95bd-5a75e258e4c3\n",
    "\n",
    "# Majority Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed9765e7-794c-4c5f-a3dd-7a96ec52a22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for majority voting\n",
    "def majority_vote(row):\n",
    "    # Collect the predicted labels\n",
    "    labels = [row['textLabel'], \n",
    "              row['audioLabel'],\n",
    "              row['videoLabel'],\n",
    "             ]\n",
    "    \n",
    "    # Count the occurrences of each class\n",
    "    class_0_count = labels.count(0)\n",
    "    class_1_count = labels.count(1)\n",
    "    \n",
    "    # Apply majority voting\n",
    "    if class_0_count > class_1_count:\n",
    "        return 0\n",
    "    elif class_1_count > class_0_count:\n",
    "        return 1\n",
    "    else:\n",
    "        # Tie-breaking rule (e.g., prioritize textLabel or assign -1 for a tie)\n",
    "        return row['textLabel']  # Example: prioritizing text predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db1eabda-b823-4952-8d78-90ebbb7ed862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply majority voting to each row\n",
    "fusion_df['majorityLabel'] = fusion_df.apply(majority_vote, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e53e7dd4-4ded-4277-9998-9cd193275057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>clip_id</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>mode</th>\n",
       "      <th>annotation_label</th>\n",
       "      <th>probText_0</th>\n",
       "      <th>probText_1</th>\n",
       "      <th>textLabel</th>\n",
       "      <th>probAudio_0</th>\n",
       "      <th>probAudio_1</th>\n",
       "      <th>audioLabel</th>\n",
       "      <th>probVideo_0</th>\n",
       "      <th>probVideo_1</th>\n",
       "      <th>videoLabel</th>\n",
       "      <th>majorityLabel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>11</td>\n",
       "      <td>a lot of sad part</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.997359</td>\n",
       "      <td>0.002641</td>\n",
       "      <td>0</td>\n",
       "      <td>0.399598</td>\n",
       "      <td>0.600402</td>\n",
       "      <td>1</td>\n",
       "      <td>0.495560</td>\n",
       "      <td>0.504440</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>10</td>\n",
       "      <td>there is sad part</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.997300</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0</td>\n",
       "      <td>0.439418</td>\n",
       "      <td>0.560582</td>\n",
       "      <td>1</td>\n",
       "      <td>0.493912</td>\n",
       "      <td>0.506088</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>13</td>\n",
       "      <td>and it a really funny</td>\n",
       "      <td>train</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002918</td>\n",
       "      <td>0.997082</td>\n",
       "      <td>1</td>\n",
       "      <td>0.350468</td>\n",
       "      <td>0.649532</td>\n",
       "      <td>1</td>\n",
       "      <td>0.450571</td>\n",
       "      <td>0.549429</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>12</td>\n",
       "      <td>but it wa really really awesome</td>\n",
       "      <td>train</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002906</td>\n",
       "      <td>0.997094</td>\n",
       "      <td>1</td>\n",
       "      <td>0.347897</td>\n",
       "      <td>0.652103</td>\n",
       "      <td>1</td>\n",
       "      <td>0.402363</td>\n",
       "      <td>0.597637</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>1</td>\n",
       "      <td>anyhow it wa really good</td>\n",
       "      <td>train</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002872</td>\n",
       "      <td>0.997128</td>\n",
       "      <td>1</td>\n",
       "      <td>0.435212</td>\n",
       "      <td>0.564788</td>\n",
       "      <td>1</td>\n",
       "      <td>0.317268</td>\n",
       "      <td>0.682732</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2194</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>30</td>\n",
       "      <td>because there really wa not all that much to i...</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.997182</td>\n",
       "      <td>0.002818</td>\n",
       "      <td>0</td>\n",
       "      <td>0.597331</td>\n",
       "      <td>0.402669</td>\n",
       "      <td>0</td>\n",
       "      <td>0.445997</td>\n",
       "      <td>0.554003</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2195</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>35</td>\n",
       "      <td>so if you like to hear a like more positive re...</td>\n",
       "      <td>test</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.997070</td>\n",
       "      <td>1</td>\n",
       "      <td>0.399418</td>\n",
       "      <td>0.600582</td>\n",
       "      <td>1</td>\n",
       "      <td>0.545271</td>\n",
       "      <td>0.454729</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>34</td>\n",
       "      <td>and she really enjoyed the film</td>\n",
       "      <td>test</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002905</td>\n",
       "      <td>0.997095</td>\n",
       "      <td>1</td>\n",
       "      <td>0.341855</td>\n",
       "      <td>0.658145</td>\n",
       "      <td>1</td>\n",
       "      <td>0.461881</td>\n",
       "      <td>0.538119</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2197</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>33</td>\n",
       "      <td>if you do want to see somebody who is possibly...</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.996939</td>\n",
       "      <td>0.003061</td>\n",
       "      <td>0</td>\n",
       "      <td>0.406756</td>\n",
       "      <td>0.593244</td>\n",
       "      <td>1</td>\n",
       "      <td>0.504509</td>\n",
       "      <td>0.495491</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2198</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>32</td>\n",
       "      <td>yeah i mean if you want to see a video it goin...</td>\n",
       "      <td>test</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.003109</td>\n",
       "      <td>0.996891</td>\n",
       "      <td>1</td>\n",
       "      <td>0.462510</td>\n",
       "      <td>0.537490</td>\n",
       "      <td>1</td>\n",
       "      <td>0.464074</td>\n",
       "      <td>0.535926</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2199 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         video_id  clip_id                                     processed_text  \\\n",
       "0     03bSnISJMiM       11                                  a lot of sad part   \n",
       "1     03bSnISJMiM       10                                  there is sad part   \n",
       "2     03bSnISJMiM       13                              and it a really funny   \n",
       "3     03bSnISJMiM       12                    but it wa really really awesome   \n",
       "4     03bSnISJMiM        1                           anyhow it wa really good   \n",
       "...           ...      ...                                                ...   \n",
       "2194  zhpQhgha_KU       30  because there really wa not all that much to i...   \n",
       "2195  zhpQhgha_KU       35  so if you like to hear a like more positive re...   \n",
       "2196  zhpQhgha_KU       34                    and she really enjoyed the film   \n",
       "2197  zhpQhgha_KU       33  if you do want to see somebody who is possibly...   \n",
       "2198  zhpQhgha_KU       32  yeah i mean if you want to see a video it goin...   \n",
       "\n",
       "       mode  annotation_label  probText_0  probText_1  textLabel  probAudio_0  \\\n",
       "0     train               0.0    0.997359    0.002641          0     0.399598   \n",
       "1     train               0.0    0.997300    0.002700          0     0.439418   \n",
       "2     train               1.0    0.002918    0.997082          1     0.350468   \n",
       "3     train               1.0    0.002906    0.997094          1     0.347897   \n",
       "4     train               1.0    0.002872    0.997128          1     0.435212   \n",
       "...     ...               ...         ...         ...        ...          ...   \n",
       "2194   test               0.0    0.997182    0.002818          0     0.597331   \n",
       "2195   test               1.0    0.002930    0.997070          1     0.399418   \n",
       "2196   test               1.0    0.002905    0.997095          1     0.341855   \n",
       "2197   test               0.0    0.996939    0.003061          0     0.406756   \n",
       "2198   test               1.0    0.003109    0.996891          1     0.462510   \n",
       "\n",
       "      probAudio_1  audioLabel  probVideo_0  probVideo_1  videoLabel  \\\n",
       "0        0.600402           1     0.495560     0.504440           1   \n",
       "1        0.560582           1     0.493912     0.506088           1   \n",
       "2        0.649532           1     0.450571     0.549429           1   \n",
       "3        0.652103           1     0.402363     0.597637           1   \n",
       "4        0.564788           1     0.317268     0.682732           1   \n",
       "...           ...         ...          ...          ...         ...   \n",
       "2194     0.402669           0     0.445997     0.554003           1   \n",
       "2195     0.600582           1     0.545271     0.454729           0   \n",
       "2196     0.658145           1     0.461881     0.538119           1   \n",
       "2197     0.593244           1     0.504509     0.495491           0   \n",
       "2198     0.537490           1     0.464074     0.535926           1   \n",
       "\n",
       "      majorityLabel  \n",
       "0                 1  \n",
       "1                 1  \n",
       "2                 1  \n",
       "3                 1  \n",
       "4                 1  \n",
       "...             ...  \n",
       "2194              0  \n",
       "2195              1  \n",
       "2196              1  \n",
       "2197              0  \n",
       "2198              1  \n",
       "\n",
       "[2199 rows x 15 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fusion_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c76087f-9535-4f69-a027-f9a559f3d60d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for the Whole Dataset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8413    0.7048    0.7670      1023\n",
      "         1.0     0.7750    0.8844    0.8261      1176\n",
      "\n",
      "    accuracy                         0.8008      2199\n",
      "   macro avg     0.8081    0.7946    0.7965      2199\n",
      "weighted avg     0.8058    0.8008    0.7986      2199\n",
      "\n",
      "\n",
      "Classification Report for Train Subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8911    0.8007    0.8435       552\n",
      "         1.0     0.8604    0.9262    0.8921       732\n",
      "\n",
      "    accuracy                         0.8723      1284\n",
      "   macro avg     0.8758    0.8635    0.8678      1284\n",
      "weighted avg     0.8736    0.8723    0.8712      1284\n",
      "\n",
      "\n",
      "Classification Report for Valid Subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6212    0.4457    0.5190        92\n",
      "         1.0     0.6871    0.8175    0.7467       137\n",
      "\n",
      "    accuracy                         0.6681       229\n",
      "   macro avg     0.6542    0.6316    0.6328       229\n",
      "weighted avg     0.6606    0.6681    0.6552       229\n",
      "\n",
      "\n",
      "Classification Report for Test Subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8068    0.6280    0.7062       379\n",
      "         1.0     0.6394    0.8143    0.7163       307\n",
      "\n",
      "    accuracy                         0.7114       686\n",
      "   macro avg     0.7231    0.7212    0.7113       686\n",
      "weighted avg     0.7319    0.7114    0.7108       686\n",
      "\n"
     ]
    }
   ],
   "source": [
    "printReport(fusion_df, 'majorityLabel')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c164b97b-79d0-4ddb-ac4f-4ebaf4900110",
   "metadata": {},
   "source": [
    "# Weighted Voting\n",
    "\n",
    "## Weights for each modality based on validation set label's accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78cf8a7c-b352-4946-9dac-8154500dfe47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_weights(df, mode='valid'):\n",
    "    \"\"\"Calculate weights for each modality based on validation accuracy.\"\"\"\n",
    "    validation_df = df[df['mode'] == mode]\n",
    "    \n",
    "    text_accuracy = (validation_df['textLabel'] == validation_df['annotation_label']).mean()\n",
    "    audio_accuracy = (validation_df['audioLabel'] == validation_df['annotation_label']).mean()\n",
    "    video_accuracy = (validation_df['videoLabel'] == validation_df['annotation_label']).mean()\n",
    "\n",
    "    return {\n",
    "        'text': text_accuracy,\n",
    "        'audio': audio_accuracy,\n",
    "        'video': video_accuracy\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "27a0b4ac-a137-40d9-bf77-c81ea2f950ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 0.8646288209606987, 'audio': 0.6069868995633187, 'video': 0.45414847161572053}\n"
     ]
    }
   ],
   "source": [
    "weights = calculate_weights(fusion_df)\n",
    "\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c52ed2b-d40e-414e-891e-aef4436331ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_voting_fusion(df, weights):\n",
    "    \"\"\"Perform late fusion using Weighted Voting.\"\"\"\n",
    "    def fused_label(row):\n",
    "        # Calculate the weighted votes\n",
    "        votes = Counter({\n",
    "            row['textLabel']: weights['text'],\n",
    "            row['audioLabel']: weights['audio'],\n",
    "            row['videoLabel']: weights['video']\n",
    "        })\n",
    "        # Return the label with the highest weight\n",
    "        return votes.most_common(1)[0][0]\n",
    "\n",
    "    df['weightedVotingOnLabel_validationAccuracyWeights_Label'] = df.apply(fused_label, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35a3b426-ab45-4035-8086-36902c1019cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fusion_df = weighted_voting_fusion(fusion_df, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c62dceb4-aca3-45af-be8c-3e71ebc6f683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>clip_id</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>mode</th>\n",
       "      <th>annotation_label</th>\n",
       "      <th>probText_0</th>\n",
       "      <th>probText_1</th>\n",
       "      <th>textLabel</th>\n",
       "      <th>probAudio_0</th>\n",
       "      <th>probAudio_1</th>\n",
       "      <th>audioLabel</th>\n",
       "      <th>probVideo_0</th>\n",
       "      <th>probVideo_1</th>\n",
       "      <th>videoLabel</th>\n",
       "      <th>majorityLabel</th>\n",
       "      <th>weightedVotingOnLabel_validationAccuracyWeights_Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>11</td>\n",
       "      <td>a lot of sad part</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.997359</td>\n",
       "      <td>0.002641</td>\n",
       "      <td>0</td>\n",
       "      <td>0.399598</td>\n",
       "      <td>0.600402</td>\n",
       "      <td>1</td>\n",
       "      <td>0.495560</td>\n",
       "      <td>0.504440</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>10</td>\n",
       "      <td>there is sad part</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.997300</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0</td>\n",
       "      <td>0.439418</td>\n",
       "      <td>0.560582</td>\n",
       "      <td>1</td>\n",
       "      <td>0.493912</td>\n",
       "      <td>0.506088</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>13</td>\n",
       "      <td>and it a really funny</td>\n",
       "      <td>train</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002918</td>\n",
       "      <td>0.997082</td>\n",
       "      <td>1</td>\n",
       "      <td>0.350468</td>\n",
       "      <td>0.649532</td>\n",
       "      <td>1</td>\n",
       "      <td>0.450571</td>\n",
       "      <td>0.549429</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>12</td>\n",
       "      <td>but it wa really really awesome</td>\n",
       "      <td>train</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002906</td>\n",
       "      <td>0.997094</td>\n",
       "      <td>1</td>\n",
       "      <td>0.347897</td>\n",
       "      <td>0.652103</td>\n",
       "      <td>1</td>\n",
       "      <td>0.402363</td>\n",
       "      <td>0.597637</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>1</td>\n",
       "      <td>anyhow it wa really good</td>\n",
       "      <td>train</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002872</td>\n",
       "      <td>0.997128</td>\n",
       "      <td>1</td>\n",
       "      <td>0.435212</td>\n",
       "      <td>0.564788</td>\n",
       "      <td>1</td>\n",
       "      <td>0.317268</td>\n",
       "      <td>0.682732</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2194</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>30</td>\n",
       "      <td>because there really wa not all that much to i...</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.997182</td>\n",
       "      <td>0.002818</td>\n",
       "      <td>0</td>\n",
       "      <td>0.597331</td>\n",
       "      <td>0.402669</td>\n",
       "      <td>0</td>\n",
       "      <td>0.445997</td>\n",
       "      <td>0.554003</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2195</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>35</td>\n",
       "      <td>so if you like to hear a like more positive re...</td>\n",
       "      <td>test</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.997070</td>\n",
       "      <td>1</td>\n",
       "      <td>0.399418</td>\n",
       "      <td>0.600582</td>\n",
       "      <td>1</td>\n",
       "      <td>0.545271</td>\n",
       "      <td>0.454729</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>34</td>\n",
       "      <td>and she really enjoyed the film</td>\n",
       "      <td>test</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002905</td>\n",
       "      <td>0.997095</td>\n",
       "      <td>1</td>\n",
       "      <td>0.341855</td>\n",
       "      <td>0.658145</td>\n",
       "      <td>1</td>\n",
       "      <td>0.461881</td>\n",
       "      <td>0.538119</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2197</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>33</td>\n",
       "      <td>if you do want to see somebody who is possibly...</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.996939</td>\n",
       "      <td>0.003061</td>\n",
       "      <td>0</td>\n",
       "      <td>0.406756</td>\n",
       "      <td>0.593244</td>\n",
       "      <td>1</td>\n",
       "      <td>0.504509</td>\n",
       "      <td>0.495491</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2198</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>32</td>\n",
       "      <td>yeah i mean if you want to see a video it goin...</td>\n",
       "      <td>test</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.003109</td>\n",
       "      <td>0.996891</td>\n",
       "      <td>1</td>\n",
       "      <td>0.462510</td>\n",
       "      <td>0.537490</td>\n",
       "      <td>1</td>\n",
       "      <td>0.464074</td>\n",
       "      <td>0.535926</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2199 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         video_id  clip_id                                     processed_text  \\\n",
       "0     03bSnISJMiM       11                                  a lot of sad part   \n",
       "1     03bSnISJMiM       10                                  there is sad part   \n",
       "2     03bSnISJMiM       13                              and it a really funny   \n",
       "3     03bSnISJMiM       12                    but it wa really really awesome   \n",
       "4     03bSnISJMiM        1                           anyhow it wa really good   \n",
       "...           ...      ...                                                ...   \n",
       "2194  zhpQhgha_KU       30  because there really wa not all that much to i...   \n",
       "2195  zhpQhgha_KU       35  so if you like to hear a like more positive re...   \n",
       "2196  zhpQhgha_KU       34                    and she really enjoyed the film   \n",
       "2197  zhpQhgha_KU       33  if you do want to see somebody who is possibly...   \n",
       "2198  zhpQhgha_KU       32  yeah i mean if you want to see a video it goin...   \n",
       "\n",
       "       mode  annotation_label  probText_0  probText_1  textLabel  probAudio_0  \\\n",
       "0     train               0.0    0.997359    0.002641          0     0.399598   \n",
       "1     train               0.0    0.997300    0.002700          0     0.439418   \n",
       "2     train               1.0    0.002918    0.997082          1     0.350468   \n",
       "3     train               1.0    0.002906    0.997094          1     0.347897   \n",
       "4     train               1.0    0.002872    0.997128          1     0.435212   \n",
       "...     ...               ...         ...         ...        ...          ...   \n",
       "2194   test               0.0    0.997182    0.002818          0     0.597331   \n",
       "2195   test               1.0    0.002930    0.997070          1     0.399418   \n",
       "2196   test               1.0    0.002905    0.997095          1     0.341855   \n",
       "2197   test               0.0    0.996939    0.003061          0     0.406756   \n",
       "2198   test               1.0    0.003109    0.996891          1     0.462510   \n",
       "\n",
       "      probAudio_1  audioLabel  probVideo_0  probVideo_1  videoLabel  \\\n",
       "0        0.600402           1     0.495560     0.504440           1   \n",
       "1        0.560582           1     0.493912     0.506088           1   \n",
       "2        0.649532           1     0.450571     0.549429           1   \n",
       "3        0.652103           1     0.402363     0.597637           1   \n",
       "4        0.564788           1     0.317268     0.682732           1   \n",
       "...           ...         ...          ...          ...         ...   \n",
       "2194     0.402669           0     0.445997     0.554003           1   \n",
       "2195     0.600582           1     0.545271     0.454729           0   \n",
       "2196     0.658145           1     0.461881     0.538119           1   \n",
       "2197     0.593244           1     0.504509     0.495491           0   \n",
       "2198     0.537490           1     0.464074     0.535926           1   \n",
       "\n",
       "      majorityLabel  weightedVotingOnLabel_validationAccuracyWeights_Label  \n",
       "0                 1                                                  0      \n",
       "1                 1                                                  0      \n",
       "2                 1                                                  1      \n",
       "3                 1                                                  1      \n",
       "4                 1                                                  1      \n",
       "...             ...                                                ...      \n",
       "2194              0                                                  0      \n",
       "2195              1                                                  1      \n",
       "2196              1                                                  1      \n",
       "2197              0                                                  1      \n",
       "2198              1                                                  1      \n",
       "\n",
       "[2199 rows x 16 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fusion_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "278fc170-2141-47ab-9378-aa295cb99a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for the Whole Dataset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7856    0.7019    0.7414      1023\n",
      "         1.0     0.7626    0.8333    0.7964      1176\n",
      "\n",
      "    accuracy                         0.7722      2199\n",
      "   macro avg     0.7741    0.7676    0.7689      2199\n",
      "weighted avg     0.7733    0.7722    0.7708      2199\n",
      "\n",
      "\n",
      "Classification Report for Train Subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7932    0.6812    0.7329       552\n",
      "         1.0     0.7827    0.8661    0.8223       732\n",
      "\n",
      "    accuracy                         0.7866      1284\n",
      "   macro avg     0.7880    0.7736    0.7776      1284\n",
      "weighted avg     0.7872    0.7866    0.7839      1284\n",
      "\n",
      "\n",
      "Classification Report for Valid Subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7527    0.7609    0.7568        92\n",
      "         1.0     0.8382    0.8321    0.8352       137\n",
      "\n",
      "    accuracy                         0.8035       229\n",
      "   macro avg     0.7955    0.7965    0.7960       229\n",
      "weighted avg     0.8039    0.8035    0.8037       229\n",
      "\n",
      "\n",
      "Classification Report for Test Subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7839    0.7177    0.7493       379\n",
      "         1.0     0.6844    0.7557    0.7183       307\n",
      "\n",
      "    accuracy                         0.7347       686\n",
      "   macro avg     0.7341    0.7367    0.7338       686\n",
      "weighted avg     0.7393    0.7347    0.7354       686\n",
      "\n"
     ]
    }
   ],
   "source": [
    "printReport(fusion_df, 'weightedVotingOnLabel_validationAccuracyWeights_Label')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc8d6ef-9778-41f3-adb6-192358b75c99",
   "metadata": {},
   "source": [
    "## Weights for each modality using logistic regression on labels\n",
    "\n",
    "There is no reason for us to calculate the weights using logistic regression on the predicted labels (not probabilities) since they will give the same results.\n",
    "\n",
    "The test accuracy remains the same whether weights for each modality are calculated using logistic regression on the validation set labels or directly based on validation set accuracy because both methods fundamentally measure the reliability of each modality. \n",
    "\n",
    "Logistic regression, when applied to labels, essentially learns a simple model that reflects the alignment between each modality’s predictions and the ground truth, which is conceptually similar to calculating validation accuracy. \n",
    "\n",
    "In both cases, the derived weights reflect the relative reliability of the modalities and are normalized to ensure comparability. Consequently, the weighted voting process amplifies the influence of more reliable modalities in the same way, leading to similar test accuracy outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "71ef471f-4e36-4b19-9fe0-2aa78224a1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# def calculate_weights_with_logistic_regression(df, mode='valid'):\n",
    "#     \"\"\"Calculate weights for each modality using logistic regression.\"\"\"\n",
    "#     validation_df = df[df['mode'] == mode]\n",
    "#     X = validation_df[['probText_0', 'probText_1', 'probAudio_0', 'probAudio_1', 'probVideo_0', 'probVideo_1']]\n",
    "#     y = validation_df['annotation_label']\n",
    "    \n",
    "#     # Encode labels as integers\n",
    "#     le = LabelEncoder()\n",
    "#     y_encoded = le.fit_transform(y)\n",
    "\n",
    "#     # Train logistic regression models for each modality\n",
    "#     models = {}\n",
    "#     accuracies = {}\n",
    "    \n",
    "#     for modality, cols in {\n",
    "#         'text': ['probText_0', 'probText_1'],\n",
    "#         'audio': ['probAudio_0', 'probAudio_1'],\n",
    "#         'video': ['probVideo_0', 'probVideo_1']\n",
    "#     }.items():\n",
    "#         X_modality = validation_df[cols]\n",
    "#         model = LogisticRegression()\n",
    "#         model.fit(X_modality, y_encoded)\n",
    "#         models[modality] = model\n",
    "        \n",
    "#         # Evaluate accuracy on the validation subset\n",
    "#         y_pred = model.predict(X_modality)\n",
    "#         accuracies[modality] = accuracy_score(y_encoded, y_pred)\n",
    "\n",
    "#     # Normalize weights so they sum to 1\n",
    "#     total_accuracy = sum(accuracies.values())\n",
    "#     weights = {modality: acc / total_accuracy for modality, acc in accuracies.items()}\n",
    "\n",
    "#     return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf4648d-5dae-4dbd-85d3-aecdf5208e83",
   "metadata": {},
   "source": [
    "# k-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e903f253-f26f-4e17-9be3-0c4669301e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def fusion_knn_rule_with_tuning_label(df, k_range, text=\"knnLabel_label\", train_mode=\"valid\"):\n",
    "    \"\"\"\n",
    "    Apply k-Nearest Neighbors (kNN) for late fusion with hyperparameter tuning on k using 5-fold cross-validation.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas DataFrame with columns probText_0, probAudio_0, probVideo_0, probText_1, probAudio_1, probVideo_1\n",
    "    - k_range: list of int, range of k values to tune (e.g., [1, 3, 5, 7, 9])\n",
    "    - text: str, the name of the column to store the resulting labels\n",
    "    - mode_column: str, the name of the column indicating the dataset mode (e.g., 'train', 'valid')\n",
    "    - mode_value: str, the value in mode_column to use for validation (e.g., 'valid')\n",
    "\n",
    "    Returns:\n",
    "    - df: DataFrame with the new column containing the fused labels\n",
    "    - best_k: int, the best k value found during hyperparameter tuning\n",
    "    \"\"\"\n",
    "    # Filter the validation subset\n",
    "    valid_df = df[df['mode'] == train_mode]\n",
    "\n",
    "    # Extract features (probabilities) and labels\n",
    "    X = valid_df[['textLabel', 'audioLabel', 'videoLabel']]\n",
    "    y = valid_df['annotation_label']  # Assuming you have a 'label' column in your DataFrame\n",
    "\n",
    "    # Initialize kNN classifier\n",
    "    knn = KNeighborsClassifier()\n",
    "\n",
    "    # Set up GridSearchCV for hyperparameter tuning\n",
    "    param_grid = {'n_neighbors': range(1, k_range)}\n",
    "    grid_search = GridSearchCV(knn, param_grid, cv=5, scoring='accuracy')  # 5-fold cross-validation\n",
    "\n",
    "    # Perform hyperparameter tuning\n",
    "    grid_search.fit(X, y)\n",
    "\n",
    "    # Get the best k value\n",
    "    best_k = grid_search.best_params_['n_neighbors']\n",
    "    print(\"Best k: \", best_k)\n",
    "\n",
    "    # Train the kNN model on the entire validation set using the best k\n",
    "    best_knn = KNeighborsClassifier(n_neighbors=best_k)\n",
    "    best_knn.fit(X, y)\n",
    "\n",
    "    # Predict labels for the entire dataset using the best kNN model\n",
    "    X_all = df[['textLabel', 'audioLabel', 'videoLabel']]\n",
    "    df[text] = best_knn.predict(X_all)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c94db461-1e2f-437d-a2de-14739db4a38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best k:  7\n"
     ]
    }
   ],
   "source": [
    "fusion_df = fusion_knn_rule_with_tuning_label(fusion_df, k_range=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f4a81025-e072-486d-8cb5-d8a0d01744ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for the Whole Dataset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8649    0.9013    0.8827      1023\n",
      "         1.0     0.9109    0.8776    0.8939      1176\n",
      "\n",
      "    accuracy                         0.8886      2199\n",
      "   macro avg     0.8879    0.8894    0.8883      2199\n",
      "weighted avg     0.8895    0.8886    0.8887      2199\n",
      "\n",
      "\n",
      "Classification Report for Train Subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8898    0.9366    0.9126       552\n",
      "         1.0     0.9502    0.9126    0.9310       732\n",
      "\n",
      "    accuracy                         0.9229      1284\n",
      "   macro avg     0.9200    0.9246    0.9218      1284\n",
      "weighted avg     0.9243    0.9229    0.9231      1284\n",
      "\n",
      "\n",
      "Classification Report for Valid Subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8081    0.8696    0.8377        92\n",
      "         1.0     0.9077    0.8613    0.8839       137\n",
      "\n",
      "    accuracy                         0.8646       229\n",
      "   macro avg     0.8579    0.8654    0.8608       229\n",
      "weighted avg     0.8677    0.8646    0.8653       229\n",
      "\n",
      "\n",
      "Classification Report for Test Subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8420    0.8575    0.8497       379\n",
      "         1.0     0.8200    0.8013    0.8105       307\n",
      "\n",
      "    accuracy                         0.8324       686\n",
      "   macro avg     0.8310    0.8294    0.8301       686\n",
      "weighted avg     0.8321    0.8324    0.8322       686\n",
      "\n"
     ]
    }
   ],
   "source": [
    "printReport(fusion_df, 'knnLabel_label')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8425d3-74ea-44de-8f24-ebce0494ff86",
   "metadata": {},
   "source": [
    "---\n",
    "# Soft Fusion (Based on class posterior probabilities)   \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97b955c-5dac-40df-b0ab-7353c1f82c42",
   "metadata": {},
   "source": [
    "# Averaging\n",
    "\n",
    "Combine the predicted probabilities by taking their arithmetic mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dca9eaeb-cc17-459b-a597-7da05680a983",
   "metadata": {},
   "outputs": [],
   "source": [
    "def averaging_fusion(df, weights=[1/3, 1/3, 1/3], text='averaging_label'):\n",
    "    # Normalize weights to ensure they sum to 1\n",
    "    weights = [w / sum(weights) for w in weights]\n",
    "\n",
    "    def avg_prob_label(row):\n",
    "        # Calculate weighted probabilities for class 0 and class 1\n",
    "        avg_prob_0 = (row['probText_0'] * weights[0] +\n",
    "                      row['probAudio_0'] * weights[1] +\n",
    "                      row['probVideo_0'] * weights[2])\n",
    "        avg_prob_1 = (row['probText_1'] * weights[0] +\n",
    "                      row['probAudio_1'] * weights[1] +\n",
    "                      row['probVideo_1'] * weights[2])\n",
    "        \n",
    "        # Return the final label (0 or 1) based on the higher weighted probability\n",
    "        return 0 if avg_prob_0 > avg_prob_1 else 1\n",
    "\n",
    "    # Apply the nested function to each row of the DataFrame\n",
    "    df[text] = df.apply(avg_prob_label, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6725f910-a2c2-4b06-b90a-cd518b9dc37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fusion_df = averaging_fusion(fusion_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b203352e-7599-4428-8bb8-0536a67d6027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for the Whole Dataset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8641    0.9013    0.8823      1023\n",
      "         1.0     0.9108    0.8767    0.8934      1176\n",
      "\n",
      "    accuracy                         0.8881      2199\n",
      "   macro avg     0.8874    0.8890    0.8879      2199\n",
      "weighted avg     0.8891    0.8881    0.8882      2199\n",
      "\n",
      "\n",
      "Classification Report for Train Subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8898    0.9366    0.9126       552\n",
      "         1.0     0.9502    0.9126    0.9310       732\n",
      "\n",
      "    accuracy                         0.9229      1284\n",
      "   macro avg     0.9200    0.9246    0.9218      1284\n",
      "weighted avg     0.9243    0.9229    0.9231      1284\n",
      "\n",
      "\n",
      "Classification Report for Valid Subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8081    0.8696    0.8377        92\n",
      "         1.0     0.9077    0.8613    0.8839       137\n",
      "\n",
      "    accuracy                         0.8646       229\n",
      "   macro avg     0.8579    0.8654    0.8608       229\n",
      "weighted avg     0.8677    0.8646    0.8653       229\n",
      "\n",
      "\n",
      "Classification Report for Test Subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8398    0.8575    0.8486       379\n",
      "         1.0     0.8194    0.7980    0.8086       307\n",
      "\n",
      "    accuracy                         0.8309       686\n",
      "   macro avg     0.8296    0.8278    0.8286       686\n",
      "weighted avg     0.8307    0.8309    0.8307       686\n",
      "\n"
     ]
    }
   ],
   "source": [
    "printReport(fusion_df, 'averaging_label')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e54750-d2eb-4474-9cf4-7b58ba6a6bb4",
   "metadata": {},
   "source": [
    "## Weighted Averaging\n",
    "\n",
    "### Weights calculating my maximizing the validation set accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2bfd0ecb-026b-4d1b-88cc-c66544d85054",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.preprocessing import normalize\n",
    "import numpy as np\n",
    "\n",
    "def calculate_weights_logistic(df):\n",
    "    \"\"\"\n",
    "    Calculate weights using logistic regression based on probabilities for text, audio, and video.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame containing probabilities and target labels.\n",
    "    - target_column: Name of the column containing the true labels (0 or 1).\n",
    "\n",
    "    Returns:\n",
    "    - Normalized weights for text, audio, and video.\n",
    "    \"\"\"\n",
    "\n",
    "    df = df[fusion_df['mode'] == 'valid']\n",
    "    \n",
    "    # Extract feature columns (probabilities for text, audio, video for class 1)\n",
    "    X = df[['probText_1', 'probAudio_1', 'probVideo_1']].values\n",
    "    y = df['annotation_label'].values  # True labels\n",
    "\n",
    "    # Fit logistic regression model\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    # Extract coefficients and normalize to sum to 1\n",
    "    raw_weights = np.abs(model.coef_[0])  # Take absolute values of coefficients\n",
    "    normalized_weights = raw_weights / raw_weights.sum()\n",
    "\n",
    "    return normalized_weights.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "933bb960-e1dd-4018-8c32-da5257465845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8880921469739113, 0.06622909384963249, 0.04567875917645638]\n"
     ]
    }
   ],
   "source": [
    "weights_weightedAvg = calculate_weights_logistic(fusion_df)\n",
    "\n",
    "print(weights_weightedAvg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8e27a44a-608f-46a5-8217-a10bc6c76f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "fusion_df = averaging_fusion(fusion_df, weights=weights_weightedAvg, text='weightedAveraging_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a7e13f65-8c7b-40b7-ad13-d7d3b70783c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for the Whole Dataset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8649    0.9013    0.8827      1023\n",
      "         1.0     0.9109    0.8776    0.8939      1176\n",
      "\n",
      "    accuracy                         0.8886      2199\n",
      "   macro avg     0.8879    0.8894    0.8883      2199\n",
      "weighted avg     0.8895    0.8886    0.8887      2199\n",
      "\n",
      "\n",
      "Classification Report for Train Subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8898    0.9366    0.9126       552\n",
      "         1.0     0.9502    0.9126    0.9310       732\n",
      "\n",
      "    accuracy                         0.9229      1284\n",
      "   macro avg     0.9200    0.9246    0.9218      1284\n",
      "weighted avg     0.9243    0.9229    0.9231      1284\n",
      "\n",
      "\n",
      "Classification Report for Valid Subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8081    0.8696    0.8377        92\n",
      "         1.0     0.9077    0.8613    0.8839       137\n",
      "\n",
      "    accuracy                         0.8646       229\n",
      "   macro avg     0.8579    0.8654    0.8608       229\n",
      "weighted avg     0.8677    0.8646    0.8653       229\n",
      "\n",
      "\n",
      "Classification Report for Test Subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8420    0.8575    0.8497       379\n",
      "         1.0     0.8200    0.8013    0.8105       307\n",
      "\n",
      "    accuracy                         0.8324       686\n",
      "   macro avg     0.8310    0.8294    0.8301       686\n",
      "weighted avg     0.8321    0.8324    0.8322       686\n",
      "\n"
     ]
    }
   ],
   "source": [
    "printReport(fusion_df, 'weightedAveraging_label')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6626f443-ff56-4db3-90a2-ba8f8867974f",
   "metadata": {},
   "source": [
    "# Min-Max Rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e64e4c89-dea5-420b-9279-d1634d5e54d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fusion_minmax_rule(df, rule, text=\"minmax_label\"):\n",
    "    \"\"\"\n",
    "    Apply the min or max rule for late fusion to assign labels based on probabilities.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas DataFrame with columns probText_0, probAudio_0, probVideo_0, probText_1, probAudio_1, probVideo_1\n",
    "    - rule: str, \"min\" or \"max\" to specify which fusion rule to use\n",
    "    - text: str, the name of the column to store the resulting labels\n",
    "\n",
    "    Returns:\n",
    "    - df: DataFrame with the new column containing the fused labels\n",
    "    \"\"\"\n",
    "    def minmax_prob_label(row):\n",
    "        # Extract probabilities for each class\n",
    "        probs_0 = [row['probText_0'], row['probAudio_0'], row['probVideo_0']]\n",
    "        probs_1 = [row['probText_1'], row['probAudio_1'], row['probVideo_1']]\n",
    "\n",
    "        # Apply the selected rule\n",
    "        if rule == \"min\":\n",
    "            fused_prob_0 = min(probs_0)\n",
    "            fused_prob_1 = min(probs_1)\n",
    "        elif rule == \"max\":\n",
    "            fused_prob_0 = max(probs_0)\n",
    "            fused_prob_1 = max(probs_1)\n",
    "\n",
    "        # Return the final label (0 or 1) based on the higher fused probability\n",
    "        \n",
    "        return 0 if fused_prob_0 > fused_prob_1 else 1\n",
    "\n",
    "    # Apply the nested function to each row of the DataFrame\n",
    "    df[text] = df.apply(minmax_prob_label, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f441a462-2bba-4944-b2b4-c00691be9701",
   "metadata": {},
   "outputs": [],
   "source": [
    "fusion_df = fusion_minmax_rule(fusion_df, rule=\"max\", text=\"max_label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "34ae3677-bda4-4314-9248-26e5a8135c16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>clip_id</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>mode</th>\n",
       "      <th>annotation_label</th>\n",
       "      <th>probText_0</th>\n",
       "      <th>probText_1</th>\n",
       "      <th>textLabel</th>\n",
       "      <th>probAudio_0</th>\n",
       "      <th>probAudio_1</th>\n",
       "      <th>audioLabel</th>\n",
       "      <th>probVideo_0</th>\n",
       "      <th>probVideo_1</th>\n",
       "      <th>videoLabel</th>\n",
       "      <th>majorityLabel</th>\n",
       "      <th>weightedVotingOnLabel_validationAccuracyWeights_Label</th>\n",
       "      <th>averaging_label</th>\n",
       "      <th>weightedAveraging_label</th>\n",
       "      <th>max_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>11</td>\n",
       "      <td>a lot of sad part</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.997359</td>\n",
       "      <td>0.002641</td>\n",
       "      <td>0</td>\n",
       "      <td>0.399598</td>\n",
       "      <td>0.600402</td>\n",
       "      <td>1</td>\n",
       "      <td>0.495560</td>\n",
       "      <td>0.504440</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>10</td>\n",
       "      <td>there is sad part</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.997300</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0</td>\n",
       "      <td>0.439418</td>\n",
       "      <td>0.560582</td>\n",
       "      <td>1</td>\n",
       "      <td>0.493912</td>\n",
       "      <td>0.506088</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>13</td>\n",
       "      <td>and it a really funny</td>\n",
       "      <td>train</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002918</td>\n",
       "      <td>0.997082</td>\n",
       "      <td>1</td>\n",
       "      <td>0.350468</td>\n",
       "      <td>0.649532</td>\n",
       "      <td>1</td>\n",
       "      <td>0.450571</td>\n",
       "      <td>0.549429</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>12</td>\n",
       "      <td>but it wa really really awesome</td>\n",
       "      <td>train</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002906</td>\n",
       "      <td>0.997094</td>\n",
       "      <td>1</td>\n",
       "      <td>0.347897</td>\n",
       "      <td>0.652103</td>\n",
       "      <td>1</td>\n",
       "      <td>0.402363</td>\n",
       "      <td>0.597637</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>1</td>\n",
       "      <td>anyhow it wa really good</td>\n",
       "      <td>train</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002872</td>\n",
       "      <td>0.997128</td>\n",
       "      <td>1</td>\n",
       "      <td>0.435212</td>\n",
       "      <td>0.564788</td>\n",
       "      <td>1</td>\n",
       "      <td>0.317268</td>\n",
       "      <td>0.682732</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2194</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>30</td>\n",
       "      <td>because there really wa not all that much to i...</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.997182</td>\n",
       "      <td>0.002818</td>\n",
       "      <td>0</td>\n",
       "      <td>0.597331</td>\n",
       "      <td>0.402669</td>\n",
       "      <td>0</td>\n",
       "      <td>0.445997</td>\n",
       "      <td>0.554003</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2195</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>35</td>\n",
       "      <td>so if you like to hear a like more positive re...</td>\n",
       "      <td>test</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.997070</td>\n",
       "      <td>1</td>\n",
       "      <td>0.399418</td>\n",
       "      <td>0.600582</td>\n",
       "      <td>1</td>\n",
       "      <td>0.545271</td>\n",
       "      <td>0.454729</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>34</td>\n",
       "      <td>and she really enjoyed the film</td>\n",
       "      <td>test</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002905</td>\n",
       "      <td>0.997095</td>\n",
       "      <td>1</td>\n",
       "      <td>0.341855</td>\n",
       "      <td>0.658145</td>\n",
       "      <td>1</td>\n",
       "      <td>0.461881</td>\n",
       "      <td>0.538119</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2197</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>33</td>\n",
       "      <td>if you do want to see somebody who is possibly...</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.996939</td>\n",
       "      <td>0.003061</td>\n",
       "      <td>0</td>\n",
       "      <td>0.406756</td>\n",
       "      <td>0.593244</td>\n",
       "      <td>1</td>\n",
       "      <td>0.504509</td>\n",
       "      <td>0.495491</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2198</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>32</td>\n",
       "      <td>yeah i mean if you want to see a video it goin...</td>\n",
       "      <td>test</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.003109</td>\n",
       "      <td>0.996891</td>\n",
       "      <td>1</td>\n",
       "      <td>0.462510</td>\n",
       "      <td>0.537490</td>\n",
       "      <td>1</td>\n",
       "      <td>0.464074</td>\n",
       "      <td>0.535926</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2199 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         video_id  clip_id                                     processed_text  \\\n",
       "0     03bSnISJMiM       11                                  a lot of sad part   \n",
       "1     03bSnISJMiM       10                                  there is sad part   \n",
       "2     03bSnISJMiM       13                              and it a really funny   \n",
       "3     03bSnISJMiM       12                    but it wa really really awesome   \n",
       "4     03bSnISJMiM        1                           anyhow it wa really good   \n",
       "...           ...      ...                                                ...   \n",
       "2194  zhpQhgha_KU       30  because there really wa not all that much to i...   \n",
       "2195  zhpQhgha_KU       35  so if you like to hear a like more positive re...   \n",
       "2196  zhpQhgha_KU       34                    and she really enjoyed the film   \n",
       "2197  zhpQhgha_KU       33  if you do want to see somebody who is possibly...   \n",
       "2198  zhpQhgha_KU       32  yeah i mean if you want to see a video it goin...   \n",
       "\n",
       "       mode  annotation_label  probText_0  probText_1  textLabel  probAudio_0  \\\n",
       "0     train               0.0    0.997359    0.002641          0     0.399598   \n",
       "1     train               0.0    0.997300    0.002700          0     0.439418   \n",
       "2     train               1.0    0.002918    0.997082          1     0.350468   \n",
       "3     train               1.0    0.002906    0.997094          1     0.347897   \n",
       "4     train               1.0    0.002872    0.997128          1     0.435212   \n",
       "...     ...               ...         ...         ...        ...          ...   \n",
       "2194   test               0.0    0.997182    0.002818          0     0.597331   \n",
       "2195   test               1.0    0.002930    0.997070          1     0.399418   \n",
       "2196   test               1.0    0.002905    0.997095          1     0.341855   \n",
       "2197   test               0.0    0.996939    0.003061          0     0.406756   \n",
       "2198   test               1.0    0.003109    0.996891          1     0.462510   \n",
       "\n",
       "      probAudio_1  audioLabel  probVideo_0  probVideo_1  videoLabel  \\\n",
       "0        0.600402           1     0.495560     0.504440           1   \n",
       "1        0.560582           1     0.493912     0.506088           1   \n",
       "2        0.649532           1     0.450571     0.549429           1   \n",
       "3        0.652103           1     0.402363     0.597637           1   \n",
       "4        0.564788           1     0.317268     0.682732           1   \n",
       "...           ...         ...          ...          ...         ...   \n",
       "2194     0.402669           0     0.445997     0.554003           1   \n",
       "2195     0.600582           1     0.545271     0.454729           0   \n",
       "2196     0.658145           1     0.461881     0.538119           1   \n",
       "2197     0.593244           1     0.504509     0.495491           0   \n",
       "2198     0.537490           1     0.464074     0.535926           1   \n",
       "\n",
       "      majorityLabel  weightedVotingOnLabel_validationAccuracyWeights_Label  \\\n",
       "0                 1                                                  0       \n",
       "1                 1                                                  0       \n",
       "2                 1                                                  1       \n",
       "3                 1                                                  1       \n",
       "4                 1                                                  1       \n",
       "...             ...                                                ...       \n",
       "2194              0                                                  0       \n",
       "2195              1                                                  1       \n",
       "2196              1                                                  1       \n",
       "2197              0                                                  1       \n",
       "2198              1                                                  1       \n",
       "\n",
       "      averaging_label  weightedAveraging_label  max_label  \n",
       "0                   0                        0          0  \n",
       "1                   0                        0          0  \n",
       "2                   1                        1          1  \n",
       "3                   1                        1          1  \n",
       "4                   1                        1          1  \n",
       "...               ...                      ...        ...  \n",
       "2194                0                        0          0  \n",
       "2195                1                        1          1  \n",
       "2196                1                        1          1  \n",
       "2197                0                        0          0  \n",
       "2198                1                        1          1  \n",
       "\n",
       "[2199 rows x 19 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fusion_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9f6b7d39-d41f-4177-8ea8-f6fe6ece640d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for the Whole Dataset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8641    0.9013    0.8823      1023\n",
      "         1.0     0.9108    0.8767    0.8934      1176\n",
      "\n",
      "    accuracy                         0.8881      2199\n",
      "   macro avg     0.8874    0.8890    0.8879      2199\n",
      "weighted avg     0.8891    0.8881    0.8882      2199\n",
      "\n",
      "\n",
      "Classification Report for Train Subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8898    0.9366    0.9126       552\n",
      "         1.0     0.9502    0.9126    0.9310       732\n",
      "\n",
      "    accuracy                         0.9229      1284\n",
      "   macro avg     0.9200    0.9246    0.9218      1284\n",
      "weighted avg     0.9243    0.9229    0.9231      1284\n",
      "\n",
      "\n",
      "Classification Report for Valid Subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8081    0.8696    0.8377        92\n",
      "         1.0     0.9077    0.8613    0.8839       137\n",
      "\n",
      "    accuracy                         0.8646       229\n",
      "   macro avg     0.8579    0.8654    0.8608       229\n",
      "weighted avg     0.8677    0.8646    0.8653       229\n",
      "\n",
      "\n",
      "Classification Report for Test Subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8398    0.8575    0.8486       379\n",
      "         1.0     0.8194    0.7980    0.8086       307\n",
      "\n",
      "    accuracy                         0.8309       686\n",
      "   macro avg     0.8296    0.8278    0.8286       686\n",
      "weighted avg     0.8307    0.8309    0.8307       686\n",
      "\n"
     ]
    }
   ],
   "source": [
    "printReport(fusion_df, 'max_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fbc689ee-f595-4c25-b8d4-5b47cb38119e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fusion_df = fusion_minmax_rule(fusion_df, rule=\"min\", text=\"min_label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9c02c7d4-b840-4614-a801-5f354a06528b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for the Whole Dataset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8641    0.9013    0.8823      1023\n",
      "         1.0     0.9108    0.8767    0.8934      1176\n",
      "\n",
      "    accuracy                         0.8881      2199\n",
      "   macro avg     0.8874    0.8890    0.8879      2199\n",
      "weighted avg     0.8891    0.8881    0.8882      2199\n",
      "\n",
      "\n",
      "Classification Report for Train Subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8898    0.9366    0.9126       552\n",
      "         1.0     0.9502    0.9126    0.9310       732\n",
      "\n",
      "    accuracy                         0.9229      1284\n",
      "   macro avg     0.9200    0.9246    0.9218      1284\n",
      "weighted avg     0.9243    0.9229    0.9231      1284\n",
      "\n",
      "\n",
      "Classification Report for Valid Subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8081    0.8696    0.8377        92\n",
      "         1.0     0.9077    0.8613    0.8839       137\n",
      "\n",
      "    accuracy                         0.8646       229\n",
      "   macro avg     0.8579    0.8654    0.8608       229\n",
      "weighted avg     0.8677    0.8646    0.8653       229\n",
      "\n",
      "\n",
      "Classification Report for Test Subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8398    0.8575    0.8486       379\n",
      "         1.0     0.8194    0.7980    0.8086       307\n",
      "\n",
      "    accuracy                         0.8309       686\n",
      "   macro avg     0.8296    0.8278    0.8286       686\n",
      "weighted avg     0.8307    0.8309    0.8307       686\n",
      "\n"
     ]
    }
   ],
   "source": [
    "printReport(fusion_df, 'min_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "78e4d613-16e1-4a4d-9b28-f38717a27cbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>clip_id</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>mode</th>\n",
       "      <th>annotation_label</th>\n",
       "      <th>probText_0</th>\n",
       "      <th>probText_1</th>\n",
       "      <th>textLabel</th>\n",
       "      <th>probAudio_0</th>\n",
       "      <th>probAudio_1</th>\n",
       "      <th>audioLabel</th>\n",
       "      <th>probVideo_0</th>\n",
       "      <th>probVideo_1</th>\n",
       "      <th>videoLabel</th>\n",
       "      <th>majorityLabel</th>\n",
       "      <th>weightedVotingOnLabel_validationAccuracyWeights_Label</th>\n",
       "      <th>averaging_label</th>\n",
       "      <th>weightedAveraging_label</th>\n",
       "      <th>max_label</th>\n",
       "      <th>min_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>11</td>\n",
       "      <td>a lot of sad part</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.997359</td>\n",
       "      <td>0.002641</td>\n",
       "      <td>0</td>\n",
       "      <td>0.399598</td>\n",
       "      <td>0.600402</td>\n",
       "      <td>1</td>\n",
       "      <td>0.495560</td>\n",
       "      <td>0.504440</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>10</td>\n",
       "      <td>there is sad part</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.997300</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0</td>\n",
       "      <td>0.439418</td>\n",
       "      <td>0.560582</td>\n",
       "      <td>1</td>\n",
       "      <td>0.493912</td>\n",
       "      <td>0.506088</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>13</td>\n",
       "      <td>and it a really funny</td>\n",
       "      <td>train</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002918</td>\n",
       "      <td>0.997082</td>\n",
       "      <td>1</td>\n",
       "      <td>0.350468</td>\n",
       "      <td>0.649532</td>\n",
       "      <td>1</td>\n",
       "      <td>0.450571</td>\n",
       "      <td>0.549429</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>12</td>\n",
       "      <td>but it wa really really awesome</td>\n",
       "      <td>train</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002906</td>\n",
       "      <td>0.997094</td>\n",
       "      <td>1</td>\n",
       "      <td>0.347897</td>\n",
       "      <td>0.652103</td>\n",
       "      <td>1</td>\n",
       "      <td>0.402363</td>\n",
       "      <td>0.597637</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>1</td>\n",
       "      <td>anyhow it wa really good</td>\n",
       "      <td>train</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002872</td>\n",
       "      <td>0.997128</td>\n",
       "      <td>1</td>\n",
       "      <td>0.435212</td>\n",
       "      <td>0.564788</td>\n",
       "      <td>1</td>\n",
       "      <td>0.317268</td>\n",
       "      <td>0.682732</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2194</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>30</td>\n",
       "      <td>because there really wa not all that much to i...</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.997182</td>\n",
       "      <td>0.002818</td>\n",
       "      <td>0</td>\n",
       "      <td>0.597331</td>\n",
       "      <td>0.402669</td>\n",
       "      <td>0</td>\n",
       "      <td>0.445997</td>\n",
       "      <td>0.554003</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2195</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>35</td>\n",
       "      <td>so if you like to hear a like more positive re...</td>\n",
       "      <td>test</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.997070</td>\n",
       "      <td>1</td>\n",
       "      <td>0.399418</td>\n",
       "      <td>0.600582</td>\n",
       "      <td>1</td>\n",
       "      <td>0.545271</td>\n",
       "      <td>0.454729</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>34</td>\n",
       "      <td>and she really enjoyed the film</td>\n",
       "      <td>test</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002905</td>\n",
       "      <td>0.997095</td>\n",
       "      <td>1</td>\n",
       "      <td>0.341855</td>\n",
       "      <td>0.658145</td>\n",
       "      <td>1</td>\n",
       "      <td>0.461881</td>\n",
       "      <td>0.538119</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2197</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>33</td>\n",
       "      <td>if you do want to see somebody who is possibly...</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.996939</td>\n",
       "      <td>0.003061</td>\n",
       "      <td>0</td>\n",
       "      <td>0.406756</td>\n",
       "      <td>0.593244</td>\n",
       "      <td>1</td>\n",
       "      <td>0.504509</td>\n",
       "      <td>0.495491</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2198</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>32</td>\n",
       "      <td>yeah i mean if you want to see a video it goin...</td>\n",
       "      <td>test</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.003109</td>\n",
       "      <td>0.996891</td>\n",
       "      <td>1</td>\n",
       "      <td>0.462510</td>\n",
       "      <td>0.537490</td>\n",
       "      <td>1</td>\n",
       "      <td>0.464074</td>\n",
       "      <td>0.535926</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2199 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         video_id  clip_id                                     processed_text  \\\n",
       "0     03bSnISJMiM       11                                  a lot of sad part   \n",
       "1     03bSnISJMiM       10                                  there is sad part   \n",
       "2     03bSnISJMiM       13                              and it a really funny   \n",
       "3     03bSnISJMiM       12                    but it wa really really awesome   \n",
       "4     03bSnISJMiM        1                           anyhow it wa really good   \n",
       "...           ...      ...                                                ...   \n",
       "2194  zhpQhgha_KU       30  because there really wa not all that much to i...   \n",
       "2195  zhpQhgha_KU       35  so if you like to hear a like more positive re...   \n",
       "2196  zhpQhgha_KU       34                    and she really enjoyed the film   \n",
       "2197  zhpQhgha_KU       33  if you do want to see somebody who is possibly...   \n",
       "2198  zhpQhgha_KU       32  yeah i mean if you want to see a video it goin...   \n",
       "\n",
       "       mode  annotation_label  probText_0  probText_1  textLabel  probAudio_0  \\\n",
       "0     train               0.0    0.997359    0.002641          0     0.399598   \n",
       "1     train               0.0    0.997300    0.002700          0     0.439418   \n",
       "2     train               1.0    0.002918    0.997082          1     0.350468   \n",
       "3     train               1.0    0.002906    0.997094          1     0.347897   \n",
       "4     train               1.0    0.002872    0.997128          1     0.435212   \n",
       "...     ...               ...         ...         ...        ...          ...   \n",
       "2194   test               0.0    0.997182    0.002818          0     0.597331   \n",
       "2195   test               1.0    0.002930    0.997070          1     0.399418   \n",
       "2196   test               1.0    0.002905    0.997095          1     0.341855   \n",
       "2197   test               0.0    0.996939    0.003061          0     0.406756   \n",
       "2198   test               1.0    0.003109    0.996891          1     0.462510   \n",
       "\n",
       "      probAudio_1  audioLabel  probVideo_0  probVideo_1  videoLabel  \\\n",
       "0        0.600402           1     0.495560     0.504440           1   \n",
       "1        0.560582           1     0.493912     0.506088           1   \n",
       "2        0.649532           1     0.450571     0.549429           1   \n",
       "3        0.652103           1     0.402363     0.597637           1   \n",
       "4        0.564788           1     0.317268     0.682732           1   \n",
       "...           ...         ...          ...          ...         ...   \n",
       "2194     0.402669           0     0.445997     0.554003           1   \n",
       "2195     0.600582           1     0.545271     0.454729           0   \n",
       "2196     0.658145           1     0.461881     0.538119           1   \n",
       "2197     0.593244           1     0.504509     0.495491           0   \n",
       "2198     0.537490           1     0.464074     0.535926           1   \n",
       "\n",
       "      majorityLabel  weightedVotingOnLabel_validationAccuracyWeights_Label  \\\n",
       "0                 1                                                  0       \n",
       "1                 1                                                  0       \n",
       "2                 1                                                  1       \n",
       "3                 1                                                  1       \n",
       "4                 1                                                  1       \n",
       "...             ...                                                ...       \n",
       "2194              0                                                  0       \n",
       "2195              1                                                  1       \n",
       "2196              1                                                  1       \n",
       "2197              0                                                  1       \n",
       "2198              1                                                  1       \n",
       "\n",
       "      averaging_label  weightedAveraging_label  max_label  min_label  \n",
       "0                   0                        0          0          0  \n",
       "1                   0                        0          0          0  \n",
       "2                   1                        1          1          1  \n",
       "3                   1                        1          1          1  \n",
       "4                   1                        1          1          1  \n",
       "...               ...                      ...        ...        ...  \n",
       "2194                0                        0          0          0  \n",
       "2195                1                        1          1          1  \n",
       "2196                1                        1          1          1  \n",
       "2197                0                        0          0          0  \n",
       "2198                1                        1          1          1  \n",
       "\n",
       "[2199 rows x 20 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fusion_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83511e0-9f70-4cc8-bfe9-26f57a1e75bf",
   "metadata": {},
   "source": [
    "Min and max rules give the same results when the probability rankings across modalities are consistent.   \n",
    "-> This occurs when the relative order of the probabilities for each class (e.g., class 0 and class 1) remains the same across all modalities.   \n",
    "In such cases, the minimum and maximum probabilities for each class will still correctly identify the class with the higher overall likelihood, leading to identical final labels.\n",
    "SO  \n",
    "-> Agreement Among Modalities  \n",
    "If the probabilities from all modalities consistently favor the same class (e.g., class 0 or class 1), both the AVERAGING and MIN-MAX rules will likely produce the same final label.  \n",
    "\n",
    "For example:   \n",
    "Modalities all strongly favor class 0:   \n",
    "Text: 0.8, Audio: 0.7, Video: 0.9 → Final decision = class 0.   \n",
    "In such cases, the actual method of fusion (min, max, or average) does not matter because all modalities already agree.   \n",
    "\n",
    "When there is significant disagreement among modalities, these rules can diverge, and the choice of rule impacts the final classification.\n",
    "\n",
    "\n",
    "Balancing Effect of Averaging   \n",
    "The averaging rule aggregates probabilities, smoothing out extremes.  \n",
    "This is functionally similar to the way the min and max rules act in certain cases:  \n",
    "- The min rule emphasizes the weakest agreement across modalities.\n",
    "- The max rule focuses on the strongest agreement.\n",
    "- Averaging lies between these extremes, blending the influence of all modalities equally. If no extreme disagreement exists among modalities, the averaged probability may still reflect the dominant class.\n",
    "\n",
    "---\n",
    "\n",
    "Situations That Prevent Consistent Results (That would make Min and Max rule give different results)\n",
    "Differences between the min and max rules arise when the rankings of class probabilities are not consistent across modalities. This happens when:\n",
    "\n",
    "- One or more modalities strongly favor one class while others favor another.\n",
    "- Disagreement arises due to noisy or unreliable modalities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0410dc4-27bd-44de-b3be-7f5d9ccec296",
   "metadata": {},
   "source": [
    "# Product Rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "20c7a7b7-51f5-4cef-b111-985c54395d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def product_fusion(df, text='product_label'):\n",
    "    def prod_prob_label(row):\n",
    "        # Calculate product of probabilities for class 0 and class 1\n",
    "        prob_0 = (row['probText_0'] * row['probAudio_0'] * row['probVideo_0'])\n",
    "        prob_1 = (row['probText_1'] * row['probAudio_1'] * row['probVideo_1'])\n",
    "        \n",
    "        # Return the final label (0 or 1) based on the higher product probability\n",
    "        return 0 if prob_0 > prob_1 else 1\n",
    "\n",
    "    # Apply the nested function to each row of the DataFrame\n",
    "    df[text] = df.apply(prod_prob_label, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "89be3548-921f-45e4-8165-d2ba48ed3697",
   "metadata": {},
   "outputs": [],
   "source": [
    "fusion_df = product_fusion(fusion_df, text=\"product_label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "adfc8813-8826-4428-b239-1aa1042cfa28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for the Whole Dataset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8641    0.9013    0.8823      1023\n",
      "         1.0     0.9108    0.8767    0.8934      1176\n",
      "\n",
      "    accuracy                         0.8881      2199\n",
      "   macro avg     0.8874    0.8890    0.8879      2199\n",
      "weighted avg     0.8891    0.8881    0.8882      2199\n",
      "\n",
      "\n",
      "Classification Report for Train Subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8898    0.9366    0.9126       552\n",
      "         1.0     0.9502    0.9126    0.9310       732\n",
      "\n",
      "    accuracy                         0.9229      1284\n",
      "   macro avg     0.9200    0.9246    0.9218      1284\n",
      "weighted avg     0.9243    0.9229    0.9231      1284\n",
      "\n",
      "\n",
      "Classification Report for Valid Subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8081    0.8696    0.8377        92\n",
      "         1.0     0.9077    0.8613    0.8839       137\n",
      "\n",
      "    accuracy                         0.8646       229\n",
      "   macro avg     0.8579    0.8654    0.8608       229\n",
      "weighted avg     0.8677    0.8646    0.8653       229\n",
      "\n",
      "\n",
      "Classification Report for Test Subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8398    0.8575    0.8486       379\n",
      "         1.0     0.8194    0.7980    0.8086       307\n",
      "\n",
      "    accuracy                         0.8309       686\n",
      "   macro avg     0.8296    0.8278    0.8286       686\n",
      "weighted avg     0.8307    0.8309    0.8307       686\n",
      "\n"
     ]
    }
   ],
   "source": [
    "printReport(fusion_df, 'product_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d0042963-fec8-409e-ad3d-7036c12dba6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>clip_id</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>mode</th>\n",
       "      <th>annotation_label</th>\n",
       "      <th>probText_0</th>\n",
       "      <th>probText_1</th>\n",
       "      <th>textLabel</th>\n",
       "      <th>probAudio_0</th>\n",
       "      <th>probAudio_1</th>\n",
       "      <th>...</th>\n",
       "      <th>probVideo_0</th>\n",
       "      <th>probVideo_1</th>\n",
       "      <th>videoLabel</th>\n",
       "      <th>majorityLabel</th>\n",
       "      <th>weightedVotingOnLabel_validationAccuracyWeights_Label</th>\n",
       "      <th>averaging_label</th>\n",
       "      <th>weightedAveraging_label</th>\n",
       "      <th>max_label</th>\n",
       "      <th>min_label</th>\n",
       "      <th>product_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>11</td>\n",
       "      <td>a lot of sad part</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.997359</td>\n",
       "      <td>0.002641</td>\n",
       "      <td>0</td>\n",
       "      <td>0.399598</td>\n",
       "      <td>0.600402</td>\n",
       "      <td>...</td>\n",
       "      <td>0.495560</td>\n",
       "      <td>0.504440</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>10</td>\n",
       "      <td>there is sad part</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.997300</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0</td>\n",
       "      <td>0.439418</td>\n",
       "      <td>0.560582</td>\n",
       "      <td>...</td>\n",
       "      <td>0.493912</td>\n",
       "      <td>0.506088</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>13</td>\n",
       "      <td>and it a really funny</td>\n",
       "      <td>train</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002918</td>\n",
       "      <td>0.997082</td>\n",
       "      <td>1</td>\n",
       "      <td>0.350468</td>\n",
       "      <td>0.649532</td>\n",
       "      <td>...</td>\n",
       "      <td>0.450571</td>\n",
       "      <td>0.549429</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>12</td>\n",
       "      <td>but it wa really really awesome</td>\n",
       "      <td>train</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002906</td>\n",
       "      <td>0.997094</td>\n",
       "      <td>1</td>\n",
       "      <td>0.347897</td>\n",
       "      <td>0.652103</td>\n",
       "      <td>...</td>\n",
       "      <td>0.402363</td>\n",
       "      <td>0.597637</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03bSnISJMiM</td>\n",
       "      <td>1</td>\n",
       "      <td>anyhow it wa really good</td>\n",
       "      <td>train</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002872</td>\n",
       "      <td>0.997128</td>\n",
       "      <td>1</td>\n",
       "      <td>0.435212</td>\n",
       "      <td>0.564788</td>\n",
       "      <td>...</td>\n",
       "      <td>0.317268</td>\n",
       "      <td>0.682732</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2194</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>30</td>\n",
       "      <td>because there really wa not all that much to i...</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.997182</td>\n",
       "      <td>0.002818</td>\n",
       "      <td>0</td>\n",
       "      <td>0.597331</td>\n",
       "      <td>0.402669</td>\n",
       "      <td>...</td>\n",
       "      <td>0.445997</td>\n",
       "      <td>0.554003</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2195</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>35</td>\n",
       "      <td>so if you like to hear a like more positive re...</td>\n",
       "      <td>test</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002930</td>\n",
       "      <td>0.997070</td>\n",
       "      <td>1</td>\n",
       "      <td>0.399418</td>\n",
       "      <td>0.600582</td>\n",
       "      <td>...</td>\n",
       "      <td>0.545271</td>\n",
       "      <td>0.454729</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2196</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>34</td>\n",
       "      <td>and she really enjoyed the film</td>\n",
       "      <td>test</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.002905</td>\n",
       "      <td>0.997095</td>\n",
       "      <td>1</td>\n",
       "      <td>0.341855</td>\n",
       "      <td>0.658145</td>\n",
       "      <td>...</td>\n",
       "      <td>0.461881</td>\n",
       "      <td>0.538119</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2197</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>33</td>\n",
       "      <td>if you do want to see somebody who is possibly...</td>\n",
       "      <td>test</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.996939</td>\n",
       "      <td>0.003061</td>\n",
       "      <td>0</td>\n",
       "      <td>0.406756</td>\n",
       "      <td>0.593244</td>\n",
       "      <td>...</td>\n",
       "      <td>0.504509</td>\n",
       "      <td>0.495491</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2198</th>\n",
       "      <td>zhpQhgha_KU</td>\n",
       "      <td>32</td>\n",
       "      <td>yeah i mean if you want to see a video it goin...</td>\n",
       "      <td>test</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.003109</td>\n",
       "      <td>0.996891</td>\n",
       "      <td>1</td>\n",
       "      <td>0.462510</td>\n",
       "      <td>0.537490</td>\n",
       "      <td>...</td>\n",
       "      <td>0.464074</td>\n",
       "      <td>0.535926</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2199 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         video_id  clip_id                                     processed_text  \\\n",
       "0     03bSnISJMiM       11                                  a lot of sad part   \n",
       "1     03bSnISJMiM       10                                  there is sad part   \n",
       "2     03bSnISJMiM       13                              and it a really funny   \n",
       "3     03bSnISJMiM       12                    but it wa really really awesome   \n",
       "4     03bSnISJMiM        1                           anyhow it wa really good   \n",
       "...           ...      ...                                                ...   \n",
       "2194  zhpQhgha_KU       30  because there really wa not all that much to i...   \n",
       "2195  zhpQhgha_KU       35  so if you like to hear a like more positive re...   \n",
       "2196  zhpQhgha_KU       34                    and she really enjoyed the film   \n",
       "2197  zhpQhgha_KU       33  if you do want to see somebody who is possibly...   \n",
       "2198  zhpQhgha_KU       32  yeah i mean if you want to see a video it goin...   \n",
       "\n",
       "       mode  annotation_label  probText_0  probText_1  textLabel  probAudio_0  \\\n",
       "0     train               0.0    0.997359    0.002641          0     0.399598   \n",
       "1     train               0.0    0.997300    0.002700          0     0.439418   \n",
       "2     train               1.0    0.002918    0.997082          1     0.350468   \n",
       "3     train               1.0    0.002906    0.997094          1     0.347897   \n",
       "4     train               1.0    0.002872    0.997128          1     0.435212   \n",
       "...     ...               ...         ...         ...        ...          ...   \n",
       "2194   test               0.0    0.997182    0.002818          0     0.597331   \n",
       "2195   test               1.0    0.002930    0.997070          1     0.399418   \n",
       "2196   test               1.0    0.002905    0.997095          1     0.341855   \n",
       "2197   test               0.0    0.996939    0.003061          0     0.406756   \n",
       "2198   test               1.0    0.003109    0.996891          1     0.462510   \n",
       "\n",
       "      probAudio_1  ...  probVideo_0  probVideo_1  videoLabel  majorityLabel  \\\n",
       "0        0.600402  ...     0.495560     0.504440           1              1   \n",
       "1        0.560582  ...     0.493912     0.506088           1              1   \n",
       "2        0.649532  ...     0.450571     0.549429           1              1   \n",
       "3        0.652103  ...     0.402363     0.597637           1              1   \n",
       "4        0.564788  ...     0.317268     0.682732           1              1   \n",
       "...           ...  ...          ...          ...         ...            ...   \n",
       "2194     0.402669  ...     0.445997     0.554003           1              0   \n",
       "2195     0.600582  ...     0.545271     0.454729           0              1   \n",
       "2196     0.658145  ...     0.461881     0.538119           1              1   \n",
       "2197     0.593244  ...     0.504509     0.495491           0              0   \n",
       "2198     0.537490  ...     0.464074     0.535926           1              1   \n",
       "\n",
       "      weightedVotingOnLabel_validationAccuracyWeights_Label  averaging_label  \\\n",
       "0                                                     0                    0   \n",
       "1                                                     0                    0   \n",
       "2                                                     1                    1   \n",
       "3                                                     1                    1   \n",
       "4                                                     1                    1   \n",
       "...                                                 ...                  ...   \n",
       "2194                                                  0                    0   \n",
       "2195                                                  1                    1   \n",
       "2196                                                  1                    1   \n",
       "2197                                                  1                    0   \n",
       "2198                                                  1                    1   \n",
       "\n",
       "      weightedAveraging_label  max_label  min_label  product_label  \n",
       "0                           0          0          0              0  \n",
       "1                           0          0          0              0  \n",
       "2                           1          1          1              1  \n",
       "3                           1          1          1              1  \n",
       "4                           1          1          1              1  \n",
       "...                       ...        ...        ...            ...  \n",
       "2194                        0          0          0              0  \n",
       "2195                        1          1          1              1  \n",
       "2196                        1          1          1              1  \n",
       "2197                        0          0          0              0  \n",
       "2198                        1          1          1              1  \n",
       "\n",
       "[2199 rows x 21 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fusion_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e78113-c402-4c15-b878-5043a25c93c7",
   "metadata": {},
   "source": [
    "# k-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "089e12a6-f1f5-4135-abe7-0643deeea20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def fusion_knn_rule_with_tuning(df, k_range, text=\"knn_label\", train_mode=\"valid\"):\n",
    "    \"\"\"\n",
    "    Apply k-Nearest Neighbors (kNN) for late fusion with hyperparameter tuning on k using 5-fold cross-validation.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas DataFrame with columns probText_0, probAudio_0, probVideo_0, probText_1, probAudio_1, probVideo_1\n",
    "    - k_range: list of int, range of k values to tune (e.g., [1, 3, 5, 7, 9])\n",
    "    - text: str, the name of the column to store the resulting labels\n",
    "    - mode_column: str, the name of the column indicating the dataset mode (e.g., 'train', 'valid')\n",
    "    - mode_value: str, the value in mode_column to use for validation (e.g., 'valid')\n",
    "\n",
    "    Returns:\n",
    "    - df: DataFrame with the new column containing the fused labels\n",
    "    - best_k: int, the best k value found during hyperparameter tuning\n",
    "    \"\"\"\n",
    "    # Filter the validation subset\n",
    "    valid_df = df[df['mode'] == train_mode]\n",
    "\n",
    "    # Extract features (probabilities) and labels\n",
    "    X = valid_df[['probText_0', 'probAudio_0', 'probVideo_0', 'probText_1', 'probAudio_1', 'probVideo_1']]\n",
    "    y = valid_df['annotation_label']  # Assuming you have a 'label' column in your DataFrame\n",
    "\n",
    "    # Initialize kNN classifier\n",
    "    knn = KNeighborsClassifier()\n",
    "\n",
    "    # Set up GridSearchCV for hyperparameter tuning\n",
    "    param_grid = {'n_neighbors': range(1, k_range)}\n",
    "    grid_search = GridSearchCV(knn, param_grid, cv=5, scoring='accuracy')  # 5-fold cross-validation\n",
    "\n",
    "    # Perform hyperparameter tuning\n",
    "    grid_search.fit(X, y)\n",
    "\n",
    "    # Get the best k value\n",
    "    best_k = grid_search.best_params_['n_neighbors']\n",
    "    print(\"Best k: \", best_k)\n",
    "\n",
    "    # Train the kNN model on the entire validation set using the best k\n",
    "    best_knn = KNeighborsClassifier(n_neighbors=best_k)\n",
    "    best_knn.fit(X, y)\n",
    "\n",
    "    # Predict labels for the entire dataset using the best kNN model\n",
    "    X_all = df[['probText_0', 'probAudio_0', 'probVideo_0', 'probText_1', 'probAudio_1', 'probVideo_1']]\n",
    "    df[text] = best_knn.predict(X_all)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "fe8f3cee-9a2f-47dd-8acf-b9c396ccf1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best k:  9\n"
     ]
    }
   ],
   "source": [
    "fusion_df = fusion_knn_rule_with_tuning(fusion_df, k_range=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "825e0b88-eff1-4d17-b11c-6ccbc7e2455d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for the Whole Dataset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8649    0.9013    0.8827      1023\n",
      "         1.0     0.9109    0.8776    0.8939      1176\n",
      "\n",
      "    accuracy                         0.8886      2199\n",
      "   macro avg     0.8879    0.8894    0.8883      2199\n",
      "weighted avg     0.8895    0.8886    0.8887      2199\n",
      "\n",
      "\n",
      "Classification Report for Train Subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8898    0.9366    0.9126       552\n",
      "         1.0     0.9502    0.9126    0.9310       732\n",
      "\n",
      "    accuracy                         0.9229      1284\n",
      "   macro avg     0.9200    0.9246    0.9218      1284\n",
      "weighted avg     0.9243    0.9229    0.9231      1284\n",
      "\n",
      "\n",
      "Classification Report for Valid Subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8081    0.8696    0.8377        92\n",
      "         1.0     0.9077    0.8613    0.8839       137\n",
      "\n",
      "    accuracy                         0.8646       229\n",
      "   macro avg     0.8579    0.8654    0.8608       229\n",
      "weighted avg     0.8677    0.8646    0.8653       229\n",
      "\n",
      "\n",
      "Classification Report for Test Subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8420    0.8575    0.8497       379\n",
      "         1.0     0.8200    0.8013    0.8105       307\n",
      "\n",
      "    accuracy                         0.8324       686\n",
      "   macro avg     0.8310    0.8294    0.8301       686\n",
      "weighted avg     0.8321    0.8324    0.8322       686\n",
      "\n"
     ]
    }
   ],
   "source": [
    "printReport(fusion_df, 'knn_label')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bc4aab-366d-48eb-8238-693c9bcf68b3",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a3f58bfe-44be-4c36-a51d-4a86534725b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "def naive_bayes_fusion(df, text='naive_bayes_label'):\n",
    "    # df_train = df[df['mode'].isin(['train', 'valid'])]\n",
    "    df_train = df[df['mode'] == 'valid']\n",
    "\n",
    "    # Extract the relevant features for probabilities (e.g., probText, probAudio, probVideo for both classes)\n",
    "    feature_columns = ['probText_0', 'probText_1',\n",
    "                       'probAudio_0', 'probAudio_1',\n",
    "                       'probVideo_0', 'probVideo_1']\n",
    "\n",
    "    # Prepare the feature matrix (X) and pseudo-labels (y) for training the Naive Bayes model\n",
    "    # We'll assume equal prior probabilities for simplicity.\n",
    "    X = df_train[feature_columns].values\n",
    "    y = df_train['annotation_label']\n",
    "\n",
    "    # Train a Gaussian Naive Bayes model\n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(X, y)\n",
    "\n",
    "    def predict_label(row):\n",
    "        # Prepare row features for prediction\n",
    "        row_features = row[feature_columns].values.reshape(1, -1)\n",
    "        \n",
    "        # Predict the label using Naive Bayes\n",
    "        return gnb.predict(row_features)[0]\n",
    "\n",
    "    # Apply the prediction function to each row of the DataFrame\n",
    "    df[text] = df.apply(predict_label, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d26f240d-3573-4c69-a460-ce70853f7197",
   "metadata": {},
   "outputs": [],
   "source": [
    "fusion_df = naive_bayes_fusion(fusion_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9f5db207-662e-4ecd-97dd-062223c4e30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for the Whole Dataset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8430    0.6931    0.7607      1023\n",
      "         1.0     0.7688    0.8878    0.8240      1176\n",
      "\n",
      "    accuracy                         0.7972      2199\n",
      "   macro avg     0.8059    0.7904    0.7924      2199\n",
      "weighted avg     0.8033    0.7972    0.7946      2199\n",
      "\n",
      "\n",
      "Classification Report for Train Subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8552    0.5562    0.6740       552\n",
      "         1.0     0.7351    0.9290    0.8208       732\n",
      "\n",
      "    accuracy                         0.7687      1284\n",
      "   macro avg     0.7951    0.7426    0.7474      1284\n",
      "weighted avg     0.7867    0.7687    0.7577      1284\n",
      "\n",
      "\n",
      "Classification Report for Valid Subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8081    0.8696    0.8377        92\n",
      "         1.0     0.9077    0.8613    0.8839       137\n",
      "\n",
      "    accuracy                         0.8646       229\n",
      "   macro avg     0.8579    0.8654    0.8608       229\n",
      "weighted avg     0.8677    0.8646    0.8653       229\n",
      "\n",
      "\n",
      "Classification Report for Test Subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8407    0.8496    0.8451       379\n",
      "         1.0     0.8119    0.8013    0.8066       307\n",
      "\n",
      "    accuracy                         0.8280       686\n",
      "   macro avg     0.8263    0.8255    0.8259       686\n",
      "weighted avg     0.8278    0.8280    0.8279       686\n",
      "\n"
     ]
    }
   ],
   "source": [
    "printReport(fusion_df, 'naive_bayes_label')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355e1e94-23ce-4ba4-b048-4f2f917126e1",
   "metadata": {},
   "source": [
    "# Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bdcb2f-734d-4c35-9efe-222560b3027c",
   "metadata": {},
   "source": [
    "## Find oiptimal number of estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "7d2970b4-c930-430d-a68a-a22b66efddde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Prepare the features (model probabilities) and the true labels\n",
    "# X = fusion_df[['probText_0', 'probText_1', \n",
    "#                'probAudio_0', 'probAudio_1',\n",
    "#                'probVideo_0', 'probVideo_1',\n",
    "#               ]]\n",
    "# y = fusion_df['annotation_label']\n",
    "\n",
    "# # Filter out the validation data\n",
    "# valid_data = fusion_df[fusion_df['mode'] == 'valid']\n",
    "# X_valid = valid_data[['probText_0', 'probText_1', \n",
    "#                        'probAudio_0', 'probAudio_1',\n",
    "#                        'probVideo_0', 'probVideo_1',\n",
    "#                       ]]\n",
    "# y_valid = valid_data['annotation_label']\n",
    "\n",
    "# # Initialize variables to store results\n",
    "# best_n_estimators = 0\n",
    "# best_accuracy = 0\n",
    "\n",
    "# # Loop over a range of n_estimators (e.g., from 10 to 200)\n",
    "# for n_estimators in range(1, 201):\n",
    "#     # Create the base model (Decision Tree) for Bagging\n",
    "#     base_model = DecisionTreeClassifier()\n",
    "    \n",
    "#     # Instantiate the BaggingClassifier with the current n_estimators\n",
    "#     bagging_model = BaggingClassifier(estimator=base_model, \n",
    "#                                       n_estimators=n_estimators, \n",
    "#                                       random_state=42)\n",
    "    \n",
    "#     # Train the model on the entire training set\n",
    "#     train_data = fusion_df[fusion_df['mode'] == 'train']\n",
    "#     X_train = train_data[['probText_0', 'probText_1', \n",
    "#                            'probAudio_0', 'probAudio_1',\n",
    "#                            'probVideo_0', 'probVideo_1',\n",
    "#                           ]]\n",
    "#     y_train = train_data['annotation_label']\n",
    "    \n",
    "#     bagging_model.fit(X_train, y_train)\n",
    "    \n",
    "#     # Predict on the validation set\n",
    "#     y_pred_valid = bagging_model.predict(X_valid)\n",
    "    \n",
    "#     # Calculate the accuracy on the validation set\n",
    "#     accuracy = accuracy_score(y_valid, y_pred_valid)\n",
    "    \n",
    "#     # If the current model has a better accuracy, update the best parameters\n",
    "#     if accuracy > best_accuracy:\n",
    "#         best_accuracy = accuracy\n",
    "#         best_n_estimators = n_estimators\n",
    "\n",
    "# # Output the best number of estimators and the corresponding accuracy\n",
    "# print(f\"The best number of estimators is: {best_n_estimators}\")\n",
    "# print(f\"The corresponding validation set accuracy is: {best_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191b3616-7ebc-4ca4-a7b0-86e4274a1bd1",
   "metadata": {},
   "source": [
    "## Calculate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "5e1dd371-b783-4466-88f2-30d4f1258ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Prepare the features (model probabilities) and the true labels\n",
    "# X = fusion_df[['probText_0', 'probText_1', \n",
    "#                'probAudio_0', 'probAudio_1',\n",
    "#                'probVideo_0', 'probVideo_1',\n",
    "#               ]]\n",
    "# y = fusion_df['annotation_label']\n",
    "\n",
    "# # Create the base model (Decision Tree) for Bagging\n",
    "# base_model = DecisionTreeClassifier()\n",
    "\n",
    "# # Instantiate BaggingClassifier with Decision Tree as base model\n",
    "# bagging_model = BaggingClassifier(estimator=base_model, \n",
    "#                                   n_estimators=best_n_estimators, \n",
    "#                                   random_state=42)\n",
    "\n",
    "# # Train the model on the training set\n",
    "# train_data = fusion_df[fusion_df['mode'] == 'train']\n",
    "# X_train = train_data[['probText_0', 'probText_1', \n",
    "#                        'probAudio_0', 'probAudio_1',\n",
    "#                        'probVideo_0', 'probVideo_1',\n",
    "#                       ]]\n",
    "# y_train = train_data['annotation_label']\n",
    "\n",
    "# bagging_model.fit(X_train, y_train)\n",
    "\n",
    "# # Predict on the whole dataset\n",
    "# y_pred = bagging_model.predict(X)\n",
    "\n",
    "# # Classification report for the entire dataset\n",
    "# print(\"Classification Report on the Entire Dataset:\")\n",
    "# print(classification_report(y, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "2ed6fe4d-ca0b-4e10-9c42-1fba8a10465c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for mode in ['train', 'valid', 'test']:\n",
    "#     subset_data = fusion_df[fusion_df['mode'] == mode]\n",
    "#     X_subset = subset_data[['probText_0', 'probText_1', \n",
    "#                             'probAudio_0', 'probAudio_1',\n",
    "#                             'probVideo_0', 'probVideo_1',\n",
    "#                            ]]\n",
    "#     y_subset = subset_data['annotation_label']\n",
    "    \n",
    "#     # Get predictions\n",
    "#     y_pred = bagging_model.predict(X_subset)\n",
    "    \n",
    "#     # Print classification report\n",
    "#     print(f\"\\nClassification Report on the {mode.capitalize()} Subset:\")\n",
    "#     print(classification_report(y_subset, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcf23b8-6d39-4fda-be02-9fab00d6ef12",
   "metadata": {},
   "source": [
    "# Fully Connected Layer\n",
    "\n",
    "https://scikit-learn.org/dev/modules/generated/sklearn.neural_network.MLPClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "daef1160-c0f8-4c38-ba61-34b42a4fa8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def train_mlp_using_labels(df, train_mode='train'):\n",
    "    \"\"\"\n",
    "    Train an MLP classifier using labels as features on the 'train' subset, \n",
    "    perform grid search to maximize accuracy on the 'valid' subset, and \n",
    "    predict final labels for all rows.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame with columns:\n",
    "            'textLabel', 'audioLabel', 'videoLabel', 'annotation_label', 'mode'.\n",
    "        train_mode (str): The mode to filter the training subset (default: 'train').\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with an additional column 'mlp_label' containing the predicted labels.\n",
    "    \"\"\"\n",
    "    # Filter the training and validation subsets\n",
    "    train_df = df[df['mode'] == train_mode]\n",
    "    # train_df = df[df['mode'].isin(['train', 'valid'])]\n",
    "    # valid_df = df[df['mode'] == valid_mode]\n",
    "\n",
    "    # Features (labels from text, audio, and video)\n",
    "    X_train = train_df[['textLabel', 'audioLabel', 'videoLabel']]\n",
    "    y_train = train_df['annotation_label']\n",
    "    # X_valid = valid_df[['textLabel', 'audioLabel', 'videoLabel']]\n",
    "    # y_valid = valid_df['annotation_label']\n",
    "\n",
    "    # Define hyperparameter grid for grid search\n",
    "    param_grid = {\n",
    "        'hidden_layer_sizes': [(4,), (8,), (16,), (32,), (64,), (128,), (64, 32), (32, 16), (16, 8), (8, 4)],\n",
    "        'activation': ['relu', 'tanh', 'identity'],\n",
    "        'learning_rate_init': [1e-5, 5e-5, 1e-4, 5e-4, 1e-3],\n",
    "        'batch_size': [4, 8, 16, 32],\n",
    "        'max_iter': [500]\n",
    "    }\n",
    "\n",
    "    # Initialize the MLPClassifier\n",
    "    mlp = MLPClassifier(early_stopping=True, tol=1e-5)\n",
    "\n",
    "    # Perform grid search with accuracy as the scoring metric\n",
    "    grid_search = GridSearchCV(estimator=mlp, param_grid=param_grid, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Select the best estimator based on grid search\n",
    "    best_mlp = grid_search.best_estimator_\n",
    "    print(\"Best params: \", grid_search.best_params_)\n",
    "    print(\"Num of iterations: \", best_mlp.n_iter_)\n",
    "\n",
    "    # # Evaluate the best model on the validation subset\n",
    "    # valid_predictions = best_mlp.predict(X_valid)\n",
    "    \n",
    "    # valid_accuracy = accuracy_score(y_valid, valid_predictions)\n",
    "    # print(f\"Validation Accuracy of Best Model: {valid_accuracy:.4f}\")\n",
    "\n",
    "    # Use the trained best MLP model to predict for the entire dataset\n",
    "    all_features = df[['textLabel', 'audioLabel', 'videoLabel']]\n",
    "    df['mlp_label'] = best_mlp.predict(all_features)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc4f7424-c570-4077-ba73-fdd0fd04688c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/my_enviroment/lib64/python3.9/site-packages/sklearn/model_selection/_search.py:412: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.array(param_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:  {'activation': 'relu', 'batch_size': 4, 'hidden_layer_sizes': (16, 8), 'learning_rate_init': 5e-05, 'max_iter': 500}\n",
      "Num of iterations:  23\n"
     ]
    }
   ],
   "source": [
    "fusion_df = train_mlp_using_labels(fusion_df, train_mode='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1092fec4-dca8-45a4-8c73-b8df828e00b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for the Whole Dataset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8413    0.7048    0.7670      1023\n",
      "         1.0     0.7750    0.8844    0.8261      1176\n",
      "\n",
      "    accuracy                         0.8008      2199\n",
      "   macro avg     0.8081    0.7946    0.7965      2199\n",
      "weighted avg     0.8058    0.8008    0.7986      2199\n",
      "\n",
      "\n",
      "Classification Report for Train Subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8911    0.8007    0.8435       552\n",
      "         1.0     0.8604    0.9262    0.8921       732\n",
      "\n",
      "    accuracy                         0.8723      1284\n",
      "   macro avg     0.8758    0.8635    0.8678      1284\n",
      "weighted avg     0.8736    0.8723    0.8712      1284\n",
      "\n",
      "\n",
      "Classification Report for Valid Subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6212    0.4457    0.5190        92\n",
      "         1.0     0.6871    0.8175    0.7467       137\n",
      "\n",
      "    accuracy                         0.6681       229\n",
      "   macro avg     0.6542    0.6316    0.6328       229\n",
      "weighted avg     0.6606    0.6681    0.6552       229\n",
      "\n",
      "\n",
      "Classification Report for Test Subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8068    0.6280    0.7062       379\n",
      "         1.0     0.6394    0.8143    0.7163       307\n",
      "\n",
      "    accuracy                         0.7114       686\n",
      "   macro avg     0.7231    0.7212    0.7113       686\n",
      "weighted avg     0.7319    0.7114    0.7108       686\n",
      "\n"
     ]
    }
   ],
   "source": [
    "printReport(fusion_df, 'mlp_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ae2b3ac-a58e-4939-b390-c76bdc892a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.neural_network import MLPClassifier\n",
    "# import pandas as pd\n",
    "\n",
    "# def train_mlp_using_probabilities(df, mode='valid'):\n",
    "#     \"\"\"\n",
    "#     Train an MLP classifier using probabilities as features from 'text', 'audio', and 'video'\n",
    "#     on the 'valid' subset and predict the final labels for all rows.\n",
    "\n",
    "#     Args:\n",
    "#         df (pd.DataFrame): Input DataFrame with columns:\n",
    "#             'probText_0', 'probText_1', 'probAudio_0', 'probAudio_1',\n",
    "#             'probVideo_0', 'probVideo_1', 'annotation_label', 'mode'.\n",
    "#         mode (str): The mode to filter the validation subset (default: 'valid').\n",
    "\n",
    "#     Returns:\n",
    "#         pd.DataFrame: DataFrame with an additional column 'mlp_label' containing the predicted labels.\n",
    "#     \"\"\"\n",
    "#     # Filter the validation subset\n",
    "#     valid_df = df[df['mode'] == mode]\n",
    "    \n",
    "#     # Features (probabilities from text, audio, and video)\n",
    "#     X = valid_df[['probText_0', 'probText_1', 'probAudio_0', 'probAudio_1', 'probVideo_0', 'probVideo_1']]\n",
    "    \n",
    "#     # Target (ground truth labels)\n",
    "#     y = valid_df['annotation_label']\n",
    "    \n",
    "#     # Train the MLP classifier\n",
    "#     mlp = MLPClassifier(hidden_layer_sizes=(64, ), max_iter=1000000000)\n",
    "#     mlp.fit(X, y)\n",
    "    \n",
    "#     # Use the trained MLP model to predict for the entire dataset\n",
    "#     all_features = df[['probText_0', 'probText_1', 'probAudio_0', 'probAudio_1', 'probVideo_0', 'probVideo_1']]\n",
    "#     df['mlpProb_label'] = mlp.predict(all_features).astype('int')\n",
    "    \n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34a00cb3-ccfb-4fed-b07f-8e9451d3cb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def train_mlp_using_probabilities(df, train_mode='train'):\n",
    "    \"\"\"\n",
    "    Train an MLP classifier using probabiliy scores as features on the 'train' subset, \n",
    "    perform grid search to maximize accuracy on the 'valid' subset, and \n",
    "    predict final labels for all rows.\n",
    "    \"\"\"\n",
    "    # Filter the training and validation subsets\n",
    "    train_df = df[df['mode'] == train_mode]\n",
    "    # train_df = df[df['mode'].isin(['train', 'valid'])]\n",
    "    # valid_df = df[df['mode'] == valid_mode]\n",
    "\n",
    "    # Features (labels from text, audio, and video)\n",
    "    X_train = train_df[['probText_0', 'probText_1', 'probAudio_0', 'probAudio_1', 'probVideo_0', 'probVideo_1']]\n",
    "    y_train = train_df['annotation_label']\n",
    "    # X_valid = valid_df[['probText_0', 'probText_1', 'probAudio_0', 'probAudio_1', 'probVideo_0', 'probVideo_1']]\n",
    "    # y_valid = valid_df['annotation_label']\n",
    "\n",
    "    # Define hyperparameter grid for grid search\n",
    "    param_grid = {\n",
    "        'hidden_layer_sizes': [(4,), (8,), (16,), (32,), (64,), (128,), (64, 32), (32, 16), (16, 8), (8, 4)],\n",
    "        'activation': ['relu', 'tanh', 'identity'],\n",
    "        'learning_rate_init': [1e-5, 5e-5, 1e-4, 5e-4, 1e-3],\n",
    "        'batch_size': [4, 8, 16, 32],\n",
    "        'max_iter': [500]\n",
    "    }\n",
    "\n",
    "    # Initialize the MLPClassifier\n",
    "    mlp = MLPClassifier(early_stopping=True, tol=1e-5)\n",
    "\n",
    "    # Perform grid search with accuracy as the scoring metric\n",
    "    grid_search = GridSearchCV(estimator=mlp, param_grid=param_grid, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Select the best estimator based on grid search\n",
    "    best_mlp = grid_search.best_estimator_\n",
    "    print(\"Best params: \", grid_search.best_params_)\n",
    "    print(\"Num of iterations: \", best_mlp.n_iter_)\n",
    "\n",
    "    # # Evaluate the best model on the validation subset\n",
    "    # valid_predictions = best_mlp.predict(X_valid)\n",
    "    \n",
    "    # valid_accuracy = accuracy_score(y_valid, valid_predictions)\n",
    "    # print(f\"Validation Accuracy of Best Model: {valid_accuracy:.4f}\")\n",
    "\n",
    "    # Use the trained best MLP model to predict for the entire dataset\n",
    "    all_features = df[['probText_0', 'probText_1', 'probAudio_0', 'probAudio_1', 'probVideo_0', 'probVideo_1']]\n",
    "    df['mlpProb_label'] = best_mlp.predict(all_features)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "192974a9-dd49-4fbd-b251-12de8f860f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/k/kyparkypar/ondemand/data/sys/myjobs/projects/default/my_enviroment/lib64/python3.9/site-packages/sklearn/model_selection/_search.py:412: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.array(param_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:  {'activation': 'relu', 'batch_size': 32, 'hidden_layer_sizes': (16, 8), 'learning_rate_init': 0.001, 'max_iter': 500}\n",
      "Num of iterations:  13\n"
     ]
    }
   ],
   "source": [
    "fusion_df = train_mlp_using_probabilities(fusion_df, train_mode='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ff7ef1a-d3cc-41c1-8447-a31aa76b4ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for the Whole Dataset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8662    0.8983    0.8820      1023\n",
      "         1.0     0.9086    0.8793    0.8937      1176\n",
      "\n",
      "    accuracy                         0.8881      2199\n",
      "   macro avg     0.8874    0.8888    0.8878      2199\n",
      "weighted avg     0.8889    0.8881    0.8882      2199\n",
      "\n",
      "\n",
      "Classification Report for Train Subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8912    0.9348    0.9125       552\n",
      "         1.0     0.9489    0.9139    0.9311       732\n",
      "\n",
      "    accuracy                         0.9229      1284\n",
      "   macro avg     0.9201    0.9244    0.9218      1284\n",
      "weighted avg     0.9241    0.9229    0.9231      1284\n",
      "\n",
      "\n",
      "Classification Report for Valid Subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8081    0.8696    0.8377        92\n",
      "         1.0     0.9077    0.8613    0.8839       137\n",
      "\n",
      "    accuracy                         0.8646       229\n",
      "   macro avg     0.8579    0.8654    0.8608       229\n",
      "weighted avg     0.8677    0.8646    0.8653       229\n",
      "\n",
      "\n",
      "Classification Report for Test Subset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8433    0.8522    0.8478       379\n",
      "         1.0     0.8152    0.8046    0.8098       307\n",
      "\n",
      "    accuracy                         0.8309       686\n",
      "   macro avg     0.8293    0.8284    0.8288       686\n",
      "weighted avg     0.8307    0.8309    0.8308       686\n",
      "\n"
     ]
    }
   ],
   "source": [
    "printReport(fusion_df, 'mlpProb_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8711c10-9bbd-4c63-bbab-25b7d97040e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "My Enviroment",
   "language": "python",
   "name": "my_enviroment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
